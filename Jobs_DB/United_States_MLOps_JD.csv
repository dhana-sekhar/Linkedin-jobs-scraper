title,company,location,date,link,description
MLOps Engineer,Genesis10,United States,2024-08-30,https://www.linkedin.com/jobs/view/mlops-engineer-at-genesis10-4012060572?position=1&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=16j9ViUHpdy8lcW3BhK4cw%3D%3D&trk=public_jobs_jserp-result_search-card,"Genesis10 is seeking a MLOps Engineer for a 3-month contract to hire position with a leading client in Columbus, OH. This role pays $ 50-60 /hour W2 based on experience. Remote work is allowed during contract but will be onsite hybrid once hired and sit in Minneapolis, MN, or Columbus, OH.

Job Description:

As an MLOps Engineer, you will be responsible for the end-to-end productionization and deployment of machine learning models at scale. You will work closely with data scientists to refine models and ensure they are optimized for production. Additionally, you will be responsible for maintaining and improving our MLOps infrastructure, automating deployment pipelines, and ensuring compliance with IT and security standards. You will play a critical role in image management, vulnerability remediation, and the deployment of Client models using modern infrastructure-as-code practices.

Job Duties:


Vulnerability Remediation & Image Management:
Manage and update Docker images, ensuring they are secure and optimized.
Collaborate with data scientists to validate that models run effectively on updated images.
Address security vulnerabilities by updating and patching Docker images.
AWS & Terraform Expertise:
Deploy, manage, and scale AWS services (SageMaker, S3, Lambda) using Terraform.
Automate the spin-up and spin-down of AWS infrastructure using Terraform scripts.
Monitor and optimize AWS resources to ensure cost-effectiveness and efficiency.
DevOps & CI/CD Pipeline Management:
Design, implement, and maintain CI/CD pipelines in Azure DevOps (ADO).
Integrate CI/CD practices with model deployment processes, ensuring smooth productionization of Client models.
Strong experience with Git for code versioning and collaboration.
Model Productionization:
Participate in the end-to-end process of productionizing machine learning models, from model deployment to monitoring and maintaining their performance.
Work with large language models, focusing on implementing near real-time and batch inferences.
Address data drift and model drift in production environments.
Collaboration & Continuous Learning:
Work closely with data scientists, DevOps engineers, and other MLOps professionals to ensure seamless integration and deployment of Client models.
Stay updated on the latest trends and technologies in MLOps, especially related to AWS and Docker.


Requirements:


Python: Deep expertise in Python for scripting and automation.
AWS: Strong experience with AWS services, particularly SageMaker, S3, and Lambda.
Terraform: Proficiency in using Terraform for infrastructure-as-code on AWS.
Docker: Extensive experience with Docker, including building, managing, and securing Docker images.
Linux: Strong command-line skills in Linux, especially for Docker and system management.
DevOps Experience: Azure DevOps (ADO): Significant experience in setting up and managing CI/CD pipelines in ADO.
Git: Proficient in using Git for version control and collaboration.
Additional DevOps Tools: Experience with Jenkins or other CI/CD tools is a plus.
4 years of experience in combination of MLOps/DevOps/Data Engineering; Bachelor's degree in Computer Science, Engineering, or a related discipline.


Preferred Experience:


Experience with large language models and productionizing Client models in a cloud environment.
Exposure to near real-time inference systems and batch processing in Client.
Familiarity with data drift and model drift management.


If you have the described qualifications and are interested in this exciting opportunity, apply today!

About Genesis10:

Ranked a Top Staffing Firm in the U.S. by Staffing Industry Analysts for six consecutive years, Genesis10 puts thousands of consultants and employees to work across the United States every year in contract, contract-for-hire, and permanent placement roles. With more than 300 active clients, Genesis10 provides access to many of the Fortune 100 firms and a variety of mid-market organizations across the full spectrum of industry verticals.

For contract roles, Genesis10 offers the benefits listed below. If this is a perm-placement opportunity, our recruiter can talk you through the unique benefits offered for that particular client.

Benefits of Working with Genesis10:


Access to hundreds of clients, most who have been working with Genesis10 for 5-20+ years.
The opportunity to have a career-home in Genesis10; many of our consultants have been working exclusively with Genesis10 for years.
Access to an experienced, caring recruiting team (more than 7 years of experience, on average.)
Behavioral Health Platform
Medical, Dental, Vision
Health Savings Account
Voluntary Hospital Indemnity (Critical Illness & Accident)
Voluntary Term Life Insurance
401K
Sick Pay (for applicable states/municipalities)
Commuter Benefits (Dallas, NYC, SF)
Remote opportunities available


For multiple years running, Genesis10 has been recognized as a Top Staffing Firm in the U.S., as a Best Company for Work-Life Balance, as a Best Company for Career Growth, for Diversity, and for Leadership, amongst others. To learn more and to view all our available career opportunities, please visit us at our website.

Genesis10 is an Equal Opportunity Employer. Candidates will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

#DIG10-OH
Show more "
MLOps Engineer,Apollo Solutions,United States,2024-08-30,https://www.linkedin.com/jobs/view/mlops-engineer-at-apollo-solutions-4013790238?position=2&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=WJ313UzuyNh7vCPDnjm9rw%3D%3D&trk=public_jobs_jserp-result_search-card,"Founding MLOps Engineer




We are searching for a Founding Engineering in Machine Learning (ML) Infrastructure for an early stage start-up pushing forward the boundaries of AI. They have been backed by top tier Venture Capital and are now looking to build the infrastructure for real-time AI applications.




You will play a crucial role in shaping the technical direction in a greenfield environment. The initial projects will include building and scaling GPU infrastructure, engaging with customers and contributing heavily in system design.




You will also provide technical leadership and supporting to grow the engineering function.

Requirements

2+ years of experience contributing to the architecture and design of large scale distributed systems
Strong understanding of Cloud technologies (AWS, GCP, Azure)
Strong AI/ML Infrastructure experience
Experience with GPUs/CUDA is a huge bonus.




If you're interested, please apply now!

Show more "
MLOPS ENGINEER,Veridic Solutions,United States,2024-08-18,https://www.linkedin.com/jobs/view/mlops-engineer-at-veridic-solutions-4001606115?position=3&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=6IU%2FDKzxhRpPtZsFhWUAxA%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Description

Veridic is a leading developer of cloud-based software based in Malvern, PA. We prioritize innovation and learning to address complex challenges and deliver top-notch cloud solutions. Our certified engineers excel in cloud projects and are affiliated with prestigious organizations like AWS, Microsoft, and OPC Foundation.




Role Description

This is a contract Mlops Engineer role at Veridic Solutions in Malvern, PA. The Mlops Engineer will be responsible for tasks like mechanical engineering, machine design, computer-aided design (CAD), project management, and research and development (R&D). This is an on-site role that involves working on cloud-based projects.




Qualifications

Mechanical Engineering, Machine Design, and Computer-Aided Design (CAD) skills
Project Management and Research and Development (R&D) skills
Experience in cloud platforms like AWS, GCP, or Azure
Knowledge of Salesforce and Mobile Product Development
Bachelor's degree in Mechanical Engineering or related field
Strong problem-solving and analytical skills
Effective communication and teamwork abilities
Show more "
MLOps ENGINEER,Veridic Solutions,United States,2024-08-28,https://www.linkedin.com/jobs/view/mlops-engineer-at-veridic-solutions-4010128243?position=4&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=9D2dtONfhUU0iUJvSMpDng%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Description:

We are seeking a skilled and motivated Machine Learning Operations (MLOps) Engineer to join our team. As an MLOps Engineer, you will work closely with data scientists, machine learning engineers, and software developers to deploy, monitor, and optimize machine learning models in production environments. Your role will be crucial in bridging the gap between machine learning and operations, ensuring that models are scalable, reliable, and integrated seamlessly into our systems.

Key Responsibilities:

Model Deployment and Integration:
Design, develop, and manage scalable machine learning model deployment pipelines.
Collaborate with data scientists and software engineers to deploy machine learning models in production environments (on-premise and cloud).
Automate the deployment process using CI/CD pipelines, containerization (e.g., Docker), and orchestration tools (e.g., Kubernetes).
Monitoring and Performance Optimization:
Monitor machine learning models in production to ensure performance, reliability, and accuracy.
Implement monitoring and alerting systems for model performance metrics and drift detection.
Optimize model performance by identifying bottlenecks and improving resource allocation.
Infrastructure Management:
Set up and manage the infrastructure required for machine learning workloads, including cloud services (e.g., AWS, GCP, Azure), databases, and data pipelines.
Ensure scalability and security of the infrastructure supporting machine learning models.
Manage and optimize the cost of cloud infrastructure used for machine learning tasks.

Show more "
MLOps Engineer,Evolutyz Corp,United States,2024-08-27,https://www.linkedin.com/jobs/view/mlops-engineer-at-evolutyz-corp-4009273405?position=5&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=3GUvxPRAGLKN%2FBV3ulbZNg%3D%3D&trk=public_jobs_jserp-result_search-card,"About Evolutyz Corp




Join Evolutyz Corp, a vibrant, award-winning, woman-owned IT consulting firm headquartered in Chicago. We are passionate about innovation and committed to driving business transformation with our custom technical solutions. As a certified MBE enterprise, we foster a diverse and inclusive work environment where your ideas are valued. At Evolutyz, you’ll find the perfect opportunity to grow your career, make an impact, and collaborate with a team that supports your professional journey. Discover how you can thrive with us at (https://www.evolutyz.com/).




Job Description:

CTH and hybrid role at Ann Arbor, MI.

Strong programming skills in languages such as Python, Java, or Scala.
Experience as an MLOps Engineer, sClientifically with Azure ML and related Azure technologies.
Experience with containerization technologies such as Docker and orchestration tools like Kubernetes.
Proficiency in automation tools like JIRA, Ansible, Jenkins, Docker compose, Artifactory, etc.
Certification in cloud computing (e.g., AWS Certified Machine Learning – SClientialty, Google Professional Machine Learning Engineer).
Knowledge of software engineering best practices such as test-driven development (TDD) and code reviews.

Show more "
MLOps Engineer,Daman,United States,2024-08-28,https://www.linkedin.com/jobs/view/mlops-engineer-at-daman-4010217994?position=6&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=eFHPshUZx7FK58%2FBLs7NZg%3D%3D&trk=public_jobs_jserp-result_search-card,"Tech Skills




AWS Sagemaker

Amazon Neptune

AWS

ML Ops Processes




Expectations




Be a thought leader in the ML Ops space. Be able to design solutions and plans for the team to execute and follow on.

Provide hands-on development of solutions in the ML Ops space to improve experience for Data Scientists and Machine Learning engineers.

Configure, manage, and improve USAA's AI/ML environment across different cloud platforms.




Qualifications




Hands-on experience in setting up AWS security groups, roles, and implementing best practices around SageMaker and Neptune




Hands-on experience working with at least one cloud hyperscaler (AWS)




Ability to build MLOps pipelines on AWS SageMaker + experience with AWS Sagemaker deployment




Hands on DevOps experience – CI/CD in Jenkins , Bitbucket, Kubernetes ,OpenShift




Preferred:

knowledge in machine learning frameworks or libraries such as TensorFlow, Keras, PyTorch, etc




Ability to understand tools used by data scientist and experience with software development and test automation




Experience with Agile development and delivery – Scrum, Lean, XP, Kanban methodologies




Proficiency in modern programming languages such as Python




Responsibilities




In this role you will help to develop, build, design, continuously improve, and support the MLOps Platform




You will participate in all stages of development, use various software and tools, and enabling self-service tools for data science teams




The role also involves designing, developing, integrating, and deploying tools for Data Science and Machine Learning (ML) Research




The successful applicant will design and operate a framework for Machine Learning Operations (MLOps), advise on software engineering for ML, and ensure consistency with cloud architectural principles

Show more "
MLOps Engineer - Ann Arbor MI,DPR Solutions Inc,United States,2024-08-08,https://www.linkedin.com/jobs/view/mlops-engineer-ann-arbor-mi-at-dpr-solutions-inc-3996528050?position=7&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=oRmqwWsVo3qPCKI9d1a%2B8w%3D%3D&trk=public_jobs_jserp-result_search-card,"MLOps Engineer

Ann Arbor MI

Long term

CANDIDATES MUST BE ONSITE FROM DAY 1. LOCAL CANDIDATES HIGHLY PREFERRED. CONTRACT TO HIRE ROLE WITH CONVERSION SOME TIME IN 2025. VISA CANDIDATES ARE OK BUT MUST BE WILLING TO TRANSFER VISA WHEN OFFERED FULL TIME ROLE.

Work schedule is 3 days in the office and 2 days WFH.

Seeking a highly skilled Machine Learnings Ops Engineer contractor with expertise in Azure ML. This role is central to strengthening our analytics capabilities, focusing on establishing MLOps Key Performance Indicators (KPIs), , implementing model monitoring and alerting systems, and exploring avenues towards online learning. The successful candidate will be an expert in Azure ML, Azure DevOps, Azure Container Apps, and familiar with automation tools like Jenkins, with a strong background in containerized software deployments and CI/CD pipelines.

As an MLOps Engineer, you will be responsible for bridging the gap between data science and IT, ensuring that machine learning models are deployed effectively and efficiently. You will collaborate with cross-functional teams to design, implement, and maintain scalable machine learning pipelines and infrastructure.

**Responsibilities: **

Design, implement, and maintain end-to-end machine learning pipelines for model training, validation, and deployment.

Collaborate with data scientists, software engineers, and DevOps engineers to integrate machine learning models into production systems.

Develop automation tools and frameworks to streamline the machine learning workflow, including data preprocessing, feature engineering, model training, and evaluation.

Optimize model performance and scalability by leveraging cloud computing resources and distributed computing techniques.

Implement monitoring and logging solutions to track model performance, data quality, and system health in production.

Manage model versioning, experimentation, and reproducibility using version control systems and experiment tracking tools.

Stay up-to-date with the latest trends and technologies in machine learning, cloud computing, and software engineering, and incorporate them into the MLOps workflow.

Provide technical guidance and mentorship to junior team members on best practices for MLOps.

**Qualifications: **

Bachelor's degree or higher in computer science, engineering, mathematics, or related field.

Strong programming skills in languages such as Python, Java, or Scala.

Proven experience as an MLOps Engineer, sClientifically with Azure ML and related Azure technologies.

Good experience with containerization technologies such as Docker and orchestration tools like Kubernetes.

Proficiency in automation tools like JIRA, Ansible, Jenkins, Docker compose, Artifactory, etc.

Knowledge of DevOps practices and tools for continuous integration, continuous deployment (CI/CD), and infrastructure as code (IaC).

Experience with version control systems such as Git and collaboration tools like GitLab or GitHub.

Excellent problem-solving skills and ability to work in a fast-paced, collaborative environment.

Strong communication skills and ability to effectively communicate technical concepts to non-technical stakeholders.

Certification in cloud computing (e.g., AWS Certified Machine Learning – SClientialty, Google Professional Machine Learning Engineer).

Knowledge of software engineering best practices such as test-driven development (TDD) and code reviews.

Experience with Rstudio/POSIT connect, RapidMiner.

Greetings !!

For More Details & Immediate Response

Contact - https://www.linkedin.com/in/saisreenca/
Show more "
MLOps SRE DevOPS - Remote / Telecommute,Cynet Systems,United States,2024-08-15,https://www.linkedin.com/jobs/view/mlops-sre-devops-remote-telecommute-at-cynet-systems-4000745505?position=8&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=4Rnk6HpqbAgBO7fqxOTNlQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Description:

Pay Range: $55hr - $60hr

Basic Qualifications:
BA / BS degree with 4+ years of experience (or) MS degree with 2+ years of experience as a SRE Engineer.
Expertise in infrastructure automation tools like Terraform, Ansible or Cloud Formation.
Strong experience with cloud services (AWS, GCP, Azure) and container orchestration tools (Kubernetes, Docker).
Proficiency in programming languages such as Python, Go.
Deep understanding of networking, security and database technologies.
Preferred Qualifications:
Bachelor's degree in Computer Science, Software Engineering, or a related field; a Master's degree is a plus.
Familiarity with AI and machine learning concepts and the ability to collaborate effectively with data scientists and AI engineers.
Strong problem-solving skills and the ability to troubleshoot complex technical issues.
Knowledge of security best practices and compliance standards.
Excellent teamwork and communication skills to lead and mentor cross-functional teams effectively.
Show more "
MLOPS Engineer,Veridic Solutions,United States,2024-08-23,https://www.linkedin.com/jobs/view/mlops-engineer-at-veridic-solutions-4006235047?position=9&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=ALco8XuB75ZVZzsDYrlp7g%3D%3D&trk=public_jobs_jserp-result_search-card,"Role : MLOps Engineer

Location : Malvern, PA (day 1 onsite)

Skills:

AWS

Python

Devops

Lambda

Docker

Kubernetes

Jenkins

Terraform




Best Regards,

Faraz Ahmad Zaidi

Senior US IT Recruiter

1201 W EVERGREEN ST, DURANT, OKLAHOMA 74701

M +19723259509 | faraz.ahmad@veridicsolutions.com

www.veridicsolutions.com

Show more "
MLOps Engineer,Datasite,United States,2024-08-29,https://www.linkedin.com/jobs/view/mlops-engineer-at-datasite-4010872638?position=10&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=6YcuQDgpv7sMILOfQpGoNw%3D%3D&trk=public_jobs_jserp-result_search-card,"Datasite is where deals are made. We provide the data rooms and SaaS technology used in M&A and other high-value transactions, to deliver projects in more than 170 countries. Carrying that success into the future is all about you. Your useful skills, your unusual experience, your unique ideas. Everyone here brings something unexpected. What’s yours? Invest your talents in us, and we’ll return the compliment.

Job Description

At Datasite we are transforming the way companies do Mergers and Acquisitions (M&A). We have the industry leading M&A platform: Datasite One that is built on modern micro-services architecture.

We are looking for a talented MLOPs Engineer to implement production monitoring and alerting for a wide range of machine learning models. As a MLOps Engineer, you will build data pipeline monitoring and create solutions for effectively monitoring outputs of various types of regression, classification, neural network, clustering, and LLM models.

We are open to US remote however we are unable to sponsor or take over sponsorship of an employment Visa at this time.

Essential Duties And Responsibilities


Work with Data Scientists to ensure that models perform as expected during initial Production implementation
Collaborate with Data Scientists, ML Engineers, and DevOps Engineers to ensure smooth model integration into Production
Design and implement monitoring and alerting for all machine learning model inputs and outputs
Demonstrate effectiveness of alerting protocol for detecting anomalous data inputs
Create high quality documentation so other teams can understand monitoring rationale and effectively troubleshoot alerts


Qualifications


Bachelor’s degree or equivalent in data science, machine learning, computer science, mathematics, or statistics
3+ years of industry experience successfully implementing monitoring systems for ML models
Experience implementing validation and monitoring protocols for machine learning models
Fluent in Python
Meticulous attention to detail
Experience with relational (e.g. Snowflake) and non-relational databases (e.g. MongoDB)
Understanding of machine learning approaches and model training processes
Understanding of DevOps and CI/CD fundamentals
Exposure to LLMs
Reputation for creating high quality documentation
Self-motivated and able to work both independently and as part of a team
Ability to quickly learn, evaluate, and apply emerging technology


The base salary range represents the estimated low and high end for this position at the time of this posting. Consistent with applicable law, each candidate’s compensation offer may vary and will be determined based on but not limited to, your geographic region, skills, qualifications, and experience along with the requirements of the position. Datasite reserves the right to modify this pay range at any time.

Salary range $100-160k

As a global organization, Datasite knows that diverse perspectives are essential to our success. We’re committed to maintaining a diverse workforce to serve our customers around the world. Datasite is an equal opportunity employer (EEO) and furthers the principles of EEO through Affirmative Action.
Show more "
Engineer - MLOps,The Wendy's Company,United States,2024-08-21,https://www.linkedin.com/jobs/view/engineer-mlops-at-the-wendy-s-company-3986109451?position=11&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=Mej89BbPr4lKEU2LrdaGqg%3D%3D&trk=public_jobs_jserp-result_search-card,"When our square shaped burgers made their first sizzle on the scene more than 50 years ago, people knew our approach wasn’t like any other. Same goes for the way we support our employees. Our culture of openness, flexibility, and inclusiveness allows everybody to flourish in their own way. If you’re looking for a career where you can be part of the action as we continue to grow our iconic brand - We got you!




The MLOps Engineer will be at the forefront of integrating machine learning models into production environments, focusing on automation, scalability, and reliability. They will work on deploying and managing ML models across various cloud platforms, ensuring efficient workflows and adherence to MLOps best practices. This role involves building and maintaining CI/CD pipelines, automating deployment processes, and optimizing the performance and scalability of ML systems.




The engineer will be responsible for developing tools to enhance data security, integrity, and overall system efficiency. They will collaborate closely with data scientists, software engineers, and IT operations to streamline model deployment, monitor performance, and troubleshoot issues. Ensuring compliance with industry standards and regulatory requirements is also a key part of this role.




This position requires a deep understanding of machine learning and operational principles, combining expertise in data science, software engineering, and IT operations. The ideal candidate will have experience with cloud platforms, container orchestration, and continuous integration tools, along with strong problem-solving skills and the ability to work in a dynamic, fast-paced environment.




Responsibilities

Assists in managing the day-to-day operations of server workloads in cloud environments by monitoring system performance, configuration and maintenance.
Automating the machine learning lifecycle. This includes automating tasks like model training, deployment, and monitoring.
Deploy and manage machine learning models in production. This involves setting up the infrastructure to run the models and ensuring they function properly.
Monitor the performance of models in production and identify any issues. They also work to optimize models for better performance and efficiency.
Collaborate \ Partner with data scientists, DevOps engineers, and other stakeholders to ensure successful integration of machine learning into business operations.
Liason with IT to assist with the Data Engineering and hardware implementation required to support the predictive demand model and support roll-out of associated kitchen equipment.
Keep up to date on industry trends and recommend solutions to meet business needs.
Participate in cross functional team meetings and provide technical support as needed for the management of operations test, market tests, or national roll outs of assigned projects including conducting restaurant surveys, data collection, management of supplier time lines and contractor activities.




Qualifications

Bachelors Degree in IT, Data Science, Statistics, Mathematics, Engineering or related degree is required.
1-3 years of experience with Spark and Data Proc Clusters.
1-3 years of experience with automation, build, and deployments using Cloud Formation or Terraform.
Proficient in leveraging CI and CD tools to automate testing and deployment. Experience working in an Agile DevOps environment.
MLOps and Automation (Jenkins and GitLab).
Excellent understanding of analytics, algorithms and simulation tools.
Demonstrated ability to manage complex systems, deal with internal customers, demonstrate leadership and work across departments.
Ability to contribute toward the development and evolution of MLOps practices.




Wendy’s was built on the premise, ""Quality is our Recipe®,"" which remains the guidepost of the Wendy's system. Today, Wendy's and its franchisees employ hundreds of thousands of people across more than 7,000 restaurants worldwide with a vision of becoming the world's most thriving and beloved restaurant brand.




The base pay range for this position is listed below. The base pay actually offered will take into account internal equity and budget for the open position and also may vary depending on the candidate’s job-related knowledge, skills, and experience, among other relevant factors. This range does not include an estimated value for any benefits, bonus, or other incentives that may be applicable based on position. * The target annual bonus for this role is 7.5% of annualized base salary, based on actual company and personal performance.




Our square burgers make us different and so do our benefits! Our restaurant support roles are eligible for a wide array of benefits, including things such as parental leave, free EAP sessions, company 401k match and other great offerings. For more details about our benefits, including an overview of eligibility and terms for certain benefits, please visit our benefits website, www.wendysbenefits.com.*




NOTE: Wendy’s benefits, bonus, and other incentives are governed by the applicable legal plans and policies and, where appropriate, may be subject to Board approval an individual award agreement terms. Those documents supersede all other information regarding Wendy’s benefits, bonus, and other incentives. Wendy’s retains the right to amend or terminate its plans and policies at its sole discretion, in accordance with applicable plans, policies and laws.




Education: Bachelor's Degree

Travel: 5%

Pay Range: $69,000 - $117,000 Annually

Show more "
MLOps Engineer - Gen AI,Acunor,United States,2024-08-29,https://www.linkedin.com/jobs/view/mlops-engineer-gen-ai-at-acunor-4011165294?position=13&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=7wqhWuIlCpMDICASMwLfhQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Description:

We are seeking an experienced MLOps Engineer to join our dynamic team.

The ideal candidate will have a strong background in machine learning operations (MLOps) with a focus on developing, testing, and deploying state-of-the-art forecasting models.

This role requires a deep understanding of machine learning, data engineering, and the ability to work collaboratively with cross-functional teams to integrate data and optimize model performance.




Qualifications:

Experience: 5+ years of experience in MLOps, data science, or a related field.

Education: Bachelor's degree in computer science, Data Science, Statistics, or a related field.

A Master’s degree is preferred.




Technical Skills:

Strong knowledge of machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, Scikit-learn).

Cloud Platforms: Experience with cloud platforms, specifically Azure, and the ability to deploy models using Azure DataBricks.

Analytical Skills: Strong analytical and problem-solving skills with a focus on feature selection and model optimization.

Collaboration: Excellent communication skills and the ability to work effectively in a collaborative team environment.




Preferred Qualifications:

Certifications: Azure certifications or similar MLOps-related certifications.

Experience with Gen AI: Prior experience developing and deploying models that leverage Generative AI technologies.

Advanced Analytics: Knowledge of advanced statistical methods and their application in forecasting.

Show more "
AI-ML Engineers for MLOPs/LLM Ops Capability Development,Zortech Solutions,United States,2024-08-19,https://www.linkedin.com/jobs/view/ai-ml-engineers-for-mlops-llm-ops-capability-development-at-zortech-solutions-4002119621?position=14&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=zIwiOLSn6QYr0ZtxMQ0UHw%3D%3D&trk=public_jobs_jserp-result_search-card,"Role: AI-ML Engineers for MLOPs/LLM Ops Capability Development

Location: Charlotte, NC/Concord, CA-Day one onsite

Duration: 6+ Months

Job Description


Participate in developing Generative AI Platform Capabilities
Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI, Azure ML)
Participate in day-to-day standups for platform capability build
Provide SME guidance for data science teams
Core Experience Needed:
5+ years of Python experience
5+ years of big data experience needed (Big Query, Hadoop)
3 years of experience in the AIML area (MLOps)
2+ years of experience in developing APIs using Python/FastAPI.
Additional skills needed:
1+year of experience in LLM, Generative AI (developing capabilities or dev/ops)
Experience in developing API on GCP/Azure/API Gateways
1+ years of experience in Vector Database, and Model Development would be an added benefit.
In this role, you will:
Participate in developing Generative AI Platform Capabilities
Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI, Azure ML)
Participate in day-to-day standups for platform capability build
Research industry best practices, evaluate new technologies, develop standards and engineering best practices and recommend innovative solutions that support automation and improve platform resiliency and fault tolerance of critical applications
Execute on roadmaps that align with technology and business strategy. Perform hardware and capacity planning, analysis and forecasts for your portfolio of applications with focus on highest availability, scalability, performance, and timely delivery
Act as an expert resource for other technical teams within DTI


Minimum Requirements


5+ years of Python experience
5+ years of big data experience needed (Big Query, Hadoop)
5+ years with Linux O/S capabilities
3 years of experience in AIML area (MLOps)
3+ years of Pyspark experience
3+ years with VMWare Virtualization technologies
Working knowledge of Auto ML technologies such as H2O Driverless AI, DataRobot, VertexAI, Elastic and Vector DB
Excellent verbal, written, and interpersonal communication skills. Ability to articulate technical solutions to both technical and business audiences
Recent and demonstrated ability to influence management on technical or business solutions
Working knowledge of design and build grid computing with CPU and GPU supporting AIML and NLP
Working knowledge of high-performance storage technologies along with Object Storage
Knowledge and understanding of network infrastructure to support high throughput and low latency grid computing


Preferred Skills


1+year of experience in LLM , Generative AI (developing capabilities or dev/ops)
Experience in developing of API on GCP/Azure/API Gateways
1+year of experience in Elastic Search, Vector Database, Model Development would be added benefit.
Experience with data processing technology (AbInitio, Informatica, IBM DataStage)
Experience with large data technology (Hadoop, Teradata, Elasticsearch, etc.)
Understanding of Agile practices and ability to work with Agile teams to define and track user stories
Experience with implementing complex F5 or other Load Balancer Technologies
Working knowledge of building high resiliency grid/cloud computing infrastructure supporting AIML and NLP workloads
Knowledge and understanding of Cloud computing, PaaS design principles and micro services and containers
Working knowledge/experience with Azure and/or GCP, as well as some experience building complex infrastructure programmatically with IaC tools (Terraform/Ansible etc.)
Working knowledge/experience with on-premise and Public Cloud technologies, such as Cloud Foundry, Kubernetes, Docker
Experience in leading / facilitating analysis of current systems and problem identification and resolution
Ability to lead / facilitate technically complex discussions and working sessions in person or via teleconference
Show more "
Senior MLOps Engineer,Quince,United States,2024-08-28,https://www.linkedin.com/jobs/view/senior-mlops-engineer-at-quince-4010607279?position=15&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=JjJU8K3G0uLkTSpeO6b6NA%3D%3D&trk=public_jobs_jserp-result_search-card,"OUR STORY

Quince was started to challenge the existing idea that nice things should cost a lot. Our mission was simple: create an item of equal or greater quality than the leading luxury brands and sell them at a much lower price.

OUR VALUES

EVERYONE SHOULD BE ABLE TO AFFORD NICE THINGS. Quality shouldn’t be a luxury. We’re proud of our mission to bring the world’s highest quality goods to people at affordable prices.

QUALITY IS MORE THAN MATERIALS. True quality is a combination of premium materials and high production standards.

WE FOCUS ON THE ESSENTIALS. From the perfect crewneck sweater to hotel quality sheets, we're all about high quality essentials that bring enjoyment to daily life.

WE’RE INNOVATING TO MAKE UNREAL PRICES A REALITY. Our uniquely developed factory-direct model lets us offer exceptionally high quality goods for much lower prices than our competitors.

ALWAYS A BETTER DEAL. We believe in real price transparency, for both our customers and factory partners. This way, everyone gets a better deal.

FAIR FACTORIES. We are committed to working with factories that meet the global standards for workplace safety and wage fairness.

OUR TEAM AND SUCCESS

Quince is a retail and technology company co-founded by a team that has extensive experience in retail, technology and building early stage companies. You’ll work with a team of world-class talent from Stanford GSB, Wish.com, D.E. Shaw, Stitch Fix, Urban Outfitters, Wayfair, McKinsey, Nike etc.

THE IDEAL CANDIDATE

We are seeking passionate individuals eager to revolutionize the way people purchase essential goods by leveraging cutting-edge ML and AI solutions. Our centralized data science team is dedicated to optimizing and automating decision-making processes while delivering valuable, actionable business insights. As an MLOps Engineer at Quince, you will play a critical role in shaping our ML development ecosystem. You will build and own the foundational ML development processes, operational pipelines, and production infrastructure necessary to support a scalable, efficient, and impactful ML practice. Your contributions will directly enhance our ability to drive meaningful business outcomes and innovation.

Responsibilities


Design, Build, and Maintain ML Pipelines: Develop and optimize end-to-end machine learning pipelines, including data ingestion, model training, validation, deployment, and monitoring.
Implement Continuous Integration/Continuous Deployment (CI/CD) for ML Models: Establish robust CI/CD processes to automate the testing, deployment, and monitoring of machine learning models in production environments.
Build and Own Production Infrastructure for Serving ML Models: Design, deploy, and maintain the production infrastructure necessary for real-time and batch serving of machine learning models, ensuring high availability, scalability, and reliability.
Build and Own the Feature Store: Design, implement, and manage the feature store to ensure efficient and scalable storage, retrieval, and versioning of features used in machine learning models, enabling consistent and reusable feature engineering across teams.
Collaborate with Data Scientists and Engineers: Work closely with data scientists, data engineers, and software engineers to ensure seamless integration of ML models into production systems, aligning models with business goals.
Monitor and Optimize Model Performance: Implement monitoring solutions to track the performance of ML models in production, identifying and addressing any issues such as data drift, model degradation, or system bottlenecks.
Ensure Scalability and Reliability: Design and implement scalable and reliable ML infrastructure, leveraging cloud platforms, containerization, and orchestration tools like Kubernetes and Docker.
Automate Data and Model Management: Develop automated solutions for version control, model registry, and experiment tracking to manage the lifecycle of ML models efficiently.
Optimize Resource Utilization: Manage and optimize the use of computational resources, such as GPUs and cloud instances, to balance performance with cost-effectiveness.
Conduct Root Cause Analysis and Troubleshooting: Diagnose and resolve issues in ML pipelines, including debugging data, code, and model performance problems.
Document Processes and Systems: Create and maintain comprehensive documentation of ML pipelines, deployment processes, and operational workflows to ensure knowledge sharing and continuity.


Desired Skills


Bachelor degree in computer science, engineering or related field
5+ years of experience in MLOps or ML engineering.
Hands-on and expertise experience in: building and maintaining ML pipelines, building and managing scalable ML production infrastructure, and AWS or other major cloud services.
Strong knowledge of CI/CD practices for ML models.
Familiarity with DevOps principles and tools.
Familiarity with TensorFlow, PyTorch, or similar frameworks.
Proficient in Python and Java (or Scala).
Excellent communication skills.
Move fast, be a team player, and kind.
Show more "
MLOps engineers,Fractal,United States,2024-08-30,https://www.linkedin.com/jobs/view/mlops-engineers-at-fractal-3994283549?position=16&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=UPnoPKy7odCBQRxcmoA%2BNw%3D%3D&trk=public_jobs_jserp-result_search-card,"It's fun to work in a company where people truly BELIEVE in what they are doing!

We're committed to bringing passion and customer focus to the business.

ML Ops Engineer – Model Risk Management

Location: San Antonio, Texas

Responsibilities


Collaborate closely with clients to deeply understand their business challenges, translating these into actionable business problems that machine learning models can solve.
Lead the creation and implementation of a comprehensive model governance framework that standardizes processes for model development, validation, monitoring, and documentation.
Establish standardized documentation templates and explore automation possibilities to streamline documentation processes at various levels, ensuring efficient capture of model metadata related to data quality, design, validation, performance testing, risk mitigation, and compliance.
Establish Model Governance, Model Data Management (Data Collection, Data Quality, Data Privacy), Monitoring, Documentation, Reporting, Risk Management, Continuous Improvement.
Work alongside cross-functional teams to identify, assess, and mitigate risks associated with model performance and compliance, ensuring alignment with business objectives and regulatory requirements.
Develop processes for continuous monitoring and performance testing of models, identifying opportunities for improvement and innovation within the MLOps ecosystem.



Skills Needed


Bachelor’s / Master’s degree in Engineering, Business, Economics/Statistics, or equivalent field.
Minimum of 5+ years of relevant experience in financial services, insurance, or a related industry, with a strong foundation in analytics, model governance, risk management, and compliance.
Demonstrated ability to apply analytical/logical thinking skills to solve complex problems and drive innovative solutions.
Proficiency in programming languages such as Python, R, or Scala; familiarity with automation tools for documentation; and experience with model development, validation, monitoring, and documentation processes.
Understanding of NLP Models, NLP Model Governance.
Exceptional communication skills, capable of presenting complex concepts to senior leadership/executives and collaborating effectively with cross-functional teams.
A proven track record of innovative thinking, inspiring action within teams, and demonstrating leadership in driving governance and risk management initiatives.
Understanding of industry regulations and compliance requirements, with experience developing and implementing governance policies and procedures.



Other Requirements


Need to be in client office for at least 4 days a week.
Be willing to travel for 25% of the time.



Pay

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Fractal, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is: $125,000 - $175,000. In addition, for the current performance period, you may be eligible for a discretionary bonus.

Benefits

As a full-time employee of the company or as an hourly employee working more than 30 hours per week, you will be eligible to participate in the health, dental, vision, life insurance, and disability plans in accordance with the plan documents, which may be amended from time to time. You will be eligible for benefits on the first day of employment with the Company. In addition, you are eligible to participate in the Company 401(k) Plan after 30 days of employment, in accordance with the applicable plan terms. The Company provides for 11 paid holidays and 12 weeks of Parental Leave. We also follow a “free time” PTO policy, allowing you the flexibility to take time needed for either sick time or vacation.

Fractal provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!

Not the right fit? Let us know you're interested in a future opportunity by clicking Introduce Yourself in the top-right corner of the page or create an account to set up email alerts as new job postings become available that meet your interest!
Show more "
AI Scrum Master,"Conch Technologies, Inc",United States,2024-08-15,https://www.linkedin.com/jobs/view/ai-scrum-master-at-conch-technologies-inc-4002051632?position=18&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=5FFVZ0Ec5c5Ai5tYiSwU%2BQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Hi,

Greetings from Conch Technologies Inc

Position: AI Scrum Master

Location: Charlotte NC (Primary) Concord CA (secondary)

Duration: 12+ Months Contract

Primary Skills: Certified Scrum Master, Agile ceremonies, Best Practices,Jira, Trello, Conflict resolution, Coach & mentor teams

Secondary Skills: Facilitation, Communication, Interpersonal skills, Problem Solving

True Scrum master

Must have a full grasp of AI concepts,

Cannot be a normal scrum master, must know AI projects

Superior Communication Skills

Key Requirements

5+ years of Scrum Master

5+ years of Python experience

5+ years of big data experience needed (Big Query, Hadoop)

3 years of experience in AIML area (MLOps)

2+ years of experience in developing APIs using Python/FastAPI.

1+ year of Document AI, Agent Builder/GCP search/conversation / Dialogflow – Nice to have

Good to have 1+year of experience in LLM, Generative AI (developing capabilities or dev/ops)

Good to have Experience in developing of API on GCP/Azure/API Gateways

Good to have 1+year of experience in Vector Database, Model Development would be added

benefit.

Key Responsibilities

Participate in developing Generative AI & Traditional AI Platform Capabilities on enterprise on-

prem and cloud platforms.

Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI,

Azure ML)

Collaborating with Data scientist to optimize the scoring pipeline.

Building automation capabilities to deploy ML Models and LLM Models on the enterprise on-

prem platform and cloud platform.

Build and Deploy capabilities for automating model scoring/Inferencing of ML models and LLMs.

Build and Deploy capabilities for data pipeline deployment standardization and model

consumption by multiple LOBs.

Collaborate with product owners, devOps team, data scientists, support teams to define and

drive end to end model scoring pipelines.

Participate in day-to-day standups for platform capability build.

Provide SME guidance for data science teams on software engineering principles, model

deployments, platform capabilities.

Drive AI use case delivery end to end collaborating with Data scientists, Data Engineers, LOB

Technology using standardized platform processes and capabilities.

Support Production Issues partnering with production support.





Thank you & Regards

V S Durga Prasad | IT Recruiter

E: vprasad@conchtech.com | T: 901-466-4708 | 615-922-1491

Conch Technologies Inc | www.conchtech.com
Show more "
AI Scrum Master,"Conch Technologies, Inc",United States,2024-08-13,https://www.linkedin.com/jobs/view/ai-scrum-master-at-conch-technologies-inc-4000806795?position=19&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=Dwufsl%2F2wgqxx%2BXrchtpMQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Hi,

Greetings from Conch Technologies Inc

Position: AI Scrum Master

Location: Charlotte NC (Primary) Concord CA (secondary)

Duration: 12+ Months Contract

Primary Skills: Certified Scrum Master, Agile ceremonies, Best Practices,Jira, Trello, Conflict resolution, Coach & mentor teams

Secondary Skills: Facilitation, Communication, Interpersonal skills, Problem Solving

True Scrum master

Must have a full grasp of AI concepts,

Cannot be a normal scrum master, must know AI projects

Superior Communication Skills

Key Requirements

5+ years of Scrum Master

5+ years of Python experience

5+ years of big data experience needed (Big Query, Hadoop)

3 years of experience in AIML area (MLOps)

2+ years of experience in developing APIs using Python/FastAPI.

1+ year of Document AI, Agent Builder/GCP search/conversation / Dialogflow – Nice to have

Good to have 1+year of experience in LLM, Generative AI (developing capabilities or dev/ops)

Good to have Experience in developing of API on GCP/Azure/API Gateways

Good to have 1+year of experience in Vector Database, Model Development would be added

benefit.

Key Responsibilities

Participate in developing Generative AI & Traditional AI Platform Capabilities on enterprise on-

prem and cloud platforms.

Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI,

Azure ML)

Collaborating with Data scientist to optimize the scoring pipeline.

Building automation capabilities to deploy ML Models and LLM Models on the enterprise on-

prem platform and cloud platform.

Build and Deploy capabilities for automating model scoring/Inferencing of ML models and LLMs.

Build and Deploy capabilities for data pipeline deployment standardization and model

consumption by multiple LOBs.

Collaborate with product owners, devOps team, data scientists, support teams to define and

drive end to end model scoring pipelines.

Participate in day-to-day standups for platform capability build.

Provide SME guidance for data science teams on software engineering principles, model

deployments, platform capabilities.

Drive AI use case delivery end to end collaborating with Data scientists, Data Engineers, LOB

Technology using standardized platform processes and capabilities.

Support Production Issues partnering with production support.





Thank you & Regards

V S Durga Prasad | IT Recruiter

E: vprasad@conchtech.com | T: 901-466-4708 | 615-922-1491

Conch Technologies Inc | www.conchtech.com
Show more "
MLOps engineers,Fractal,United States,2024-08-29,https://www.linkedin.com/jobs/view/mlops-engineers-at-fractal-3993664381?position=20&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=dVne6DaPfHSe4jZKIeIgfw%3D%3D&trk=public_jobs_jserp-result_search-card,"It's fun to work in a company where people truly BELIEVE in what they are doing!

We're committed to bringing passion and customer focus to the business.

MLOps Engineer – Model Risk Management

Location: San Antonio, Texas

Fractal Analytics is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better.

We believe that a true Fractalite is one who empowers imagination with intelligence. And that it will be such Fractalites that will continue to build the company for the next 100 years.

Role Overview

2 Openings available for senior and mid-level MLOps Engineers.

We seek an innovative and forward-thinking ML Ops Engineer specializing in Model Risk Management & Governance. This role is designed for someone who thrives on the intersection of technical excellence and strategic insight and is capable of navigating the complexities of machine learning models while ensuring robust governance and risk management protocols are in place. You will be part of a dynamic team tasked with developing, implementing, and maintaining a centralized model governance framework that ensures compliance, consistency, and efficiency across all model modules.

Responsibilities


Collaborate closely with clients to deeply understand their business challenges, translating these into actionable business problems that machine learning models can solve.
Lead the creation and implementation of a comprehensive model governance framework that standardizes processes for model development, validation, monitoring, and documentation.
Establish standardized documentation templates and explore automation possibilities to streamline documentation processes at various levels, ensuring efficient capture of model metadata related to data quality, design, validation, performance testing, risk mitigation, and compliance.
Establish Model Governance, Model Data Management (Data Collection, Data Quality, Data Privacy), Monitoring, Documentation, Reporting, Risk Management, Continuous Improvement.
Work alongside cross-functional teams to identify, assess, and mitigate risks associated with model performance and compliance, ensuring alignment with business objectives and regulatory requirements.
Develop processes for continuous monitoring and performance testing of models, identifying opportunities for improvement and innovation within the MLOps ecosystem.



Skills Needed


Bachelor’s / Master’s degree in Engineering, Business, Economics/Statistics, or equivalent field.
Minimum of 5+ years of relevant experience in financial services, insurance, or a related industry, with a strong foundation in analytics, model governance, risk management, and compliance.
Demonstrated ability to apply analytical/logical thinking skills to solve complex problems and drive innovative solutions.
Proficiency in programming languages such as Python, R, or Scala; familiarity with automation tools for documentation; and experience with model development, validation, monitoring, and documentation processes.
Understanding of NLP Models, NLP Model Governance.
Exceptional communication skills, capable of presenting complex concepts to senior leadership/executives and collaborating effectively with cross-functional teams.
A proven track record of innovative thinking, inspiring action within teams, and demonstrating leadership in driving governance and risk management initiatives.
Understanding of industry regulations and compliance requirements, with experience developing and implementing governance policies and procedures.



Other Requirements


Ability to be present at the client office for at least 4 days a week.
Openness to travel up to 25% of the time to meet business needs.



Pay

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Fractal, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is: $125,000 - $175,000. In addition, for the current performance period, you may be eligible for a discretionary bonus.

Benefits

As a full-time employee of the company or as an hourly employee working more than 30 hours per week, you will be eligible to participate in the health, dental, vision, life insurance, and disability plans in accordance with the plan documents, which may be amended from time to time. You will be eligible for benefits on the first day of employment with the Company. In addition, you are eligible to participate in the Company 401(k) Plan after 30 days of employment, in accordance with the applicable plan terms. The Company provides for 11 paid holidays and 12 weeks of Parental Leave. We also follow a “free time” PTO policy, allowing you the flexibility to take time needed for either sick time or vacation.

Fractal provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!

Not the right fit? Let us know you're interested in a future opportunity by clicking Introduce Yourself in the top-right corner of the page or create an account to set up email alerts as new job postings become available that meet your interest!
Show more "
Senior Engineer AI MLOps,Cubiq Recruitment,United States,2024-08-27,https://www.linkedin.com/jobs/view/senior-engineer-ai-mlops-at-cubiq-recruitment-4008437653?position=21&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=crRjo0n4g%2FTkB1rgKyUYiw%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Title: Senior Engineer AI/MLOps

Location: Fully Remote (US-based Residents Only, already authorized for work)

Salary: $200,000 - $275,000 + Equity




Company Overview:

Join us in developing cutting-edge artificial general intelligence (AGI) to revolutionize the design of complex physical systems. Work remotely with a future office likely in California (relocation not required).




This company is in stealth-mode, founded by top AI researchers & scientists, backed by some of the most prolific investors across Silicon Valley.




The platform allows users to train and deploy LLMs and Foundation Models whilst also continually training an autonomous AI agent. As the platform grows, it will work towards AGI, and eventually Super-Intelligence.




Responsibilities:

Design and implement deep learning infrastructure for LLMs and foundation models.
Build infrastructure for training and fine-tuning LLMs using non-traditional data.
Develop training/evaluation pipelines on multi-node cloud platforms.
Manage large training and inference clusters.

Skills:

Experience with GenAI/LLM development and MLOps tools (MLFlow, KubeFlow).
Proficiency in PyTorch, HuggingFace, DeepSpeed, or Wandb.

Preferred:

Experience with Diffusion Models, Docker, Kubernetes, Terraform.




Join us in pushing the boundaries of AI and system design.

Show more "
Lead MLOps Engineer,Envision Technology Solutions,United States,2024-08-15,https://www.linkedin.com/jobs/view/lead-mlops-engineer-at-envision-technology-solutions-4002049733?position=22&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=yrkN2StZ0HL2fwzYobrdGA%3D%3D&trk=public_jobs_jserp-result_search-card,"Role: Lead MLOPs Engineer

Location: Remote

Duration: 12+ months contract




Mandatory Skills:

·        3-5 years’ experience working with MLOps system

·        Must have Healthcare industry experience (Healthcare insurance payer side domain)

·        3-5 years of experience in developing/working on MLOps systems, and an overall experience of 10+years into Data Science

·        Expert on using Python to develop scripts for MLOps

·        Expert on cloud platform (Azure/AWS) developer environments




Requirements:

Experience in

·        Designing data pipelines and engineering infrastructure to support enterprise machine learning systems at scale

·        Organizing offline models that data scientists build and turn them into a real machine learning production system

·        Developing and deploying scalable tools and services for our clients to handle machine learning training and inference

·        Understanding application of software engineering rigor and best practices to machine learning, like CI/CD, automation, auditability, versioning, and data security (KubeFlow, MLFlow)

·        Developing and maintaining ML systems built with open source tools (Kale)

·        Facilitate the development and deployment of proof-of-concept machine learning systems

·        Previous work with data drift model drift

·        Expertise on Kubernetes, Kafka, and/or docker

·        Exposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.)

·        Expert in using AWS or Azure ML tools (SageMaker/Azure ML etc.) [preferred]







Thanks & Regards




485B US Highway 1 S, STE 300, Iselin,

New Jersey 08830, United States

Vaibhav Panchbhaiya

Technical Recruiter

3B Staffing LLC.

vaibhav@3bstaffing.com

(973) 587-6909- EXT 533

Show more "
MLops Engineer (DevOps),TEKsystems,United States,2024-08-28,https://www.linkedin.com/jobs/view/mlops-engineer-devops-at-teksystems-4012134035?position=23&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=iq0KDC4t2xJtqlYA227v8w%3D%3D&trk=public_jobs_jserp-result_search-card,"Skills

Aws, Docker, terraform, ci/cd, devops, Model Production, Python, SQL

Top Skills Details

Aws,Docker,terraform,ci/cd,devops,Model Production

Description

This is a 3 month contract to hire position. While this person can possibly work remote during the contract portion, the candidate will be expected to work hybrid once they start in fulltime employment. The work location is Columbus, OH or Minneapolis, MN.

Candidates need to have Docker, AWS, Terraform, CI/CD Devops, and Model Production experience.

Contract Duration: 90 days (Contract-to-Hire)

About Us

We are a forward-thinking team within a large enterprise, deeply invested in leveraging machine learning and artificial intelligence to drive impactful business outcomes. Our team is responsible for ensuring the smooth, scalable and secure deployment of machine learning models into production, handling both real-time and batch processing workloads. We offer a unique opportunity to work closely with data scientists and engineers, focusing on large language models and cutting-edge MLOps practices.

Job Summary

As an MLOps Engineer, you will be responsible for the end-to-end productionization and deployment of machine learning models at scale. You will work closely with data scientists to refine models and ensure they are optimized for production. Additionally, you will be responsible for maintaining and improving our MLOps infrastructure, automating deployment pipelines, and ensuring compliance with IT and security standards. You will play a critical role in image management, vulnerability remediation, and the deployment of ML models using modern infrastructure-as-code practices.

Key Responsibilities


Vulnerability Remediation & Image Management:
Manage and update Docker images, ensuring they are secure and optimized.
Collaborate with data scientists to validate that models run effectively on updated images.
Address security vulnerabilities by updating and patching Docker images.
AWS & Terraform Expertise:
Deploy, manage, and scale AWS services (SageMaker, S3, Lambda) using Terraform.
Automate the spin-up and spin-down of AWS infrastructure using Terraform scripts.
Monitor and optimize AWS resources to ensure cost-effectiveness and efficiency.
DevOps & CI/CD Pipeline Management:
Design, implement, and maintain CI/CD pipelines in Azure DevOps (ADO).
Integrate CI/CD practices with model deployment processes, ensuring smooth productionization of ML models.
Strong experience with Git for code versioning and collaboration.
Model Productionization:
Participate in the end-to-end process of productionizing machine learning models, from model deployment to monitoring and maintaining their performance.
Work with large language models, focusing on implementing near real-time and batch inferences.
Address data drift and model drift in production environments.
Collaboration & Continuous Learning:
Work closely with data scientists, DevOps engineers, and other MLOps professionals to ensure seamless integration and deployment of ML models.
Stay updated on the latest trends and technologies in MLOps, especially related to AWS and Docker.



Required Skills & Qualifications


Python: Deep expertise in Python for scripting and automation.
AWS: Strong experience with AWS services, particularly SageMaker, S3, and Lambda.
Terraform: Proficiency in using Terraform for infrastructure-as-code on AWS.
Docker: Extensive experience with Docker, including building, managing, and securing Docker images.
Linux: Strong command-line skills in Linux, especially for Docker and system management.
DevOps Experience: Azure DevOps (ADO): Significant experience in setting up and managing CI/CD pipelines in ADO.
Git: Proficient in using Git for version control and collaboration.
Additional DevOps Tools: Experience with Jenkins or other CI/CD tools is a plus.
Experience & Education: 4 years of experience in combination of MLOps/DevOps/Data Engineering; Bachelor's degree in Computer Science, Engineering, or a related discipline.



Preferred Qualifications


Experience with large language models and productionizing ML models in a cloud environment.
Exposure to near real-time inference systems and batch processing in ML.
Familiarity with data drift and model drift management.
Eligibility requirements apply to some benefits and may depend on your job classification



and length of employment. Benefits are subject to change and may be subject to

specific elections, plan, or program terms.  If eligible, the benefits

Available For This Temporary Role May Include The Following


Medical, dental & vision
Critical Illness, Accident, and Hospital
401(k) Retirement Plan – Pre-tax and Roth post-tax contributions available
Life Insurance (Voluntary Life & AD&D for the employee and dependents)
Short and long-term disability
Health Spending Account (HSA)
Transportation benefits
Employee Assistance Program
Time Off/Leave (PTO, Vacation or Sick Leave)



About TEKsystems

We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.
Show more "
Data Engineer with MLOps,Syntricate Technologies,United States,2024-08-07,https://www.linkedin.com/jobs/view/data-engineer-with-mlops-at-syntricate-technologies-3995025645?position=24&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=kHO5YjjS1lFQfCCzXY4iuw%3D%3D&trk=public_jobs_jserp-result_search-card,"Hi,

Hope you are doing well

Number of position : 3

Only Full Time

Full-time

I, Shakib (i3 infotek) would like to share a job opportunity as Data Engineer with MLOps based in Irving, TX (Onsite) location for a Full-time position.

In case, if you are not comfortable with this location, please share your preference with contact details for further requirements

Kindly find the JD below and let me know if you are available for the same.

Job tittle – Data Engineer with MLOps

Duration: Full-time

Location – Irving, TX (Onsite)

Job Description

Roles & Responsibilities


Minimum 5 years of work experience in building data pipelines using Python, PySpark, DJango.
Hands-On experience in working with Python and related packages (like NumPy, pandas etc.) to load and scrap the data.
Hands-on experience with at least one of the tools the Hadoop eco-system (HDFS, AWS Glue, MapReduce, Yarn, Hive, Pig, Impala, Spark, Kafka).
Working experience on Relational/Non-relational databases and familiarity with data model concepts
Working exposure in blending as part of larger scrum team and understanding of related scrum ceremonies
Working knowledge of Unix/Linux.
Knowledge of cloud platforms (e.g., AWS, Azure, GCP)


Please reply me with your updated resume and required details:

Full Name

Best number to reach you:

Work Authorization/Visa Status

Current Location:

Expected Compensation

Best time to call you:

Waiting for your earliest response

Sincerely,

Mohd Shakib

Sr. Technical Recruiter Direct: (phone number removed)
Show more "
Staff MLOps Engineer,Bazaarvoice,United States,2024-08-29,https://www.linkedin.com/jobs/view/staff-mlops-engineer-at-bazaarvoice-4013219155?position=25&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=iV4mSJYlVQnCBZQDgycPfA%3D%3D&trk=public_jobs_jserp-result_search-card,"We’re looking for a Staff MLOps Engineer to join our Machine Learning team. You’ll work closely with a team of engineers to create a platform on top of that data that will be leveraged by virtually every other product and system we have built or will build in the future. You’ll be responsible for building and maintaining the infrastructure and tooling that enables our ML Engineers and Data Scientists to focus on model development and feature engineering.

Key Responsibilities


Design, implement, and maintain robust MLOps platforms and tooling for both batch and streaming ML pipelines.
Develop and manage monitoring and observability solutions for ML systems.
Lead DevOps practices, including CI/CD pipelines and Infrastructure as Code (IaC).
Architect and implement cloud-based solutions on AWS.
Collaborate with ML Engineers and Data Scientists to develop, train, and deploy machine learning models.
Engage in feature engineering and model optimization to improve ML system performance.
Participate in the full ML lifecycle, from data preparation to model deployment and monitoring.
Optimize and refactor existing systems for improved performance and reliability.
Drive technical initiatives and best practices in both MLOps and ML Engineering.



Required Skills And Experience


Strong Python Proficiency: Excellent skills for developing, deploying, and maintaining our machine learning systems.
Language Versatility: Experience with statically-typed or JVM languages. Willingness to learn Scala is highly desirable.
Cloud Engineering Skills: Extensive experience with Cloud Platforms & Services, ideally AWS (e.g., Lambda, ECS, ECR, CloudWatch, MSK, SNS, SQS).
Infrastructure as Code: Proficiency in IaC, particularly Terraform.
Kubernetes Expertise: Strong hands-on experience with managing clusters and deploying services.
Data Orchestration: Experience with ML orchestration tools (e.g., Flyte, Airflow, Kubeflow, Luigi, or Prefect).
CI/CD: Expertise in pipelines, especially GitHub Actions and Jenkins.
Networking: Knowledge of concepts and implementation.
Streaming: Experience with Kafka and other streaming technologies.
ML Monitoring: Familiarity with observability tools (e.g., Arize AI, Weights and Biases).
NLP/LLMs: Experience with NLP, LLMs, and RAG systems in production, or strong desire to learn.
CLI & Shell Scripting: Proficiency in scripting and command-line tools.
APIs: Experience with deploying and managing production APIs.
Software Engineering Best-Practices: Knowledge of industry standards and practices.



Preferred Qualifications


AWS AI Services: Hands-on experience with AWS SageMaker and/or AWS Bedrock.
Data Processing: Experience with high-volume, unstructured data processing.
ML Applications: Familiarity with NLP, Computer Vision, and traditional ML applications.
System Migration: Previous work in refactoring and migrating complex systems.
AWS Certification: AWS Solution Architect Professional or Associate certification.
Advanced Degree: Master's degree in ML / AI / Computer Science.



Personal Qualities


Passionate about building developer-friendly platforms and tools.
Thrives in a terminal-based development environment.
Enthusiastic about creating production-grade, robust, reliable, and performant systems.
Not afraid to dive into and improve complex existing solutions.
Team player who works well with ML Engineers, Data Scientists, and management.
Strong technical mentoring skills.
Excellent problem-solving and communication skills.



Show more "
AI ML,BLYK Engineering Services,United States,2024-08-16,https://www.linkedin.com/jobs/view/ai-ml-at-blyk-engineering-services-4000272672?position=26&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=hQv%2F7pPThR9N3PgilncCrQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Role: AI ML

Location: San Diego, CA

SEMI-CONDUCTOR DOMAIN EXPERIENCE IS MUST




 

Description

As a Machine Learning Engineer on our core Software AIML team, you will be at the forefront of designing and developing cutting-edge GenAI applications.

You will be working closely with business stakeholders and data engineers to communicate AI recommendations to senior management.

 

Key Responsibilities:

Engage deeply with business teams to identify opportunities and translate the needs into innovative and practical AIML solutions

Design, build, and deploy state of the art AIML models to solve complex business problems

Understand key performance levers and metrics to highlight AIML solution operational issues and drive improvement

Foster close collaboration with engineers and infrastructure partners to implement robust and scalable solutions

Communicate the results and insights effectively to partners and senior leaders, providing clear and actionable recommendations

Stay updated with the latest trends, technologies, and best practices in AI and GenAI and data engineering

Regularly research and present new ideas to improve the team's technical capabilities

 

Minimum Qualifications:

Industry experience 10+ years BSCS, 5+ years MS/PhD in Computer Science, Statistics, Applied Math, or a related field

Preferred Qualifications:

Expert in AIML modeling, Python, AIML Infrastructure, model deployment and MLOps

Experience working in Supply Chain, Operations, or a related field

End to end GenAI application experience

Knowledge in RAG, Prompt Engineering, LoRA and other GenAI techniques

Ability to operate independently and lead without authority

Superb communication and interpersonal skills

 

AI SW Engineer Skills/Experience:

Experience in AI System Development foundational model Lifecycle training, retrieval of Augmented Systems, and Model Evaluation.

Proficient in Large Language Models (LLMs) Architecture, creating targeted Instruction Datasets, and implementing Quantization and Inference Optimizations.

Capable of covering Problem Definition, Data Acquisition, and Full-cycle Deployment, utilizing tools like MLflow, Cloud Platforms like AWS, Google Cloud, Azure.

Proprietary Models like GPT-4 and Claude, Open-source Models like Llama and Mistral, able to deliver high-performing, scalable, and cost-efficient AI solutions.

NLP libraries like NLTK, spaCy, GPT-3, BERT, and Hugging Face's Transformers to create sophisticated natural language processing solutions.

 

TECHNICAL SKILLS:

Methodologies: Spiral, Agile, Waterfall, Lean

Programming Language: C++, Python, Shell, SQL, R

IDE Tools: PyCharm, RStudio, Visual Studio Code, Jupyter Notebook, Google Collab, Navicat

ML Frameworks: Transformers, Scikit-Learn, Keras, TensorFlow, PyTorch, ONNX, NLTK, OpenAI, langchain,

llama-index,kore.ai

DL Architectures: LLM, ANN, CNN, R-CNN, RNN, GRU, LSTM, Transformers, Attention Mechanism, Tokenisers,

BERT, T5, Sentence Transformers, Foundational models

Packages: Pandas, NumPy, Spark, Matplotlib, SciPy

Cloud Technologies: AWS (EC2, S3, RDS, ECS, Lambda), Azure(VM, Functions, ACR, AKS), Digital Ocean, GCP, Paperspace

Database: MySQL, PostgreSQL, MongoDB, Chroma DB, Pinecone, SQLite

Web Frameworks and Web Servers/ Deployment:

Fast API, Flask, Nginx, Gunicorn, Uvicorn, Docker, Kubernetes

Miscellaneous Tools and Technologies:

JIRA, Auto Gluon, GitHub Actions, GitHub Issues, Datadog, MS Power BI, Postman, Locust, Stream lit, CUDA, cuDNN, TensorRT

Version Control: Git, GitHub, DVC (Data Version Control)

Operating Systems: Windows, Linux, Mac

 







LAVANYA KUMARI KAKARLA

LEAD RECRUITER

Call: +1(816) 754 1498

Email: lkumari@blykengineering.com 

Show more "
Machine Learning Operations Engineer ( ML Ops),IT Associates,United States,2024-08-29,https://www.linkedin.com/jobs/view/machine-learning-operations-engineer-ml-ops-at-it-associates-4012856745?position=27&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=NBSmzjPUDlVgp8o%2BoKIyRQ%3D%3D&trk=public_jobs_jserp-result_search-card,"MLOps Engineer




Local to MI or willing to relocate
12+ months contract
Hybrid - 1-2 days/week in the office and 3-4 days work from home.
Immediate hire
Azure experience is a must. Azure Container Apps
Strong DevOps Practices and Tools exp. Red Hat Linux, Jenkins ( Building Jenkins Instances) , Ansible Playbooks for automation
Problem Solving




**Responsibilities: **




Design, implement, and maintain end-to-end machine learning pipelines for model training, validation, and deployment.
Collaborate with data scientists, software engineers, and DevOps engineers to integrate machine learning models into production systems.
Optimize model performance and scalability by leveraging cloud computing resources and distributed computing techniques.
Implement monitoring and logging solutions to track model performance, data quality, and system health in production.
Manage model versioning, experimentation, and reproducibility using version control systems and experiment tracking tools.
Stay up-to-date with the latest trends and technologies in machine learning, cloud computing, and software engineering, and incorporate them into the MLOps workflow.
Provide technical guidance and mentorship to junior team members on best practices for MLOps.




**Qualifications: **




Bachelor's degree or higher in computer science, engineering, mathematics, or related field.
Strong programming skills in languages such as Python, Java, or Scala.
Proven experience as an MLOps Engineer, specifically with Azure ML and related Azure technologies specially Azure Container Apps experience.
Good experience with containerization technologies such as Docker and orchestration tools like Kubernetes.
Proficiency in automation tools like Ansible playbooks, Jenkins (Building and configuring Jenkins instances from scratch) , Docker compose, Artifactory, etc.
Strong Knowledge of DevOps practices and tools for continuous integration, continuous deployment (CI/CD), and infrastructure as code (IaC).
Red Hat Linux ( RPM based) experience highly preferred.
Experience working in Air-Gapped environment highly preferred.
Experience with version control systems such as Git and collaboration tools like GitLab or GitHub.
Excellent problem-solving skills and ability to work in a fast-paced, collaborative environment.
Strong communication skills and ability to effectively communicate technical concepts to non-technical stakeholders.
Certification in cloud computing (e.g., AWS Certified Machine Learning – Specialty, Google Professional Machine Learning Engineer) is a plus
Knowledge of software engineering best practices such as test-driven development (TDD) and code reviews.
Experience with Rstudio/POSIT connect, RapidMiner

Show more "
Data Scientist,HatchPros,United States,2024-08-23,https://www.linkedin.com/jobs/view/data-scientist-at-hatchpros-4008677090?position=28&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=90lgLd7P0jbhQs5X818gIw%3D%3D&trk=public_jobs_jserp-result_search-card,"Video

REmote

USC or GC

central or eastern time zone only

Pricing experience

Education


Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, Mathematics, or a related field.


Experience


Exploratory Data Analysis (EDA):
Proficiency in performing EDA to understand data characteristics and identify patterns, trends, and anomalies.
Experience in data cleaning, data preprocessing, and dealing with missing or inconsistent data.
Machine Learning Model Building:
Proven experience in developing, training, and validating machine learning models for various applications.
Strong understanding of supervised and unsupervised learning algorithms, including regression, classification, clustering, and dimensionality reduction.
Experience in time series forecasting, anomaly detection, and natural language processing is a plus.
Programming Skills:
Proficiency in Python programming, with a deep understanding of data structures, algorithms, and object-oriented programming.
Experience with Python-based data science and machine learning libraries such as NumPy, Pandas, Scikit-learn, TensorFlow, Keras, and PyTorch.
Experience with SQL for database querying and data manipulation.
Feature Engineering:
Expertise in creating new features from raw data to improve model performance.
Knowledge of feature selection techniques to reduce dimensionality and prevent overfitting.
Data Visualization:
Ability to create insightful and interactive visualizations to communicate data findings and model results.
Proficiency with data visualization tools such as Matplotlib, Seaborn, Plotly, or Tableau.


Preferred Experience


Experience with deep learning techniques and frameworks such as TensorFlow and PyTorch.
Familiarity with MLOps practices and tools for continuous integration, delivery, and monitoring of machine learning models.
Previous experience in industries such as safety, compliance, or engineering is a plus.
Show more "
Senior ML Ops Engineer,Fractal,United States,2024-08-30,https://www.linkedin.com/jobs/view/senior-ml-ops-engineer-at-fractal-4012349494?position=29&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=57mLGcw4BiqaV8bbgMYPWg%3D%3D&trk=public_jobs_jserp-result_search-card,"Senior ML Ops Engineer




Fractal Analytics is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better. We believe that a true Fractalite empowers imagination with intelligence. And that it will be such Fractalites that will continue to build the company for the next 100 years.




Please visit Fractal | Intelligence for Imagination for more information about Fractal.

Role Overview

We seek an innovative and forward-thinking ML Ops Engineer specializing in Model Development. This role is designed for someone who thrives on the intersection of technical excellence and strategic insight and is capable of navigating the complexities of machine learning models while coordinating the Model Deployment with data scientists. You will be part of a dynamic team tasked with designing and implementing scalable, efficient, and reliable model training and evaluation processes.




Responsibilities

Collaborate closely with clients to deeply understand their business challenges, translating these into actionable business problems that machine learning models can solve.
Focus on Model Development and Deployment coordination with data scientists for designing and implementing scalable, efficient, and reliable model training and evaluation processes.
Implement CI/CD pipelines for machine learning models using tools like AWS.
Code Pipeline /AWS Cloud formation / Terraform. Enabling seamless deployment and integration into production systems.
Automate the build, testing, and deployment processes to ensure smooth and efficient delivery of updated models.
Implement monitoring solutions to track the performance and behavior of deployed models in real-time.
Set up alerts and notifications to proactively identify issues, such as model degradation or data drift, and take appropriate actions.
Optimize the performance and cost efficiency of machine learning workflows on AWS Sagemaker.
Fine-tune the infrastructure settings, explore autoscaling capabilities, and utilize spot instances for cost-effective model training and inference.
Work alongside cross-functional teams to identify, assess, and mitigate risks associated with model performance and compliance, ensuring alignment with business objectives and regulatory requirements.
Develop processes for continuous monitoring and performance testing of models, identifying opportunities for improvement and innovation within the ML Ops ecosystem.




Qualifications

Bachelor’s / Master’s degree in Engineering, Economics/Statistics, or equivalent field.
Minimum of 8+ years of relevant ML Ops experience in building robust machine learning pipelines in production.
Industry domain experience within insurance, healthcare, financial services, or a related area is strongly preferred.
Hands-on experience in deploying and managing containerized applications using Kubernetes and Docker for scalable and resilient infrastructure in ML Ops environments.
Understanding of ML gateway and load balancing.
Understanding of machine learning lifecycle, model building process, ability to build model implementation pipelines, model evaluation , drift detection, etc.
Experience with Kafka for efficient data streaming and real-time data processing in distributed systems.
Data monitoring tools such as DataDog or similar technology
Knowledge of working with Vertex AI
Experience in setting up and managing Continuous Integration and Continuous Deployment (CI/CD) pipelines, automating testing, deployment, and monitoring processes in MLOps and DevOps workflows.
Git, Control M, ETL experience,
Proficiency in programming languages such as Python, R, or Scala, essential for scripting and automation in MLOps workflows.
Understanding of NLP Models.




Other Requirements

Ability to be present at the client office for at least 4 days a week.
Openness to travel up to 25% of the time to meet business needs.




Pay

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Fractal, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is: $110,000 - $160,000. In addition, for the current performance period, you may be eligible for a discretionary bonus.

Benefits

As a full-time employee of the company or as an hourly employee working more than 30 hours per week, you will be eligible to participate in the health, dental, vision, life insurance, and disability plans in accordance with the plan documents, which may be amended from time to time. You will be eligible for benefits on the first day of employment with the Company. In addition, you are eligible to participate in the Company 401(k) Plan after 30 days of employment, in accordance with the applicable plan terms. The Company provides for 11 paid holidays and 12 weeks of Parental Leave. We also follow a “free time” PTO policy, allowing you the flexibility to take time needed for either sick time or vacation.

Fractal provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

Show more "
MLOps Engineer – Model Risk Management,Fractal,United States,2024-08-07,https://www.linkedin.com/jobs/view/mlops-engineer-%E2%80%93-model-risk-management-at-fractal-3993651824?position=30&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=2ov79QzvM%2BYJHLcea9WzRg%3D%3D&trk=public_jobs_jserp-result_search-card,"Fractal Analytics is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better.




We believe that a true Fractalite is one who empowers imagination with intelligence. And that it will be such Fractalites that will continue to build the company for the next 100 years.




Role Overview

2 Openings available for senior and mid-level MLOps Engineers.

We seek an innovative and forward-thinking ML Ops Engineer specializing in Model Risk Management & Governance. This role is designed for someone who thrives on the intersection of technical excellence and strategic insight and is capable of navigating the complexities of machine learning models while ensuring robust governance and risk management protocols are in place. You will be part of a dynamic team tasked with developing, implementing, and maintaining a centralized model governance framework that ensures compliance, consistency, and efficiency across all model modules.




Responsibilities:

Collaborate closely with clients to deeply understand their business challenges, translating these into actionable business problems that machine learning models can solve.
Lead the creation and implementation of a comprehensive model governance framework that standardizes processes for model development, validation, monitoring, and documentation.
Establish standardized documentation templates and explore automation possibilities to streamline documentation processes at various levels, ensuring efficient capture of model metadata related to data quality, design, validation, performance testing, risk mitigation, and compliance.
Establish Model Governance, Model Data Management (Data Collection, Data Quality, Data Privacy), Monitoring, Documentation, Reporting, Risk Management, Continuous Improvement.
Work alongside cross-functional teams to identify, assess, and mitigate risks associated with model performance and compliance, ensuring alignment with business objectives and regulatory requirements.
Develop processes for continuous monitoring and performance testing of models, identifying opportunities for improvement and innovation within the MLOps ecosystem.




Skills Needed:

Bachelor’s / Master’s degree in Engineering, Business, Economics/Statistics, or equivalent field.
Minimum of 5+ years of relevant experience in financial services, insurance, or a related industry, with a strong foundation in analytics, model governance, risk management, and compliance.
Demonstrated ability to apply analytical/logical thinking skills to solve complex problems and drive innovative solutions.
Proficiency in programming languages such as Python, R, or Scala; familiarity with automation tools for documentation; and experience with model development, validation, monitoring, and documentation processes.
Understanding of NLP Models, NLP Model Governance.
Exceptional communication skills, capable of presenting complex concepts to senior leadership/executives and collaborating effectively with cross-functional teams.
A proven track record of innovative thinking, inspiring action within teams, and demonstrating leadership in driving governance and risk management initiatives.
Understanding of industry regulations and compliance requirements, with experience developing and implementing governance policies and procedures.




Other Requirements:

Ability to be present at the client office for at least 4 days a week.
Openness to travel up to 25% of the time to meet business needs.




Pay:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Fractal, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is: $125,000 - $175,000. In addition, for the current performance period, you may be eligible for a discretionary bonus.




Benefits:

As a full-time employee of the company or as an hourly employee working more than 30 hours per week, you will be eligible to participate in the health, dental, vision, life insurance, and disability plans in accordance with the plan documents, which may be amended from time to time. You will be eligible for benefits on the first day of employment with the Company. In addition, you are eligible to participate in the Company 401(k) Plan after 30 days of employment, in accordance with the applicable plan terms. The Company provides for 11 paid holidays and 12 weeks of Parental Leave. We also follow a “free time” PTO policy, allowing you the flexibility to take time needed for either sick time or vacation.




Fractal provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

Show more "
MLops Data Scientist,LTIMindtree,United States,2024-08-08,https://www.linkedin.com/jobs/view/mlops-data-scientist-at-ltimindtree-3995697977?position=31&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=tzxEW2KiTuN4%2FVw9aTOVzQ%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us:

LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com.




Job Title:

MLops Data Science




Work Location

Denver, Colorado, United States




Job Description:

""MLOps with AWS SageMaker experience to work from Denver P3P4

Mandatory

Hands on experience with AWS Sagemaker for ML model training pipeline development and integration

Hands on experience on shifting traffics all at once canary bluegreen

Hands on experience in working with Snowflake its integration to AWS resources

Require good knowledge on model deployment MLOps

Proficient knowledge on IAC using Terraform yaml to create and manage AWS resources

Proficient knowledge on CICD pipelines creation and its optimization

Individuals who are adept at developing and testing AI models




Must be able to

Break a problem down to its implementable components

Perform data cleaning data transforms and feature engineering

Perform model fitting tuning and validationtesting

Identify what parts of the experiments worked and what did not

Use this new knowledge and loop from 1 until the project scope is complete




Good to have

Proficient in Python SQL

Good Data Science and ML work experience specifically on the regression and classification models

Good analytical skill to derive insights and correlation from the data points

Good understanding on NLP GenAI domain""




Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”):




Benefits and Perks:

Comprehensive Medical Plan Covering Medical, Dental, Vision

Short Term and Long-Term Disability Coverage

401(k) Plan with Company match

Life Insurance

Vacation Time, Sick Leave, Paid Holidays

Paid Paternity and Maternity Leave




The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation.




Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting.




LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law.

Safe return to office:

In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.

Show more "
"MLOps Engineer (MLOps, Python / Contract / Hybrid / Arlington, VA)",Motion Recruitment,United States,2024-08-20,https://www.linkedin.com/jobs/view/mlops-engineer-mlops-python-contract-hybrid-arlington-va-at-motion-recruitment-4006159449?position=32&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=I7yLeo2lljCIGDXhW2ZP1g%3D%3D&trk=public_jobs_jserp-result_search-card,"A Business Analytics and Decision Support team is looking for an MLOps Engineer. This is a full-time, hybrid, contract position located in Arlington, VA. This role is for 11-months with the intention to hire.

They are looking for an MLOps Engineer to join the team and work within a group that deals with Flow Optimization specific to different Amazon warehouses and looks at labor metrics. Good candidates for this position will have experience working with Python and understand working with AWS, and any deployment work or at least understanding of CI/CD pipelines is a big plus.

As an MLOps Engineer within our BADS team, you will work closely with science teams to bring research to production. This is a role that combines engineering knowledge (around machine learning, natural language processing, computer vision), technical strength, and product focus. It will be your job to implement novel ML systems, product integrations, and performance optimizations releases into production. While ensuring CI/CD compliance and ensuring best practices in software development and cloud infrastructure are followed (in the realm of scalability, security and availability).

Required Skills & Experience


AWS development experience/build within AWS products.
Extensive experience coding/scripting in Python
Bachelors in programming or similar (statistics, mathematical degrees on top of that would be a plus)
Minimum 5 years of ML experience
Familiarity with Tensorflow and the statistics scripting language R.


Responsibilities


Own the development and operationalization of solutions deployed in production.
Work across multiple teams to integrate our solutions with products owned by our partners.
Design model experimentation processes and frameworks in synergy with our scientists.
Help the team grow and cultivate best practices in software development, MLOps, and experimentation.
Model training, data pre-processing,
Ongoing support of model and lifestyle.


This is a W-2 contract, so all benefits will be through Motion Recruitment:


Medical, dental, and vision coverage
Paid Time Off (PTO) and Holidays
401(k) Matching


Applicants must be currently authorized to work in the US on a full-time basis now and in the future.

Posted By: Akibu Koroma
Show more "
DevOps/MLOps Engineering Lead,"Synergy Consulting Group, Inc.",United States,2024-08-26,https://www.linkedin.com/jobs/view/devops-mlops-engineering-lead-at-synergy-consulting-group-inc-4010707816?position=33&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=UULGzhCeEpJF5PM7F0%2B7Rg%3D%3D&trk=public_jobs_jserp-result_search-card,"Key Criteria




5+ years of relevant experience

Proven experience in leading DevOps/MLOps initiatives

Creating and maintaining robust, scalable, and efficient CI/CD pipelines for our machine learning models and data processing workflows

Collaborate with cross-functional teams to streamline and automate the end-to-end deployment processes

Ensuring AI/ML initiatives are delivered with high quality and speed

Show more "
Sr. MLOps Engineer (AWS),Compassion International,United States,2024-08-16,https://www.linkedin.com/jobs/view/sr-mlops-engineer-aws-at-compassion-international-4001960093?position=34&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=WxyKKICyt8B%2BRuOaPoTzGg%3D%3D&trk=public_jobs_jserp-result_search-card,"The expected salary range for this position is $120,230.00 - $150,280.00. Employees in specific high cost of labor locations in the United States (such as San Francisco, CA and Seattle, WA) may qualify for a geographic differential. Compassion International is not responsible for third parties who omit this information when copying and re-posting job openings.

This senior professional engineer plays a pivotal role in building and operationalizing the minimally inclusive data necessary for ministry data and analytics initiatives following industry standard practices and tools. He or she is involved in enterprise-level projects and solves complex problems by building, managing and optimizing data pipelines and then moving these data pipelines effectively into production for key data and analytics consumers like business intelligence analysts, data scientists and others who need curated data for data and analytics use cases across the ministry. This incumbent ensures compliance and is a trusted resource and advisor and ensures compliance with ethical standards, data governance and data security requirements while implementing, improving, and operationalizing integrated and reusable data pipelines to enable faster data access, integrated data reuse and improved time-to-solution data and analytics initiatives. He or she is measured on his or her ability to deliver comprehensive solutions for the ministry's business processes and enhance data flow to the right decision-makers at the right moment to help release children from poverty in Jesus' name. At this career level, the incumbent generally works independently on large complex projects or leads a team on projects. He or she often coaches other data professionals.

What will you do?


Maintains a personal relationship with Jesus Christ. Is a consistent witness for Jesus Christ, maintains a courteous, Christ-like attitude in dealing with people within and outside of Compassion, and faithfully upholds Compassion’s ministry in prayer.
Acts as an advocate to raise the awareness of the needs of children. Understands Christ’s mandate to protect children. Commits to and prioritizes child protection considerations in all decision-making, tasks and activities across the ministry. Abides by all behavioral expectations in Compassion’s Statement of Commitment to Child Protection and Code of Conduct. Reports any concerns of abuse, neglect or exploitation of children through Compassion’s internal reporting process and appropriately supports responses to incidents if they occur.
Builds and manages data pipelines consisting of a series of states through which data flows from sources to integration and consumption and leads to do so. Solves complex problems, creates, maintains, and optimizes workloads to move from development to production for specific use cases. Architecting, creating and maintaining data pipelines is the primary responsibility of the senior data engineer.
Collaborates with product teams, information and data architects, data scientists, data analysts and other data consumers to work on the models and algorithms developed by them to optimize them for cost, data quality, security and governance and put them into production, leading to potentially large productivity gains.
Responsible for improving data science and business intelligence teams’ productivity by applying modern tools, techniques and architectures to help the teams innovate and partially or completely automate the most-common, repeatable and tedious data preparation and integration tasks to minimize manual and error-prone processes.
Consults and works with renovating data management infrastructure to drive automation in data integration and management. Identifies and recommends integrations of AI-enabled metadata management tools and techniques, tracks data consumption patterns, performs intelligent sampling and caching, and monitors data schema changes toward recommending automations of existing and future integration flows.
Evangelizes effective data management practices and promotes better understanding of data and analytics. Promotes available data and analytics capabilities and expertise to business units and educates them on leveraging capabilities to achieve ministry goals.
Develops strategies around existing technology products to ensure these products produce expected results and benefit to data consumers at minimal cost. Manages the successful implementation of improvements across the organization and impacts across value streams and business units are considered.
Proactively collaborates and consults with various team members on plans to execute and evaluate performance and ways to reduce complexity. Fostering a culture of technical excellence and continuous learning through mentoring junior engineers and data scientists.
Assists other data engineers and architects in preparing presentations and documentation of new or improved data governance and data standards to governing councils and stakeholders, such as the Architecture Review Board and Data Opportunities Council.
Serves as a subject matter expert on AI and ML ops, data pipelines, data processes, flow, data governance, and available data and analytics applications, including deployment of CI/CD practices for machine learning systems.
Coaches neighbours and teammates leveraging data and provides training and advice on Compassion's data pipelines.


What do you bring?


Ten years Relevant experience working in this or a related field.
Proficiency in the following AWS technologies:
  Data Lake
  Lake Formation
  Glue
  S3
  EventBridge
  Lambda Step Functions
  DynamoDB
  Athena
  AWS IAM (Identify & Access Management)
  CDK or Terraform
  AI/ML model management
AI platform experience in any of the following:
  GCP Vertex
  Azure ML Studio
  DataRobot
  SageMaker
  Comprehend
  Rekognition


Why work here?


The mission: Join a team that is motivated to release children from poverty in Jesus’ name.
Our benefits: Receive generous paid time off, 10% contribution to a 403(b) retirement fund on top of your salary, excellent healthcare coverage, free short-term professional counseling, and more.
Spiritual growth: Participate in regular chapel services, prayer groups, and department devotionals.


Show more "
AI/ML Engineer,Digital Janet,United States,2024-08-08,https://www.linkedin.com/jobs/view/ai-ml-engineer-at-digital-janet-3996581675?position=35&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=5LEcIQJFkxflPuf7LoRzPA%3D%3D&trk=public_jobs_jserp-result_search-card,"Jd

Key Responsibilities:


Participate in developing Generative AI & Traditional AI Platform Capabilities on enterprise on-prem and cloud platforms.
Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI, Azure ML)
Collaborating with Data scientist to optimize the scoring pipeline.
Building automation capabilities to deploy ML Models and LLM Models on the enterprise on-prem platform and cloud platform.
Build and Deploy capabilities for automating model scoring/Inferencing of ML models and LLMs.
Build and Deploy capabilities for data pipeline deployment standardization and model consumption by multiple LOBs.
Collaborate with product owners, devOps team, data scientists, support teams to define and drive end to end model scoring pipelines.
Participate in day-to-day standups for platform capability build.
Provide SME guidance for data science teams on software engineering principles, model deployments, platform capabilities.
Drive AI use case delivery end to end collaborating with Data scientists, Data Engineers, LOB Technology using standardized platform processes and capabilities.
Support Production Issues partnering with production support.


Key Requirements


5+ years of Python experience
5+ years of big data experience needed (Big Query, Hadoop)
3 years of experience in AIML area (MLOps)
2+ years of experience in developing APIs using Python/FastAPI.
1+ year of Document AI, Agent Builder/GCP search/conversation / Dialogflow – Nice to have
Good to have 1+year of experience in LLM, Generative AI (developing capabilities or dev/ops)
Good to have Experience in developing of API on GCP/Azure/API Gateways
Good to have 1+year of experience in Vector Database, Model Development would be added benefit.
Show more "
MLOps Engineer / Python,Signify Technology,United States,2024-08-06,https://www.linkedin.com/jobs/view/mlops-engineer-python-at-signify-technology-3992765781?position=36&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=uX%2FoIk4d2PA9H%2Bte29YlKA%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Title: Senior MLOps Engineer

Salary: $190,000 - $250,000

Location: California, Remote




A well funded startup, partnered with multiple Fortune 500 companies is hiring a Senior Machine Learning / Software Engineer who has experience building scalable ML Infrastructures. On a team of 7 you will be building, scaling, and delivering products to clients while using Python, Docker, Kubernetes, PyTorch, Tensorflow, and cloud (AWS/Azure/GCP) technologies. If you have experience working with large amounts of data to build scalable data infrastructure and optimized data access patterns then this role is for you! Any experience or interest in Large Language Models is a plus. This is a growing team with a lot of professional growth opportunities, Equity, and it provides a highly collaborative working environment in a space where you can make a deep impact within the Machine Learning community.




Requirements

5+ years of experience building Machine Learning models
Python, PyTorch / Tensorflow, and cloud experience
NLP and LLM experience desired, but not required
Experience building out scalable data infrastructures




Benefits

Medical, Dental, and Vision Insurance
Equity
Paid Time Off
Parental Leave
Remote flexibility




If you are interested in learning more about this position or any other roles we may have open, please apply today!







Our Commitment to Diversity, Equity, and Inclusion

Signify’s mission is to empower every person, regardless of their background or circumstances, with an equitable chance to achieve the careers they deserve. Building a diverse future, one placement at a time.

Our Recruitment Consultants undergo continuous training in Inclusive Recruitment. As an MSDUK certified business, we're committed to creating diverse candidate shortlists. We organize free networking events for our candidates and meticulously track our diversity initiatives through data and reporting. Together with our clients, we advocate for an equity-first approach to hiring.

Show more "
AI – ML Engineer with GCP (Google Cloud Platform) Experience (only W2 Position – Strictly No C2C Accepted) 8.26.24,"Systems Technology Group, Inc. (STG)",United States,2024-08-26,https://www.linkedin.com/jobs/view/ai-%E2%80%93-ml-engineer-with-gcp-google-cloud-platform-experience-only-w2-position-%E2%80%93-strictly-no-c2c-accepted-8-26-24-at-systems-technology-group-inc-stg-4008118352?position=37&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=epc4yMg4gky5QmUMEgawRg%3D%3D&trk=public_jobs_jserp-result_search-card,"Title: AI – ML Engineer with GCP (Google Cloud Platform) Experience (only W2 Position – Strictly No C2C Accepted) 8.26.24




Description: STG is a SEI CMMi Level 5 company with several Fortune 500 and State Government clients. STG has an opening for AI – ML Engineer with GCP Experience.

Please note that this project assignment is with our own direct clients. We do not go through any vendors. STG only does business with direct end-clients. This is expected to be a long-term position. STG will provide immigration and permanent residency sponsorship assistance to those candidates who need it.




Job Description:

We believe freedom of movement drives human progress. We also believe in providing you with the freedom to define and realize your dreams. With our incredible plans for the future of mobility, we have a wide variety of opportunities for you to accelerate your career potential as you help us define tomorrow’s transportation. Global Data Insight & Analytics organization is looking for a Machine Learning Engineer focused on building and driving the strategy forward for our internal Data Science / AI/ML platform. This role will work in a small, cross-functional team. The position will collaborate directly and continuously with other engineers, business partners, product managers and designers, and will release early and often. The team you will be working on is focused on building Mach1ML platform – an AI/ML enablement platform to democratize Machine Learning across enterprise (similar to Uber’s Michelangelo, Facebook’s FBLearner, etc.)




Position Responsibilities:

Work closely with Tech Anchor, Product Manager and Product Owner to deliver MLOPs platform and Gen AI solution in GCP using Python and other tools for the data scientists and business across the company.

Work with software and ML engineers/Data Scientist to tackle challenging AIOps and Gen AI problems.

Maintain and mange current CI/CD ecosystem and tools

Find ways to automate and continually improve current CI/CD processes and release processes

Examine, inspect codes / scripts and resolve issues

Help innovate standardize machine learning development practices.

Experiment, innovate and share knowledge with the team.

Lead by example in use of Paired Programming for cross training/upskilling, problem solving, and speed to delivery.

Leverage latest ML/Gen AI / GCP/AIOPs/Kubernetes technologies.




Skills Required:

A Bachelor’s degree in Computer Science / Computer Engineering or similar technical discipline.

3+ years of work experience as a backend software engineer in Python with exceptional software engineering knowledge.

2+ years of experience with Cloud Engineering / Services

Experience with ML workflow orchestration tools: Airflow, Kubeflow etc.

Advanced working knowledge of object-oriented/object function programming languages: Python, C/C++

Experience/understanding in MLOPs and Gen AI

Experience in DevOps: Jenkins/Tekton etc.

Experience with cloud services, preferably GCP Services like Vertex AI, Cloud Function, BigQuery etc.

Experience in container management solution: Kubernetes, Docker

Experience in scripting language: Bash, PowerShell etc.

Experience with Infrastructure as code: Terraform etc.




Skills Preferred:

Master focused in Computer Science / Machine Learning or related field

Experience working with Google Cloud platform (GCP) – specifically Google Kubernetes engine, Terraform, and infrastructure

Experience in programming concepts such as Paired Programming, Test Driven Development, etc.

Knowledge of coding and software craftsmanship practices.

Must be a quick learner and open to learning new technology.

Experience applying agile practices to solution delivery.

Must be team-oriented and have excellent oral and written communication skills.

Must be a self-starter to understand existing bottlenecks and come up with innovative solutions.

Experience and good understanding of GCP, DevOps, AI/ML and GEN AI.




AI – ML Engineer with GCP Experience position is based in Dearborn, MI. A great opportunity to experience the corporate environment leading personal career growth.




Resume Submittal Instructions: Interested/qualified candidates should email their word formatted resumes to Vasavi Konda – vasavi.konda(.@)stgit.com and/or contact @(Two-Four-Eight) Seven- One-Two – Six-Seven-Two-Five (@248.712.6725). In the subject line of the email please include: First and Last Name AI – ML Engineer with GCP Experience.




For more information about STG, please visit us at www.stgit.com.




Sincerely,

Vasavi Konda| Recruiting Specialist

“Opportunities don't happen, you create them.”

Systems Technology Group (STG)

3001 W. Big Beaver Road, Suite 500

Troy, Michigan 48084

Phone: @(Two-Four-Eight) Seven- One-Two – Six-Seven-Two-Five: @248.712.6725(O)

Email: vasavi.konda(.@)stgit.com

Show more "
AWS ML Ops/Dev Ops Engineer,Mindteck,United States,2024-08-21,https://www.linkedin.com/jobs/view/aws-ml-ops-dev-ops-engineer-at-mindteck-4006587041?position=38&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=9q4whQILnb4YkwKuuDlNEg%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Title: AWS DevOps/MLOps Engineer Job Description:

CLIENT is seeking a talented AWS DevOps/MLOps Lead to develop platforms for big data and data science on AWS. As models, apps, and data pipelines are created and operationalized, the bigdata and data science team requires engineers with understanding of cloud native technology to develop, manage, automate, and facilitate the operational capabilities of the big data and data science team.

Required Skills


Experience in AWS system and network architecture design, with specific focus on AWS Sagemaker and AWS ECS
Experience developing and maintaining Client systems built with open source tools
Experience developing with containers and Kubernetes in cloud computing environments
Experience with one or more data-oriented workflow orchestration frameworks (KubeFlow, Airflow, Argo)
Design the data pipelines and engineering infrastructure to support our clients' enterprise machine learning systems at scale
Develop and deploy scalable tools and services for our clients to handle machine learning training and inference
Support model development, with an emphasis on auditability, versioning, and data security
Experience with data security and privacy solutions such as Denodo, Protegrity, and synthetic data generation.
Ability to develop applications using Python and deploy to AWS Lambda and API Gateway
Ability to develop Jenkins pipelines using the groovy scripting.
. Good understanding in testing frameworks like Py/Test.
Ability to work with AWS services like S3, DynamoDB, Glue, Redshift and RDS
Proficient understanding of Git and version control systems
Familiarity with continuous integration and continuous deployment.
Develop the terraform modules to deploy the standard infrastructure.
Ability to develop the deployment pipelines using the Jenkins, XL Release
Experience in Python boto3 to automate the cloud operations.
Experience in documenting technical solutions and solution diagrams
Good understanding of the simple python applications which can be deployed as a docker container.
Experiencing in creating workflows using AWS step functions
Create the docker images using the custom python libraries.


Required Skills:


AWS (experience mandatory): S3, KMS, IAM, EC2, ECS, BATCH, ECR, Lambda, Data Sync, EFS, IAM Roles, Policies, Cloud Trail, Cost Explorer, ACM, AWS Route53, SNS, SQS, ELB, CloudWatch, Lambda and VPC, Service Catalog
Automation (experience mandatory): Terraform, Python (boto3), serverless, Jenkins (Groovy), NodeJs
Bigdata (Knowledge): Redshift, DynamoDB, Databricks, Glue, and Athena.
Data science (Experience): Sagemaker, Athena, Glue, DynamoDB, Databricks, MWAA (Airflow),
DevOps (experience mandatory): Python, Terraform, Jenkins, GitHub, Make files, and Shell scripting.
Data Virtualization (Knowledge) : Denodo
Data Security (Knowledge): Protegrity


Qualifications


Bachelor's degree from a reputed institution/university.
10+ years of building end-to-end systems as a Platform Engineer, Client DevOps Engineer, or Data Engineer.
4+ Years of experience in python, groovy, and java programming.
Experience working in the SCRUM Environment.
Show more "
Senior DevOps Engineer with MLOps - W2,"eTek IT Services, Inc.",United States,2024-08-26,https://www.linkedin.com/jobs/view/senior-devops-engineer-with-mlops-w2-at-etek-it-services-inc-4008117167?position=39&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=Kkgvdd0eRWIxyR5E27y8VQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Required SkillsDevOps; MLOps; Azure / AzureML; CI/CD; Jenkins, GitHub; Tensorflow; PyTorch; Machine Learning Models

Additional Skills

Job Description

Job Title:DevOps / MLOps Engineer Lead

Location:San Antonio, TX | Findlay, OH

Education Level:Bachelor’s Degree

Position Summary

We are seeking an experienced and highly motivated DevOps / MLOps Engineer Lead to join our dynamic Data Science and AI team. In this role, you will be pivotal in creating and maintaining robust, scalable, and efficient CI/CD pipelines for our machine learning models and data processing workflows. You will collaborate with cross-functional teams to streamline and automate the end-to-end deployment processes, ensuring our AI/ML initiatives are delivered with high quality and speed.

Key Responsibilities


Develop and Implement CI/CD Pipelines: Design, build, and maintain continuous integration and deployment pipelines for machine learning models and data processing workflows.
Automation and Orchestration: Develop and continuously improve automation solutions to enable teams to build and deploy code efficiently and consistently.
Promote DevSecOps Principles: Foster a DevSecOps culture across the Analytics & Innovation organization, ensuring security is integrated into the development process.
Lifecycle Streamlining: Streamline the data science and development lifecycles by identifying and resolving pain points and productivity barriers.
Collaboration: Work closely with data scientists, data engineers, and software developers to integrate and deploy machine learning models into production.
Monitoring and Troubleshooting: Implement monitoring and logging solutions to ensure the health and performance of deployed models and systems, and troubleshoot issues as they arise.
Security and Compliance: Ensure the security and compliance of data and infrastructure, adhering to industry best practices and regulatory requirements.
Documentation: Maintain comprehensive documentation of systems, processes, and workflows to facilitate knowledge sharing and collaboration.


Requirements

Desired Skills and Experience


Education: Bachelor’s Degree in Computer Science, Engineering, or a related field.
Experience: 5+ years of experience in DevOps, MLOps, or a related field.
Azure DevOps and AzureML experience.


Technical Expertise


Proficiency in cloud platforms (AWS, Azure, GCP) and containerization technologies (Docker, Kubernetes).
Strong programming skills in Python, Bash, PowerShell or other scripting languages.
Experience with infrastructure as code (Terraform, ARM).


Tool Proficiency


Familiarity with CI/CD tools (Jenkins, GitHub Actions, ADO Pipelines).
Knowledge of machine learning frameworks (TensorFlow, PyTorch) and data processing tools (Apache Spark, Airflow).
Problem-Solving: Excellent problem-solving and analytical skills, with a focus on delivering practical and efficient solutions.


Preferred Experiences


Advanced Analytics Tools: Experience with advanced analytics tools and methodologies, including monitoring and logging solutions (Azure Monitor, Prometheus, Grafana).
Agile Methodologies: Experience working in Agile development environments.
Communication: Strong verbal and written communication skills, capable of articulating complex technical concepts to both technical and non-technical stakeholders.
Team Collaboration: A collaborative mindset with a track record of working effectively within diverse teams.


Other Qualifications


AZ-400 DevOps Engineer Certification is desired.
Experience with Data Science and Machine Learning teams is desired.


Skills: devops,machine learning,azure,ci,cd
Show more "
AI/ML Engineer,ClearML,United States,2024-08-30,https://www.linkedin.com/jobs/view/ai-ml-engineer-at-clearml-4013332556?position=40&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=3R4XyR4iDBJ%2Fv29d4fnsdA%3D%3D&trk=public_jobs_jserp-result_search-card,"AI/ML Engineer 




ClearML is a unified, open source platform for continuous machine learning (ML), trusted by forward-thinking Data Scientists, ML Engineers, DevOps, and decision makers at leading Fortune 500, enterprises, academia, and innovative start-ups worldwide. We enable customers to build continuous ML workflows -- from experiment management and orchestration through data management and scheduling, followed by provisioning and serving -- to achieve the fastest time to ML production, fastest time to value, and increased performance.




We help data science, ML engineering, and DevOps teams easily develop, orchestrate, and automate ML workflows at scale. Our frictionless, unified, end-to-end MLOps suite enables users and customers to focus on developing their ML code and automation, ensuring their work is reproducible and scalable. ClearML is trusted by brands such as NVIDIA, Philips, Samsung, Hyundai and Bosch. 




As a member of the machine Learning team at ClearML, you will have the opportunity to contribute to our mission of transforming the ML space -- bridging software, machine learning, and automation . Our team is focused on improving the customer experience of our MLOPs platform and tools through data-driven insights, research, and development.




By joining ClearML, you will have the chance to be a part of a dynamic team that is dedicated to advancing the field of machine learning and helping ML engineers train high-performing, fair, and reproducible models.




Overview:

We are an open source end-to-end AI platform, built by developers for developers.




We're looking for a Machine Learning engineer to join our growing team. In this role, you will collaborate across our development and product teams and will have a chance to collaborate with our MLOPs experts working in the exciting areas of machine learning, deep learning, NLP, computer vision and DevOps. 




The ideal candidate will be an ML Engineer who wants to learn how to analyze large amounts of raw information to find patterns and use them to optimize model performance. You will work with our team to learn to build ML/DL data pipelines to extract valuable business insights, analyze trends, and help us make better decisions.




We expect you to be highly analytical with a knack for analysis, math, and statistics, and a passion for machine learning and research. Critical thinking and problem-solving skills are also required.




Responsibilities:

Build scalable infrastructure for training, evaluating, and serving models
Research and analyze valuable data sources and automate processes
Perform preprocessing of structured and unstructured data
Review large amounts of information to discover trends and patterns
Create predictive models and machine-learning algorithms
Organize and present information using data visualization techniques
Develop and suggest solutions and strategies to business challenges
Work together with engineering and product development teams to build and test ML/DL solutions stretching the entire spectrum of ML operationalization from data processing, model training, hyperparameter tuning, deployment, and model management.




Requirements:

 2+ years of machine learning experience to include building production-grade machine learning models in industry /research settings
Strong programming skills in Python and deep-learning  
Experience building end-to-end scalable ML infrastructure with on-premise / cloud platforms.
Familiar with Kubernetes and/or similar container system
Strong math and analytical skills, with business acumen
Strong communication and presentation skills
Good problem-solving abilities
BSc or BA degree in Computer Science, Engineering or other relevant area; graduate degree in Data Science or other quantitative field is preferred
Show more "
AI/ML Engineer,Digital Janet,United States,2024-08-08,https://www.linkedin.com/jobs/view/ai-ml-engineer-at-digital-janet-3996509493?position=41&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=F8wmaQA74PZmqcQC61llnw%3D%3D&trk=public_jobs_jserp-result_search-card,"Jd

Key Responsibilities:


Participate in developing Generative AI & Traditional AI Platform Capabilities on enterprise on-prem and cloud platforms.
Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI, Azure ML)
Collaborating with Data scientist to optimize the scoring pipeline.
Building automation capabilities to deploy ML Models and LLM Models on the enterprise on-prem platform and cloud platform.
Build and Deploy capabilities for automating model scoring/Inferencing of ML models and LLMs.
Build and Deploy capabilities for data pipeline deployment standardization and model consumption by multiple LOBs.
Collaborate with product owners, devOps team, data scientists, support teams to define and drive end to end model scoring pipelines.
Participate in day-to-day standups for platform capability build.
Provide SME guidance for data science teams on software engineering principles, model deployments, platform capabilities.
Drive AI use case delivery end to end collaborating with Data scientists, Data Engineers, LOB Technology using standardized platform processes and capabilities.
Support Production Issues partnering with production support.


Key Requirements


5+ years of Python experience
5+ years of big data experience needed (Big Query, Hadoop)
3 years of experience in AIML area (MLOps)
2+ years of experience in developing APIs using Python/FastAPI.
1+ year of Document AI, Agent Builder/GCP search/conversation / Dialogflow – Nice to have
Good to have 1+year of experience in LLM, Generative AI (developing capabilities or dev/ops)
Good to have Experience in developing of API on GCP/Azure/API Gateways
Good to have 1+year of experience in Vector Database, Model Development would be added benefit.
Show more "
Machine Learning Engineer: 24-02363,"Akraya, Inc.",United States,2024-08-23,https://www.linkedin.com/jobs/view/machine-learning-engineer-24-02363-at-akraya-inc-4006002107?position=42&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=Ay9mIVYb2fRybjrfiYap6A%3D%3D&trk=public_jobs_jserp-result_search-card,"Primary Skills: Machine Learning, AWS, Python

Contract Type: W2 Only

Duration: 11+ Months with possible extension

Location: Arlington, VA/ Boston, MA ()

Pay Range: $58 - $65 per hour

#LP

Job Responsibilities


Own the development and operationalization of solutions deployed in production.
Work across multiple teams to integrate our solutions with products owned by our partners.
Design model experimentation processes and frameworks in synergy with our scientists.
Help the team grow and cultivate best practices in software development, MLOps, and experimentation.


JOB REQUIREMENTS:


AWS development experience, Build within AWS products.
Bachelors in programming or similar (statistics, mathematical degrees on top of that would be a plus)
Minimum 5 years of ML experience in the role previous.
High preference for anyone with a previous ML title.
Familiarity with Tensorflow and the statistics scripting language R.


ABOUT AKRAYA

Akraya is an award-winning IT staffing firm consistently recognized for our commitment to excellence and a thriving work environment. Most recently, we were recognized Inc's Best Workplaces 2024 and Silicon Valley's Best Places to Work by the San Francisco Business Journal (2024) and Glassdoor's Best Places to Work (2023 & 2022)!

Industry Leaders in IT Staffing

As staffing solutions providers for Fortune 100 companies, Akraya's industry recognitions solidify our leadership position in the IT staffing space. We don't just connect you with great jobs, we connect you with a workplace that inspires!

Join Akraya Today!

Let us lead you to your dream career and experience the Akraya difference. Browse our open positions and join our team!


Show more "
Machine Learning Engineer,Ema Unlimited,United States,2024-08-30,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-ema-unlimited-4013294923?position=43&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=tnk%2FLyLfJwk5gDgzN8XzTQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Who We Are

At Ema, we are pioneering the next generation of AI technology to empower enterprise employees to unleash their creativity and productivity. Our proprietary AI, Ema, handles repetitive tasks, allowing humans to focus on what truly matters. Founded by former executives from Google, Coinbase, and Okta, and backed by leading investors like Accel Partners and Silicon Valley luminaries such as Sheryl Sandberg and Jerry Yang, we are a well-funded, dynamic company based in Silicon Valley and Bangalore.Our team is a blend of exceptional talent from top tech companies and prestigious universities, creating a powerhouse of innovation and expertise. We thrive in a hybrid work environment, fostering collaboration and creativity.




Who You Are

We are seeking passionate Machine Learning Engineers who are eager to solve complex problems and transform theoretical concepts into practical, scalable solutions. Whether you hold a Ph.D. in Computer Science or have deep industry experience, if you have a background in large language models, information retrieval, or natural language processing, we want you to join our mission-driven startup.




Your Role

As a Machine Learning Engineer at Ema, you will:

Innovate and Implement: Develop and deploy cutting-edge machine learning models for NLP, retrieval, ranking, and more, using advanced algorithms like Transformer-based models and reinforcement learning.
Data-Driven Development: Lead the processing and analysis of large datasets, informing model development and ensuring robust performance.
Lifecycle Management: Engage in every stage of ML model development, from problem definition to deployment, ensuring quality and effectiveness through A/B testing and automated validation.
Collaborate and Communicate: Work closely with technical and non-technical stakeholders to ensure understanding and adoption of ML solutions.




What We Value

Education & Experience: A Master’s or Ph.D. in a relevant field, or significant industry experience in deploying machine learning models.
Technical Skills: Proficiency in Python, TensorFlow, or PyTorch, and experience with large-scale data systems and MLOps principles.
Industry Insight: Stay abreast of the latest trends in machine learning and AI, applying this knowledge to drive innovation.
Problem Solving & Collaboration: Exceptional problem-solving skills and the ability to work collaboratively in a fast-paced, startup environment.




Why Ema?

Impactful Work: At Ema, your work directly contributes to our mission of transforming enterprise productivity. We value shipped impact over theoretical perfection, encouraging innovation and efficiency.
Collaborative Culture: We believe in breaking down silos. Every engineer codes, contributes to product management, and participates in the full lifecycle of product development.
Continuous Growth: Embrace the 10x engineering mindset by continuously improving and scaling your efforts. We support learning and growth, enabling you to challenge the status quo and pursue ambitious goals.
Supportive Environment: Our team thrives on collaboration and knowledge sharing. We encourage feedback, mentorship, and the sharing of expertise to drive team success.




Join us at Ema and be part of a team that is not just building AI, but redefining what it means to work in the AI-first era. If you are ready to make a significant impact and grow with us, we want to hear from you.

Show more "
Senior MLOps Engineer,Intapp,United States,2024-08-21,https://www.linkedin.com/jobs/view/senior-mlops-engineer-at-intapp-4004711641?position=44&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=zeraFKrmbXfdlXc6lyqg%2Fw%3D%3D&trk=public_jobs_jserp-result_search-card,"As a Senior MLOps Engineer, you will play a crucial role in enabling applied AI. Your main focus will be on the design, build, and maintenance of secure, scalable and efficient ML Platform, with a platform as a product mindset, that automates the end-to-end life-cycle for traditional ML models and LLM models, as part of the Cloud platforms engineering (CPE) directorate. CPE’s mission is to enable our Engineering teams to ship value faster, securely, efficiently and reliably.

In this role, you will:




Design and implement robust MLOps and LLMOps pipelines to automate and optimize machine learning model training, testing, deployment, and scaling.


Collaborate with data scientists and software engineers to ensure operational criteria are met before deployment.


Maintain and enhance continuous integration (CI) and continuous deployment (CD) environments for machine learning systems.


Develop tools to improve visibility into the system's operation and to facilitate rapid troubleshooting and debugging.


Foster a culture of continuous improvement by incorporating feedback and lessons learned into future ML deployments.


Lead initiatives to increase the resilience and scalability of ML systems.



What you need:




Bachelor’s degree in computer science, Engineering, Statistics, or a related field.


Experience in software development or data engineering, with at least 3 years focused on MLOps or similar roles.


Proven track record in designing and deploying scalable machine learning systems in production.


Strong programming skills in Python and experience with ML frameworks and tools (e.g., TensorFlow, PyTorch, MLFlow, MetaFlow, vLLM, Kubeflow, Jupyter notebook, Azure ML Studio, Amazon Sagemaker, Apache Spark, Apache Flink).


Expertise in containerization technologies (e.g., Docker, Kubernetes) and automation tools (e.g., Jenkins, GitLab CI).


Excellent problem-solving skills and the ability to work independently or as part of a team.



Bonus if you have:




Experience with data governance and ensuring compliance with data security regulations.


Familiarity with performance tuning of big data technologies.


LLM Model development



What you will gain at Intapp:

Our culture at Intapp emphasizes accountability, responsibility, and growth. We support each other in a positive, open atmosphere that fosters creativity, approachability, and teamwork. We’re committed to creating a modern work environment that’s connected yet flexible, supporting both professional success and work-life balance. In return for your passion, commitment, and collaborative approach, we offer:




Competitive base salary plus variable compensation and equity


Generous paid parental leave, including adoptive leave


Traditional comprehensive benefits, plus:



Generous Paid Time Off


Tuition reimbursement plan


Family Formation benefit offered by Carrot


Wellness programs and benefits provided by Modern Health


Paid volunteer time off and donation matching for the causes you care about


Opportunities for personal growth and professional development supported by a community of talented professionals


An open, collaborative environment where your background and contributions are valued


Experience at a growing public company where you can make an impact and achieve your goals


Open offices and kitchens stocked with beverages and snacks


Intapp provides equal employment opportunities to all qualified applicants and will make hiring decisions without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristic protected by federal, state or local laws. All offers are contingent upon passing a criminal history and other background checks if applicable to the position.

Please note: Intapp will not hire through text message, social media, or email alone. We will never extend a job offer unless you have been contacted directly by an Intapp recruiter and have participated in the interview process which will generally consist of 3 or more virtual or in person meetings. Please note that Intapp only uses company email addresses, which contain “@intapp.com” or “@dealcloud.com” to communicate with candidates via email. Intapp will never ask for financial information of any kind or for any payment during the job application process. We post all legitimate job openings on the Intapp Career Site at https://www.intapp.com/working-at-intapp/. If you believe you were a victim of such a scam, you may contact your local authorities. Intapp is not responsible for any claims, losses, damages, or expenses resulting from scammers.
Show more "
Machine Learning Operations Engineer,Flagship Pioneering,United States,2024-08-30,https://www.linkedin.com/jobs/view/machine-learning-operations-engineer-at-flagship-pioneering-3996315706?position=45&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=M%2Fq8WCli%2BdEM3M%2BqLMp%2FzA%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Summary

Flagship Labs 97 Inc. (FL97) is a privately held, early-stage technology company pioneering the application of artificial intelligence to transform every aspect of the scientific method. FL97 is backed by Flagship Pioneering, which brings the courage, long-term vision, and resources needed to realize unreasonable results. Join our mission-driven team and contribute to the future of science.

Our Life Sciences effort is leveraging AI and high-throughput automation for valuable therapeutic discovery and development across biological modalities.

At FL97, we are uniquely cross-functional and collaborative. We are actively reimagining the way teams work together and communicate. Therefore, we seek individuals with an inclusive mindset and a diversity of thought. Our teams thrive in unstructured and creative environments. All voices are heard because we know that experience comes in many forms, skills are transferable, and passion goes a long way.

If this sounds like an environment you’d love to work in, even if you only have some of the experience listed below, please apply.

The Role

FL97 is seeking a dedicated and skilled Machine Learning Operations Engineer (ML Ops) to join our team. This role will focus on building and maintaining private cloud infrastructure used to train large scale machine learning models. You will be part of a dynamic, cross-functional team responsible for developing new artificial intelligence models that push the frontier of science. Working closely with biologists, bioinformaticians, software developers, machine learning scientists and automation engineers, you will contribute to the development of ML models for a range of scientific applications. The ideal candidate has a strong background in machine learning, as well as either experience in biotech industry or a record of scientific achievement, with a focus on MLOps, model training, and deployment.

Responsibilities include:


Developing and managing a large cloud-based cluster with >100 GPUs in support of FL 97 machine learning scientists (help make the GPUs go brr).
Implementing MLOps practices to streamline the model development and deployment process.
Collaborating with cross-functional teams to integrate ML models into the data pipelines for our labs.
Implementing rigorous testing, documentation, and performance benchmarking.


Qualifications:


Master's degree (or equivalent experience) in computer science, computational biology, physics, or other quantitative disciplines
Experience managing Kubernetes clusters with kubectl on cloud-based GPU infrastructure such as Lamda Labs or AWS
Experience with MLOps practices and tools including version control, automated testing, and CI/CD
Experience with GPU accelerated ML computing in at least pytorch and robust experience in the Python data science ecosystem.
Knowledge of additional high-performance libraries like Accelerate, DeepSpeed, etc is a plus
Experience with managing large, containerized multi-GPU training runs for large language models on Ray, Dask, Kueue, or Slurm or similar libraries.


Working at FL97, you would have access to advanced technology in the areas of:


AI experimental design and simulation
Automated custom instrumentation
Generative molecular and material design


More About Flagship Pioneering

Flagship Pioneering is a biotechnology company that invents and builds platform companies, each with the potential for multiple products that transform human health or sustainability. Since its launch in 2000, Flagship has originated and fostered more than 100 scientific ventures, resulting in more than $90 billion in aggregate value. Many of the companies Flagship has founded have addressed humanity’s most urgent challenges: vaccinating billions of people against COVID-19, curing intractable diseases, improving human health, preempting illness, and feeding the world by improving the resiliency and sustainability of agriculture. Flagship has been recognized twice on FORTUNE’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies, and has been twice named to Fast Company’s annual list of the World’s Most Innovative Companies. Learn more about Flagship at www.flagshippioneering.com.

Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

At Flagship, we recognize there is no perfect candidate. If you have some of the experience listed above but not all, please apply anyway. Experience comes in many forms, skills are transferable, and passion goes a long way. We are dedicated to building diverse and inclusive teams and look forward to learning more about your unique background.

Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.
Show more "
System Administrator/Machine Learning Operations (MLOps),ABSC (Absolute Business Solutions Corp.),United States,2024-08-30,https://www.linkedin.com/jobs/view/system-administrator-machine-learning-operations-mlops-at-absc-absolute-business-solutions-corp-3942394601?position=46&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=4r4TWWy09qmcs7paLpkivw%3D%3D&trk=public_jobs_jserp-result_search-card,"ABSC is seeking a System Administrator/Machine Learning Operations (MLOps) supporting DIA-NMEC under the DOMEX Data Discovery Platform (D3P) Modernization program which falls under our 10 year DOMEX Technology Platform (DTP) contract. Have impact as part of a mission-focused, solutions oriented, and adaptive team that values innovation, collaboration, and professional development. Come support a major program advancing the state of the art in Machine Learning Operations (MLOps) supporting mission-focused big data analytics and predictive analytics. You will be delivering cutting edge machine learning capabilities to advance national security objectives, swiftly produce and analyze results, and disseminate findings with actionable intelligence insights. While most work is conducted on-site at our client location in Bethesda, MD, we offer a flexible schedule and, occasionally, some tasks may be performed remotely. Percentage of remote work will vary based on client requirements / deliverables. If you are ready to join ABSC in enabling the NMEC to provide critical and unique capabilities to the Intelligence Community, apply today!

Responsibilities include, but are not limited to:


Work closely with a cross-functional agile application development team of data scientists, data engineers, software developers, system engineers, researchers, and data analysts working on the design, building, and optimization of a complex, resource demanding application.
Support multiple simultaneous work packages and take open-ended or high-level guidance, independently and collaboratively provide first-class infrastructure and deployment solutions.
Bring your mix of intellectual curiosity, quantitative acumen, and customer-focus to identify novel approaches to improve the performance of system function through system administration optimizations in partnership with a highly qualified, highly motivated team.


Experience and education required for this role:


Bachelor's degree or equivalent with a minimum of eight years of experience in a related field. Two additional years of experience may be substituted for the bachelor's degree.
4+ years of experience in system administration preferably in a cloud native environment
Must have an active TS/SCI clearance and willing and able to obtain a CI Polygraph.
Strong experience with Amazon Web Services (AWS/C2S)
Strong experience with Linux OS system administration
Strong experience application and infrastructure deployment, configuration, and maintenance
Proper prerequisites and ability to gain and maintain Privileged User Access (PUA) on the customer’s network
Experience maintaining hardware in compliance with security policy
Proficiency in one or more system administration scripting languages
Track record of active learning and creative problem solving
Ability to analyze and assess infrastructure and application deployment requirements and determine optimum, cost-effective solutions
Ability and desire to work in a fast-paced environment learning new skills quickly as needed


Desired experience includes:


A significant share of your experience in direct support of military or intelligence community customers, demonstrating progressive technical development and mission-focused outcomes
Experience supporting data team operations
An interest in data science, data engineering, or machine learning
Experience system administration in an on-prem, air-gapped environment
Experience configuring and optimizing storage solutions
Experience configuring and optimizing networking solutions
Experience or a desire to learn
Deploying and maintaining Kubernetes applications
DevOps and MLOPs
IT automation (e.g., SaltStack, Ansible, Terraform, etc.)
Familiarity utilizing virtualization and distributed file systems, such as Hadoop (or similar distributed file systems) in development and production environments;
Familiarity using git, svn, JIRA, or other version control and program management technologies;
Amazon Web Services (AWS) professional certifications;
Familiarity with NVIDIA GPUs and NVIDIA GPU appliances


Who we are:

Since 2001, Absolute Business Solutions Corp (ABSC) has delivered professional services and technology-enabled solutions to federal, defense, and intelligence customers through a mission-first ethos resulting in agile, innovative, and technology-advancing capabilities.

ABSC’s employees – including software developers, multi-disciplined intelligence analysts, technology protection engineers, program support personnel, and specialists in cloud, data science, AI/ML, and cyber – diligently support their customers, address their challenges, and stay ahead of technological or operational impacts to the mission.

ABSC stands ready to deliver the next generation of programs, personnel, and solutions to help advance our federal government customers’ driving innovation, agility, and security across all mission areas.

Some of our benefits include:


4 weeks of PTO plus 11 Federal Holidays
Retirement Planning – 401k Fully Vested with Matching
Tuition Assistance Program – Have Student Loans? Let us help!
Annual Health and Wellness Allowance
Career Development –5,250 USD Annually Towards Education and Training
Volunteer Time Off – Spend time directly supporting a charity of your choice
Charitable Match – ABSC matches (set amount) an employee’s donation to a qualifying charity
Paid Parental Leave –Employees receive 3 weeks of paid parental leave at 100% pay
Referral Program – We pay for internal and external referrals!
Performance Bonus


Apply to join our team today! We are always looking to grow our team - if you know someone who is seeking a new career opportunity, please share this job opening with them! ABSC offers generous external referral bonuses. You don’t need to be an employee to benefit from our Referral Program!

*ABSC is a proud V3, Virginia Values Vets, member which recognizes our commitment to hiring Veterans. If you are a veteran, please be sure to include that in your application. Thank you! *

Absolute Business Solutions Corp. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Equal Employment Opportunity Posters https://www.dol.gov/agencies/ofccp/posters; If you’d like to view a copy of the company’s affirmative action plan or policy statement, please email HR@absc-us.com.

If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact ABSC Human Resources at 703-437-3000 or HR@absc-us.com. Please do not call about the status of your job application if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a response.
Show more "
Hybrid Work - Need Lead ML Ops Engineer in Irving TX or Richardson TX,Steneral Consulting,United States,2024-08-15,https://www.linkedin.com/jobs/view/hybrid-work-need-lead-ml-ops-engineer-in-irving-tx-or-richardson-tx-at-steneral-consulting-4000465814?position=47&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=E%2BK0LAIC2evomispH%2B7ISg%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Title - Lead ML Ops Engineer

Type - Hybrid

Location - Irving, TX or Richardson, TX

Should be local

Description -

Required


Python & SQL for scripting & programming
Experience in ML & Ops Engineering
Open source (but they use Python on Azure Kubernetes)
ML Ops
Kubernetes
Public Cloud
Support the deployment of ML/AI pipelines on the platform.
Enable functionality to support analysis, model optimization, statistical testing, model versioning, deployment and monitoring of model and data.
Ability to translate functionality into scalable, tested, and configurable platform architecture and software.
Establish strong software engineering principles for development in Python on the Azure/Google Cloud Platform.
Deliver features aligned to enterprise AutoML, Feature Engineering, and MLOPS capability.
Innovative thinking and great communication skills.
Strong ownership of deliverables, with design decisions aligned to scale and industry best practices.
Provide technical leadership and mentorship to a team of machine learning engineers. Collaborate with cross-functional teams to align ML initiatives with overall business goals.
Design, implement, and optimize machine learning algorithms and models. Stay abreast of the latest advancements in ML research and apply them to solve complex business problems.
Architect and implement scalable and efficient machine learning systems. Collaborate with software engineers to integrate ML models into production systems.
Work closely with data engineers to ensure the availability and quality of data for training and evaluation of machine learning models.
Develop strategies for deploying machine learning models at scale. Ensure models are integrated into production systems with high reliability and performance.
Design and conduct experiments to evaluate the performance of machine learning models. Iterate on models based on feedback and evolving business requirements.


Required Qualifications


6+ years of experience in analytics domains, and deep understanding of ML operationalization and lifecycle management.
5+ years of deploying and monitoring analytical assets in batch/real-time business processes.
5+ years of SQL & Python programming experience leveraging strong software development principles.
Experience in designing and developing AI applications and systems.
Experience with real-time and streaming technology (i.e. Azure Event Hubs, Azure Functions, Pub/Sub, Kafka, Spark Streaming etc.)
Experience with REST API/Microservice development using Python/Java.
Experience with deployment/scaling of apps on containerized environment (AKS and/or GKE)
Experience with Snowflake/BigQuery, Google Dataproc/Databricks or any big data frameworks on Spark
Experience with RDBMS and NoSQL Databases and hands-on query tuning/optimization.


Preferred Qualifications


Hands on experience in building solutions using cloud native services (Azure, GCP preferred)
Understanding of DevOps, Infrastructure as Code, automation for self service


Education


Required: Bachelor’s degree in computer science, Engineering, Statistics, Physics, Math, or related field or equivalent experience
Preferred: Master’s Degree or PhD with coursework focused on advanced algorithms, mathematics in computing, data structures, etc.
Show more "
MLOps Engineer,Stanford Health Care,United States,2024-08-07,https://www.linkedin.com/jobs/view/mlops-engineer-at-stanford-health-care-3996232820?position=48&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=bDyWzB8I2vgD50wOSv3GjA%3D%3D&trk=public_jobs_jserp-result_search-card,"1.0 FTE Full time Day - 08 Hour R2441639 Remote USA 108480039 TDS Data Science Innovation Technology & Digital Solutions

If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)

We are seeking a versatile DevOps Engineer with a strong foundation in full stack development to join our dynamic team. In addition to your expert-level DevOps skills, we are excited to see candidates who have hands-on experience in full stack development. As a DevOps Engineer at Stanford Healthcare, you'll play a crucial role in bridging the gap between development and operations, ensuring seamless integration, deployment, and automation of our systems. Your proficiency in both areas will empower you to architect solutions that not only optimize our infrastructure but also enhance the end-to-end development lifecycle. If you possess a deep understanding of coding, architecture, and deployment processes, coupled with your proven DevOps expertise, we encourage you to bring your unique perspective and skill set to our team. Your ability to collaborate, adapt, and innovate will contribute to the growth and success of both our DevOps practices and our broader development initiatives.

This is a Stanford Health Care job.

A Brief Overview

The MLOPs Engineer will play an integral role incorporating Artificial Intelligence (AI) within Stanford Health Care. The solutions will impact patient care, medical research, and operational services. This group is tasked to innovate, build, deploy and monitor production grade AI, machine learning (ML) and predictive algorithms into healthcare. The role will partner closely with lead researchers within the AI field and leaders across various clinical specialties and operations.

This role will report to the Infrastructure group and have a dotted line relationship to the Data Science team. The role will be responsible for maintaining cloud-based infrastructure as code repositories, maintaining infrastructure, deployment pipelines and designing the security landscape for the team and objects. The role will set the standards for the full SDLC of projects for the Data Science team.

Locations

Stanford Health Care

What You Will Do


Design, build and maintain scalable and robust infrastructure for AI/ML systems, including cloud-based environments, containerization and orchestration platforms.
Develop and implement CI/CD pipelines to automate the deployment, testing and monitoring of AI/ML models and applications.
Collaborate with data scientists, data engineers and software engineers to optimize model training, deployment and inference pipelines.
Monitor and troubleshoot AI/ML systems to ensure high availability, performance and reliability.
Maintain and monitor model training and inference pipelines across multi-cloud tenants especially around Large Language Models (LLMs).
Maintain Kubernetes pods, container registry and virtual machine image library and model registry
Monitor infrastructure utilization and costs pertaining to model training, inference and GPU utilization
Implement best practices for security, data privacy and compliance in AI/ML workflows and infrastructure.
Evaluate and integrate new tools, technologies and frameworks to improve the efficiency and effectiveness of our MLOps processes.
Mentor and provide technical guidance to junior members of the organization.
Stay up-to-date with the latest advancements and trends in MLOps, DevOps and cloud technologies and share them with the team.


Education Qualifications


Bachelor’s or higher degree in Computer Science, Engineering or a related field


Experience Qualifications


Three (3) or more years of directly related experience


Required Knowledge, Skills And Abilities


Proven experience as an MLOps Engineer.
Strong knowledge of cloud platforms such as AWS, Azure or Google Cloud and experience with infrastructure-as-code tools like Terraform or CloudFormation.
Proficiency in containerization technologies such as Docker and container orchestration platforms like Kubernetes.
Experience with CI/CD tools such as GitLab CI/CD, Github Actions or CiricleCI.
Solid programming skills in languages such as Python, Rust or Go and experience in scripting and automation.
Familiarity with machine learning frameworks and libraries such as PyTorch, Tensorflow and scikit-learn.
Deep understanding of DevOps principles, agile methodologies and software development lifecycle.
Strong problem-solving and trouble shooting skills, with the ability to analyze and resolve complex technical issues.
Excellent communication and collaboration skills with the ability to work effectively in cross-functional teams.


Physical Demands and Work Conditions

Blood Borne Pathogens


Category III - Tasks that involve NO exposure to blood, body fluids or tissues, and Category I tasks that are not a condition of employment


These Principles Apply To ALL Employees

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:


Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination


Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.

Base Pay Scale: Generally starting at $74.66 - $98.94 per hour

The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.
Show more "
Senior AI/ML Engineer,Artmac,United States,2024-08-19,https://www.linkedin.com/jobs/view/senior-ai-ml-engineer-at-artmac-4004531953?position=49&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=Sx8bWoPkpMa%2B6dj5Pv6zLQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Who We Are

Artmac Soft is a technology consulting and service-oriented IT company dedicated to providing innovative technology solutions and services to Customers.

Job Description

Job Title : Senior AI/ML Engineer

Job Type : W2 / C2C

Experience : 6-10 Years

Location : San Diego, California

Responsibilities


10+ years of industry experience, including 5+ years of experience with AIML modeling, MLOps, and model deployment.
Experience in AI System Development foundational model Lifecycle training, retrieval of Augmented Systems, and Model Evaluation.
Proficient in Large Language Models (LLMs) Architecture, creating targeted Instruction Datasets, and implementing Quantization and Inference Optimizations.
Capable of covering Problem Definition, Data Acquisition, and Full-cycle Deployment, utilizing tools like MLflow and cloud Platforms like AWS, Google Cloud, and Azure.
Proprietary Models like GPT-4 and Claude, Open-source Models like Llama and Mistral, are able to deliver high-performing, scalable, and cost-efficient AI solutions.
NLP libraries like NLTK, spaCy, GPT-3, BERT, and Hugging Face's Transformers create sophisticated natural language processing solutions.
Expert in AIML modeling, Python, AIML Infrastructure, model deployment, and MLOps
Experience working in Supply Chain, Operations, or a related field
End-to-end GenAI application experience
Knowledge in RAG, Prompt Engineering, LoRA, and other GenAI techniques
Ability to operate independently and lead without authority
Superb communication and interpersonal skills.


Technical Skills


Methodologies: Spiral, Agile, Waterfall, Lean.
Programming Language: C++, Python, Shell, SQL, R
IDE Tools: PyCharm, RStudio, Visual Studio Code, Jupyter Notebook, Google Collab, Navicat.
ML Frameworks: Transformers, Scikit-Learn, Keras, TensorFlow, PyTorch, ONNX, NLTK, OpenAI, long-chain, llama-index,kore.ai
DL Architectures: LLM, ANN, CNN, R-CNN, RNN, GRU, LSTM, Transformers, Attention Mechanism, Tokenisers, BERT, T5, Sentence Transformers, Foundational models
Packages: Pandas, NumPy, Spark, Matplotlib, SciPy
Cloud Technologies: AWS (EC2, S3, RDS, ECS, Lambda), Azure(VM, Functions, ACR, AKS), Digital Ocean, GCP, Paperspace
Database: MySQL, PostgreSQL, MongoDB, ChromaDB, Pinecone, SQLite
Web Frameworks and Web Servers/ Deployment: Fast API, Flask, Nginx, Gunicorn, Uvicorn, Docker, Kubernetes
Miscellaneous Tools and Technologies: JIRA, Auto Gluon, GitHub Actions, GitHub Issues, Datadog, MS Power BI, Postman, Locust, Stream lit, CUDA, cuDNN, TensorRT
Version Control: Git, GitHub, DVC (Data Version Control)
Operating Systems: Windows, Linux, Mac.


Qualifications


Industry experience 10+ years BSCS, 5+ years MS/PhD in Computer Science, Statistics, Applied Math, or a related field
Show more "
MLOps Engineer,Dice,United States,2024-08-29,https://www.linkedin.com/jobs/view/mlops-engineer-at-dice-4011018961?position=50&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=Wf0CjMRaSrk83f6zsflReA%3D%3D&trk=public_jobs_jserp-result_search-card,"Dice is the leading career destination for tech experts at every stage of their careers. Our client, Apex Systems, is seeking the following. Apply via Dice today!

Job#: 2043671

Job Description:

Job Title: MLOps Engineer

Job Location: Columbus, OH or Minnetonka, MN

Pay Range: $51/hr-$59/hr

Contract Length: 3 Months (Contract-to-Hire)

About Us:

We are a forward-thinking team within a large enterprise bank, deeply invested in leveraging machine learning and artificial intelligence to drive impactful business outcomes. Our team is responsible for ensuring the smooth, scalable and secure deployment of machine learning models into production, handling both real-time and batch processing workloads. We offer a unique opportunity to work closely with data scientists and engineers, focusing on large language models and cutting-edge MLOps practices.

Job Summary:

As an MLOps Engineer, you will be responsible for the end-to-end productionization and deployment of machine learning models at scale. You will work closely with data scientists to refine models and ensure they are optimized for production. Additionally, you will be responsible for maintaining and improving our MLOps infrastructure, automating deployment pipelines, and ensuring compliance with IT and security standards. You will play a critical role in image management, vulnerability remediation, and the deployment of ML models using modern infrastructure-as-code practices.

Key Responsibilities:


Vulnerability Remediation & Image Management:
Manage and update Docker images, ensuring they are secure and optimized.
Collaborate with data scientists to validate that models run effectively on updated images.
Address security vulnerabilities by updating and patching Docker images.
AWS & Terraform Expertise:
Deploy, manage, and scale AWS services (SageMaker, S3, Lambda) using Terraform.
Automate the spin-up and spin-down of AWS infrastructure using Terraform scripts.
Monitor and optimize AWS resources to ensure cost-effectiveness and efficiency.
DevOps & CI/CD Pipeline Management:
Design, implement, and maintain CI/CD pipelines in Azure DevOps (ADO).
Integrate CI/CD practices with model deployment processes, ensuring smooth productionization of ML models.
Strong experience with Git for code versioning and collaboration.
Model Productionization:
Participate in the end-to-end process of productionizing machine learning models, from model deployment to monitoring and maintaining their performance.
Work with large language models, focusing on implementing near real-time and batch inferences.
Address data drift and model drift in production environments.
Collaboration & Continuous Learning:
Work closely with data scientists, DevOps engineers, and other MLOps professionals to ensure seamless integration and deployment of ML models.
Stay updated on the latest trends and technologies in MLOps, especially related to AWS and Docker.


Required Skills & Qualifications:


Python: Deep expertise in Python for scripting and automation.
AWS: Strong experience with AWS services, particularly SageMaker, S3, and Lambda.
Terraform: Proficiency in using Terraform for infrastructure-as-code on AWS.
Docker: Extensive experience with Docker, including building, managing, and securing Docker images.
Linux: Strong command-line skills in Linux, especially for Docker and system management.
DevOps Experience: Azure DevOps (ADO): Significant experience in setting up and managing CI/CD pipelines in ADO.
Git: Proficient in using Git for version control and collaboration.
Additional DevOps Tools: Experience with Jenkins or other CI/CD tools is a plus.
Experience & Education: 4 years of experience in combination of MLOps/DevOps/Data Engineering; Bachelors degree in Computer Science, Engineering, or a related discipline.


Preferred Qualifications:


Experience with large language models and productionizing ML models in a cloud environment.
Exposure to near real-time inference systems and batch processing in ML.
Familiarity with data drift and model drift management.


EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.
Show more "
Machine Learning Operations Associate,Upbring,United States,2024-08-29,https://www.linkedin.com/jobs/view/machine-learning-operations-associate-at-upbring-4012884147?position=51&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=BDQJBc0aKiUqtVP9CY6CKw%3D%3D&trk=public_jobs_jserp-result_search-card,"About Upbring

At Upbring, we are servants on a mission to break the cycle of child abuse. We are warriors, brave as the thousands of Texas Children and families we serve. We stand up for those who can’t speak for themselves. We are a family who values innovation, empathy, patience, understanding and trustworthiness.

What You'll Do

The Machine Learning Operations (MLOps) Associate position uses statistical analysis and machine learning to extract meaningful insights from data and develop, deploy, and maintain sophisticated predictive models. The ML Operations Associate excels in engineering models for real-world application and systems administration support. The MLOps Associate develops data products and executes projects; collaborates with internal stakeholders and external technology partners to develop predictive models; possesses a keen eye for business and strategic value; and approaches the position’s responsibilities with humility, curiosity, and passion for Upbring’s mission.

Our Upbring staff members are servant-leaders in the pursuit of breaking the cycle of child abuse and empowering others to do the same through example while embodying our core values: We are Warriors. We are Servants. We are Family.

Responsibilities

We Are Warriors | We Set the Standards for Child Welfare

Work Standards


Collaborate in the design, implementation, and validation of predictive models and advanced machine learning algorithms to solve specific business challenges.
Provide backup and support for all machine learning models and data products.
Develop comprehensive data processing pipelines, from data collection and cleaning to analysis and modeling, ensuring data quality and accessibility.
Perform exploratory data analysis to uncover hidden patterns, correlations, and insights from complex datasets.
Deploy machine learning models into production environments, ensuring they are scalable, maintainable, and integrate seamlessly with existing systems.
Monitor model performance and make adjustments as needed to maintain accuracy and effectiveness.
Other duties and special projects as assigned.


Communication


Assist in proposal development, RFP responses, and other business and fundraising development efforts.
Communicate complex technical concepts to non-technical stakeholders.
Develop strong data analytics and data science capabilities in a cross-functional manner, focusing on customer view of specialty hub services as well as general operations.


We Are Servants| We Help Others

Teamwork


Collaborate with cross-functional teams to understand business needs and translate them into technical specifications for model development.
Partner with appropriate departments to consult on data flows, data uses, predictive models, and reports.
Collaborate with the team to drive successful implementation and adoption of analytics solutions and models.
Assist the team in building Upbring-wide capabilities by delivering technology expertise in data modeling, data science, predictive analytics, and tools.


We Are Family | We Are Passionate & Compassionate

Building Relationships


Develop and maintain strong working relationships with Senior Leadership, program management, and internal and external customers to ensure program/department needs, goals, and objectives meet the expectations of the requestor or project with the highest quality
Exhibit professional behavior and a positive attitude with both internal and external parties that reflect positively on Upbring and is consistent with Upbring’s policies and practices
Actively participate in exhibiting cultural awareness and sensitivity when interacting with children, parent(s)/guardian(s), staff, and the community


Qualifications

Minimum Qualifications


A bachelor’s degree in computer science, Engineering, Data Science OR a related field; or a combination of education and experience in lieu of degree.
Proficiency in programming languages Python, R, or Java
Proficiency with machine learning frameworks, such as TensorFlow, PyTorch, Keras or scikit-learn.
Proven experience with predictive modeling, feature engineering, and ML model design, training, validation and evaluation techniques
Excellent analytical, critical thinking and problem-solving skills
Strong statistical analysis and mathematical modeling skills
Self-starter with the ability and discipline to work autonomously
Mission-driven professional with a passion for making a positive social impact
Proficiency with Microsoft Word, Excel, and Outlook


Preferred Qualifications


Five (5) years of applicable work experience, or an Advanced Degree in Computer Science, Engineering, Data Science, OR a related field.
Advanced proficiency with Microsoft Excel
Proficiency with SQL
Experience with deploying and managing ML models in production environments
Proficiency with cloud platforms (e.g., Azure, AWS, Google Cloud) and containerization technologies (e.g., Docker, Kubernetes).
Knowledge of data engineering best practices, including version control (e.g. Git), testing, and deployment strategies
Experience working in or with the nonprofit industry, child welfare, social and family services


Perks at Upbring


Competitive PTO & paid holidays
Health, dental, vision insurance & more!
403(b) Plan
Employee Assistance Program
24/7 access to telemedicine and counseling services
Discounted Gym Memberships


Diversity. Equity. Inclusion. Belonging

We are a diverse and inclusive Organization that recognizes our strength is in the efforts of our selfless warriors. Honoring and recognizing the value and dignity of all individuals is the cornerstone of our agency. The more diverse the individuals, thought processes and lived experiences, the greater the opportunity is to combine unique perspectives to make a greater impact. Our trust, respect, and appreciation for one another is demonstrated through our communication, celebration of progress and relentless effort to be at our best TO FULLFILL OUR MISSION OF BREAKING THE CYCLE OF CHILD ABUSE.

Upbring is an Equal Employment Opportunity/AA Employer and does not discriminate on the basis of race, color, ancestry, religion, age, sex, sexual orientation, gender, gender expression, gender identity, pregnancy, marital status, national origin, genetic information, physical or mental disability, military or veteran status.
Show more "
Sr. ML Ops Engineer,Greylock,United States,2024-08-26,https://www.linkedin.com/jobs/view/sr-ml-ops-engineer-at-greylock-3981009560?position=53&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=kDiNF8JYkA%2B%2F7MSH4rwYKA%3D%3D&trk=public_jobs_jserp-result_search-card,"One of our growth-stage investments is looking to hire a Sr ML Ops Engineer with 8+ years overall experience and 4+ years industry experience building associated MLOps infrastructure, pipelines, and (observability) tooling. Priority given to candidates with strong foundations in DevOps/SRE (AWS, Kubernetes, Docker, CI/CD, etc.) who have a solid understanding of deep learning (ideally, transformer) architectures. Prior startup experience is a plus!




Application Process:

We will contact anyone who looks like a potential match--requesting to schedule an initial call with you immediately. Otherwise, a follow-up email will not be sent until a match is identified with one of our investments (due to the high volume of applicants we typically receive from our job postings).




Greylock Talent:

There are no fees associated with any of the work we do. As a value-add investor, we provide free candidate referrals/introductions to all of our active investments (one of the many services we provide).

Show more "
Senior Software Engineer (AI Infrastructure/MLOps),Acceler8 Talent,United States,2024-08-28,https://www.linkedin.com/jobs/view/senior-software-engineer-ai-infrastructure-mlops-at-acceler8-talent-4010135137?position=54&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=0dTdly36aGiV8vGGNDpD3w%3D%3D&trk=public_jobs_jserp-result_search-card,"Senior Software Engineer (AI Infrastructure / MLOps)




Introduction: We are seeking a Senior Software Engineer (AI Infrastructure / MLOps) to join our team. This role offers a unique opportunity to work on cutting-edge MLOps technologies and develop large-scale web applications for data-centric AI.




About the Company: Our team comprises MIT PhDs who have worked at leading tech companies and research institutions. We specialize in developing tools that enhance the quality of datasets, enabling data scientists and engineers across various industries to diagnose and fix issues effectively.




About the Role: you will be responsible for developing and maintaining our user-friendly web app built on advanced ML algorithms. You'll orchestrate cloud infrastructure for data ingestion, model training, serving, and data analysis. This role is ideal for those who enjoy tackling complex data and AI systems problems and want to have a significant impact by building systems from the ground up.




What We Can Offer You:

Competitive salary and equity offering for certain roles
Annual travel stipend to support work-life balance and cultural empathy
Premium health insurance, including dental and vision
Professional development stipend for ongoing learning in ML and software
Opportunity to work with a dynamic and friendly team of MIT graduates




Key Responsibilities:

Orchestrate cloud infrastructure to support SaaS/VPC data and machine learning pipelines
Design, develop, deploy, and maintain software from the ground up using a modern tech stack
Collaborate with other engineers to build and maintain large-scale systems
Establish a strong engineering culture across the company




Relevant Keywords: AWS, Docker, Kubernetes, databases, DevOps, AI, machine learning, cloud infrastructure, MLOps, data-centric AI

Show more "
"Software Architect - MLOps, Python",Natera,United States,2024-08-28,https://www.linkedin.com/jobs/view/software-architect-mlops-python-at-natera-3990132846?position=55&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=6KgkKcqaGprg67r6ePlvuA%3D%3D&trk=public_jobs_jserp-result_search-card,"Title: Software Architect

Location: Austin, TX or San Carlos, CA (or Remote within the USA)

Company Overview: Natera is a global leader in cell-free DNA testing, specializing in oncology, women’s health, and organ health. Our mission is to empower personalized healthcare decisions through innovative technology. At Natera, we revolutionize the world of medicine by developing genetic products that combine cutting-edge technology and science. On top of that we want to accelerate the breakthroughs in research to improve care by offering our unique genomic and clinical data.

Position Summary: As a Software Architect, you will play a pivotal role in designing and implementing robust, scalable, and efficient solutions that bridge the gap between business requirements and technical capabilities. Your responsibilities include:


Solution Design and Integration:
Collaborate with cross-functional teams (including data scientists, engineers, and business stakeholders) to understand project requirements.
Translate business needs into strategic architecture solutions, ensuring alignment with industry regulations and best practices.
Integrate cloud-native tools from major hyperscalers (e.g., AWS, GCP) and machine learning frameworks.
Data Warehousing and ETL:
Design and develop data warehouses and data marts.
Create ETL processes for data integration and transformation.
Ensure data quality and integrity.
Infrastructure and Tooling:
Plan, provide, and maintain infrastructure for data storage, processing, and analytics.
Enable efficient data pipelines and real-time data processing.
Implement security measures for data protection.
AIOps and MLOps Expertise:
Implement best practices from Software Engineering, DevOps, MLOps, and LLMOps.
Drive automation and orchestration of AI/ML operations.
Optimize model deployment, monitoring, and maintenance processes.
Technical Skills:
Proficiency in programming languages (e.g., Python, SQL).
Deep understanding of cloud services (AWS, GCP) and data storage solutions (e.g., S3, BigQuery).
Familiarity with data modeling, data lakes, and data governance.
Experience with data visualization tools (e.g., Tableau, Power BI).
Proficiency in programming languages (e.g., Python, R, Scala).
Deep understanding of cloud services (AWS, GCP) and containerization (Docker, Kubernetes).
Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch).
Experience with CI/CD pipelines and version control (Git).
Qualifications:
Bachelor’s or Master’s degree in Computer Science, Engineering, or related field.
Minimum 7 years of experience in data architecture, solution design, or related roles.
Strong analytical and problem-solving skills.
Excellent communication and collaboration abilities.
Proven track record in AIOps and MLOps implementation.

The pay range is listed and actual compensation packages are based on a wide array of factors unique to each candidate, including but not limited to skill set, years & depth of experience, certifications and specific office location. This may differ in other locations due to cost of labor considerations.

Remote USA

$117,900—$147,400 USD

OUR OPPORTUNITY

Natera™ is a global leader in cell-free DNA (cfDNA) testing, dedicated to oncology, women’s health, and organ health. Our aim is to make personalized genetic testing and diagnostics part of the standard of care to protect health and enable earlier and more targeted interventions that lead to longer, healthier lives.

The Natera team consists of highly dedicated statisticians, geneticists, doctors, laboratory scientists, business professionals, software engineers and many other professionals from world-class institutions, who care deeply for our work and each other. When you join Natera, you’ll work hard and grow quickly. Working alongside the elite of the industry, you’ll be stretched and challenged, and take pride in being part of a company that is changing the landscape of genetic disease management.

What We Offer

Competitive Benefits - Employee benefits include comprehensive medical, dental, vision, life and disability plans for eligible employees and their dependents. Additionally, Natera employees and their immediate families receive free testing in addition to fertility care benefits. Other benefits include pregnancy and baby bonding leave, 401k benefits, commuter benefits and much more. We also offer a generous employee referral program!

For more information, visit www.natera.com.

Natera is proud to be an Equal Opportunity Employer. We are committed to ensuring a diverse and inclusive workplace environment, and welcome people of different backgrounds, experiences, abilities and perspectives. Inclusive collaboration benefits our employees, our community and our patients, and is critical to our mission of changing the management of disease worldwide.

All qualified applicants are encouraged to apply, and will be considered without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, disability or any other legally protected status. We also consider qualified applicants regardless of criminal histories, consistent with applicable laws.

If you are based in California, we encourage you to read this important information for California residents.

Link: https://www.natera.com/notice-of-data-collection-california-residents/

Please be advised that Natera will reach out to candidates with a @natera.com email domain ONLY. Email communications from all other domain names are not from Natera or its employees and are fraudulent. Natera does not request interviews via text messages and does not ask for personal information until a candidate has engaged with the company and has spoken to a recruiter and the hiring team. Natera takes cyber crimes seriously, and will collaborate with law enforcement authorities to prosecute any related cyber crimes.

For More Information


BBB announcement on job scams
FBI Cyber Crime resource page
Show more "
? Job Title/Role MLOPS Architect (Machine Learning / AI Architect),Resource Logistics Inc.,United States,2024-08-02,https://www.linkedin.com/jobs/view/%3F-job-title-role%09mlops-architect-machine-learning-ai-architect-at-resource-logistics-inc-3990945794?position=56&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=CQSGrneGtUdK8N6nNkFzuA%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Title/Role MLOPS Clienthitect (Machine Learning / AI Clienthitect) Experience level required (Years) 10+ Mandatory required skills AWS, Python, Airflow, Kedro, or Luigi Preferred/Desired skills Hadoop, Spark, or similar frameworks. Experience with graph databases a plus Please share the Detailed Job Description


Designing Cloud Clienthitecture :
As an AWS Cloud Clienthitect, youll be responsible for designing cloud Clienthitectures, preferably on AWS, Clienture, or multi-cloud environments.
Your Clienthitecture design should enable seamless scalability, flexibility, and efficient resource utilization for MLOps implementations.
Data Pipeline Design :
Develop data taxonomy and data pipeline designs to ensure efficient data management, processing, and utilization across the AI/Client platform.
These pipelines are critical for ingesting, transforming, and serving data to machine learning models.
MLOps Implementation :
Collaborate with data scientists, engineers, and DevOps teams to implement MLOps best practices.
This involves setting up continuous integration and continuous deployment (CI/CD) pipelines for model training, deployment, and monitoring.
Infrastructure as Code (IaC) :
Use tools like AWS CloudFormation or Terraform to define and provision infrastructure resources.
Infrastructure as Code allows you to manage your cloud resources programmatically, ensuring consistency and reproducibility.
Security and Compliance :
Ensure that the MLOps Clienthitecture adheres to security best practices and compliance requirements.
Implement access controls, encryption, and monitoring to protect sensitive data and models.
Performance Optimization :
Optimize cloud resources for cost-effectiveness and performance.
Consider factors like auto-scaling, load balancing, and efficient use of compute resources.
Monitoring and Troubleshooting :
Set up monitoring and alerting for the MLOps infrastructure.
Be prepared to troubleshoot issues related to infrastructure, data pipelines, and model deployments.
Collaboration and Communication :
Work closely with cross-functional teams, including data scientists, software engineers, and business stakeholders.
Effective communication is essential to align technical decisions with business goals.
Activities

Strong experience in Python

"" Experience in data product development, analytical models, and model governance

"" Experience with AI workflow management tools such as Airflow, Kedro, or Luigi

"" Exposure statistical modeling, machine learning algorithms, and predictive analytics.

"" Highly structured and organized work planning skills

"" Strong understanding of the AI development lifecycle and Agile practices

"" Proficiency in big data technologies like Hadoop, Spark, or similar frameworks. Experience with graph databases a plus.

"" Extensive Experience in working with cloud computing platforms - AWS

"" Proven track record of delivering data products in environments with strict adherence to security and model governance standards. Experience 7.5-12 Years Skill (Primary) Microsoft-Clienture Analytics-Clienture Client Job Family Clienthitecture / Design Band TP Job Senior Technical Clienthitect Requisition Source Proactive SR Other Requirement St. Louis, MO Remote allowed

Flexibility on rate for another $5

Mandatory Exp - AWS, Python, Airflow, Kedro, or Luigi

Submit along with Skill matrix on these skills
Show more "
ML Ops Engineer (Hybrid),Zendar,United States,2024-08-13,https://www.linkedin.com/jobs/view/ml-ops-engineer-hybrid-at-zendar-4000549650?position=57&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=I3EiTbDEmtQS95BhBCTqvQ%3D%3D&trk=public_jobs_jserp-result_search-card,"To apply to this position, click here: https://zendar.breezy.hr/p/b1c3b0470f85-ml-ops-engineer?source=www.zendar.io&popup=true

Who We Are

Zendar is creating a high-resolution radar imaging system that has resolution similar to lidar, allowing cars to see the driving world in all conditions and at long distances to travel at high speeds. We want to change the role of radar in the Advanced driving assist (ADAS) sensor stack and demonstrate that radars can take on many of the functions of lidar at a much lower cost. Zendar has pioneered a software-defined radar technology which fuses data streams from multiple sensors to build a more accurate scene and utilizes machine learning to understand the environment. All of this works in an embedded AI processor with tight latency and performance guarantees to deliver reliable sensing and perception.

Zendar was founded in the San Francisco Bay area, at the very heart of one of the most advanced regions in the development of advanced vehicles technologies. We also have offices in Germany and France.

Zendar has a diverse and dynamic team of electrical, mechanical, RF, algorithms and software engineers with a deep background in sensing technology. Zendar is backed by Tier-1 VCs, has raised more than $50M in funding and has established strong partnerships with industry leaders. Our team has more than doubled in number over the last year as our technology has gained traction in the automotive and agriculture industries.

The Role

Radar has long been a neglected sensor in the autonomy field. At Zendar, we have applied state-of-the-art ML techniques to show that radar can be just as capable as a camera in perceiving the environment. Our ML team’s mission is to unlock the capability of radar and show that camera + radar is the right combination of sensors for autonomy.

To help us achieve this mission, we are establishing an MLOps Team to support and power the productivity of our perception efforts. In this role, you will be second hire on the MLOps Team at Zendar, working alongside the team lead, a small team of machine learning researchers and engineers, and Zendar’s existing DevOps team.

As a core member of the MLOps team, you’ll be working on:


A robust and reliable data lake for our proprietary training and evaluation data
A high-capacity batch job system for ad-hoc compute workloads
A dynamically-scalable and GPU-accelerated compute cluster for model training
Whatever else we need to scale up to the next level!


As An MLOps Engineer At Zendar, You Will


Work with our rich store of proprietary radar, lidar, and camera data, and take ownership of our associated ETL / data transformation pipelines
Take meaningful ownership over the responsibilities mentioned above, continually working to improve and expand the systems we already have in place
Collaborate with the Machine Learning / Radar Perception team and the DevOps team to build out new capabilities and scale our existing capabilities to new heights


What We Look For


3+ years of hands-on experience with cloud computing platforms (AWS, GCP, or Azure)
Broad knowledge of data engineering and ML ops tools (Airflow, kubernetes, docker)
Strong engineering skills in Python and SQL
Excellent communication and organizational skills
Eagerness to challenge yourself, learn new skills, and adapt as the company grows.*


Bonus Points


Experience with the modern Deep Learning stack (PyTorch, Tensorflow, CUDA)
Prior experience with automotive perception tasks (semantic segmentation, object detection, tracking, route planning)
Knowledge of the physics of radar devices and electromagnetic theory


What We Have To Offer


Opportunity to make an impact at a young, venture-backed company in an emerging market
Competitive salary ranging from $125-165k annually depending on experience
Performance based Bonus
Benefits including medical, dental, and vision insurance, flexible PTO, and equity
Hybrid work model: in office 3 days per week, the rest… work from wherever!
Daily catered lunch and a stocked fridge (when working in the Berkeley, CA office)
Zendar participates in E-Verify.


Zendar is committed to creating a diverse environment where talented people come to do their best work. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.
Show more "
Machine Learning Engineer,"ShiftCode Analytics, Inc.",United States,2024-08-11,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-shiftcode-analytics-inc-3997472708?position=58&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=kIU5anS0iOKJ9wNyStxhkw%3D%3D&trk=public_jobs_jserp-result_search-card,"MACHINE LEARNING ENGINEER

LONG TERM CONTRACT

NEW YORK CITY, NEW YORK

100% REMOTE ROLE

VISA- USC/GC ONLY

Requirement

Machine Learning Engineer with over 5 years of experience and expertise in building Client models with Python.

MLOps in an Azure environment and model management processes.

Experience in working with Azure Data Lake and Snowflake environments, as well as healthcare experience.
Show more "
AWS ML Ops/DevOps Engineer,US Tech Solutions,United States,2024-08-14,https://www.linkedin.com/jobs/view/aws-ml-ops-devops-engineer-at-us-tech-solutions-3999542532?position=59&pageNum=0&refId=ralRxiq5AfJpsl7lHmuR%2Bg%3D%3D&trackingId=1ZaAvyQ8OOZLIYJYaH2l7g%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Description:

Client is seeking a talented AWS DevOps/MLOps Lead to develop platforms for big data and data science on AWS. As models, apps, and data pipelines are created and operationalized, the bigdata and data science team requires engineers with understanding of cloud native technology to develop, manage, automate, and facilitate the operational capabilities of the big data and data science team.

Required Skills:


Experience in AWS system and network architecture design, with specific focus on AWS Sagemaker and AWS ECS
Experience developing and maintaining Client systems built with open source tools
Experience developing with containers and Kubernetes in cloud computing environments
Experience with one or more data-oriented workflow orchestration frameworks (KubeFlow, Airflow, Argo)
Design the data pipelines and engineering infrastructure to support our clients’ enterprise machine learning systems at scale
Develop and deploy scalable tools and services for our clients to handle machine learning training and inference
Support model development, with an emphasis on auditability, versioning, and data security
Experience with data security and privacy solutions such as Denodo, Protegrity, and synthetic data generation.
Ability to develop applications using Python and deploy to AWS Lambda and API Gateway
Ability to develop Jenkins pipelines using the groovy scripting.
. Good understanding in testing frameworks like Py/Test.
Ability to work with AWS services like S3, DynamoDB, Glue, Redshift and RDS
Proficient understanding of Git and version control systems
Familiarity with continuous integration and continuous deployment.
Develop the terraform modules to deploy the standard infrastructure.
Ability to develop the deployment pipelines using the Jenkins, XL Release
Experience in Python boto3 to automate the cloud operations.
Experience in documenting technical solutions and solution diagrams
Good understanding of the simple python applications which can be deployed as a docker container.
Experiencing in creating workflows using AWS step functions
Create the docker images using the custom python libraries.


Required Skills:


AWS (experience mandatory): S3, KMS, IAM, EC2, ECS, BATCH, ECR, Lambda, Data Sync, EFS, IAM Roles, Policies, Cloud Trail, Cost Explorer, ACM, AWS Route53, SNS, SQS, ELB, CloudWatch, Lambda and VPC, Service Catalog
Automation (experience mandatory): Terraform, Python (boto3), serverless, Jenkins (Groovy), NodeJs
Bigdata (Knowledge): Redshift, DynamoDB, Databricks, Glue, and Athena.
Data science (Experience): Sagemaker, Athena, Glue, DynamoDB, Databricks, MWAA (Airflow),
DevOps (experience mandatory): Python, Terraform, Jenkins, GitHub, Make files, and Shell scripting.
Data Virtualization (Knowledge) : Denodo
Data Security (Knowledge): Protegrity


Qualifications:


Bachelor’s degree from a reputed institution/university.
10+ years of building end-to-end systems as a Platform Engineer, Client DevOps Engineer, or Data Engineer.
4+ Years of experience in python, groovy, and java programming.


About US Tech Solutions:

US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com.

US Tech Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Show more "
Data Engineer with MLOps,Syntricate Technologies,United States,2024-08-07,https://www.linkedin.com/jobs/view/data-engineer-with-mlops-at-syntricate-technologies-3995025645?position=1&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=9hlKoqqQp6svhDs9TUm%2BsA%3D%3D&trk=public_jobs_jserp-result_search-card,"Hi,

Hope you are doing well

Number of position : 3

Only Full Time

Full-time

I, Shakib (i3 infotek) would like to share a job opportunity as Data Engineer with MLOps based in Irving, TX (Onsite) location for a Full-time position.

In case, if you are not comfortable with this location, please share your preference with contact details for further requirements

Kindly find the JD below and let me know if you are available for the same.

Job tittle – Data Engineer with MLOps

Duration: Full-time

Location – Irving, TX (Onsite)

Job Description

Roles & Responsibilities


Minimum 5 years of work experience in building data pipelines using Python, PySpark, DJango.
Hands-On experience in working with Python and related packages (like NumPy, pandas etc.) to load and scrap the data.
Hands-on experience with at least one of the tools the Hadoop eco-system (HDFS, AWS Glue, MapReduce, Yarn, Hive, Pig, Impala, Spark, Kafka).
Working experience on Relational/Non-relational databases and familiarity with data model concepts
Working exposure in blending as part of larger scrum team and understanding of related scrum ceremonies
Working knowledge of Unix/Linux.
Knowledge of cloud platforms (e.g., AWS, Azure, GCP)


Please reply me with your updated resume and required details:

Full Name

Best number to reach you:

Work Authorization/Visa Status

Current Location:

Expected Compensation

Best time to call you:

Waiting for your earliest response

Sincerely,

Mohd Shakib

Sr. Technical Recruiter Direct: (phone number removed)
Show more "
Staff MLOps Engineer,Bazaarvoice,United States,2024-08-29,https://www.linkedin.com/jobs/view/staff-mlops-engineer-at-bazaarvoice-4013219155?position=2&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=LCOuA7Pj4siZDpj%2FFLJA9Q%3D%3D&trk=public_jobs_jserp-result_search-card,"We’re looking for a Staff MLOps Engineer to join our Machine Learning team. You’ll work closely with a team of engineers to create a platform on top of that data that will be leveraged by virtually every other product and system we have built or will build in the future. You’ll be responsible for building and maintaining the infrastructure and tooling that enables our ML Engineers and Data Scientists to focus on model development and feature engineering.

Key Responsibilities


Design, implement, and maintain robust MLOps platforms and tooling for both batch and streaming ML pipelines.
Develop and manage monitoring and observability solutions for ML systems.
Lead DevOps practices, including CI/CD pipelines and Infrastructure as Code (IaC).
Architect and implement cloud-based solutions on AWS.
Collaborate with ML Engineers and Data Scientists to develop, train, and deploy machine learning models.
Engage in feature engineering and model optimization to improve ML system performance.
Participate in the full ML lifecycle, from data preparation to model deployment and monitoring.
Optimize and refactor existing systems for improved performance and reliability.
Drive technical initiatives and best practices in both MLOps and ML Engineering.



Required Skills And Experience


Strong Python Proficiency: Excellent skills for developing, deploying, and maintaining our machine learning systems.
Language Versatility: Experience with statically-typed or JVM languages. Willingness to learn Scala is highly desirable.
Cloud Engineering Skills: Extensive experience with Cloud Platforms & Services, ideally AWS (e.g., Lambda, ECS, ECR, CloudWatch, MSK, SNS, SQS).
Infrastructure as Code: Proficiency in IaC, particularly Terraform.
Kubernetes Expertise: Strong hands-on experience with managing clusters and deploying services.
Data Orchestration: Experience with ML orchestration tools (e.g., Flyte, Airflow, Kubeflow, Luigi, or Prefect).
CI/CD: Expertise in pipelines, especially GitHub Actions and Jenkins.
Networking: Knowledge of concepts and implementation.
Streaming: Experience with Kafka and other streaming technologies.
ML Monitoring: Familiarity with observability tools (e.g., Arize AI, Weights and Biases).
NLP/LLMs: Experience with NLP, LLMs, and RAG systems in production, or strong desire to learn.
CLI & Shell Scripting: Proficiency in scripting and command-line tools.
APIs: Experience with deploying and managing production APIs.
Software Engineering Best-Practices: Knowledge of industry standards and practices.



Preferred Qualifications


AWS AI Services: Hands-on experience with AWS SageMaker and/or AWS Bedrock.
Data Processing: Experience with high-volume, unstructured data processing.
ML Applications: Familiarity with NLP, Computer Vision, and traditional ML applications.
System Migration: Previous work in refactoring and migrating complex systems.
AWS Certification: AWS Solution Architect Professional or Associate certification.
Advanced Degree: Master's degree in ML / AI / Computer Science.



Personal Qualities


Passionate about building developer-friendly platforms and tools.
Thrives in a terminal-based development environment.
Enthusiastic about creating production-grade, robust, reliable, and performant systems.
Not afraid to dive into and improve complex existing solutions.
Team player who works well with ML Engineers, Data Scientists, and management.
Strong technical mentoring skills.
Excellent problem-solving and communication skills.



Show more "
AI ML,BLYK Engineering Services,United States,2024-08-16,https://www.linkedin.com/jobs/view/ai-ml-at-blyk-engineering-services-4000272672?position=3&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=kBPKw8g0jWZyVmAEWBmSNQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Role: AI ML

Location: San Diego, CA

SEMI-CONDUCTOR DOMAIN EXPERIENCE IS MUST




 

Description

As a Machine Learning Engineer on our core Software AIML team, you will be at the forefront of designing and developing cutting-edge GenAI applications.

You will be working closely with business stakeholders and data engineers to communicate AI recommendations to senior management.

 

Key Responsibilities:

Engage deeply with business teams to identify opportunities and translate the needs into innovative and practical AIML solutions

Design, build, and deploy state of the art AIML models to solve complex business problems

Understand key performance levers and metrics to highlight AIML solution operational issues and drive improvement

Foster close collaboration with engineers and infrastructure partners to implement robust and scalable solutions

Communicate the results and insights effectively to partners and senior leaders, providing clear and actionable recommendations

Stay updated with the latest trends, technologies, and best practices in AI and GenAI and data engineering

Regularly research and present new ideas to improve the team's technical capabilities

 

Minimum Qualifications:

Industry experience 10+ years BSCS, 5+ years MS/PhD in Computer Science, Statistics, Applied Math, or a related field

Preferred Qualifications:

Expert in AIML modeling, Python, AIML Infrastructure, model deployment and MLOps

Experience working in Supply Chain, Operations, or a related field

End to end GenAI application experience

Knowledge in RAG, Prompt Engineering, LoRA and other GenAI techniques

Ability to operate independently and lead without authority

Superb communication and interpersonal skills

 

AI SW Engineer Skills/Experience:

Experience in AI System Development foundational model Lifecycle training, retrieval of Augmented Systems, and Model Evaluation.

Proficient in Large Language Models (LLMs) Architecture, creating targeted Instruction Datasets, and implementing Quantization and Inference Optimizations.

Capable of covering Problem Definition, Data Acquisition, and Full-cycle Deployment, utilizing tools like MLflow, Cloud Platforms like AWS, Google Cloud, Azure.

Proprietary Models like GPT-4 and Claude, Open-source Models like Llama and Mistral, able to deliver high-performing, scalable, and cost-efficient AI solutions.

NLP libraries like NLTK, spaCy, GPT-3, BERT, and Hugging Face's Transformers to create sophisticated natural language processing solutions.

 

TECHNICAL SKILLS:

Methodologies: Spiral, Agile, Waterfall, Lean

Programming Language: C++, Python, Shell, SQL, R

IDE Tools: PyCharm, RStudio, Visual Studio Code, Jupyter Notebook, Google Collab, Navicat

ML Frameworks: Transformers, Scikit-Learn, Keras, TensorFlow, PyTorch, ONNX, NLTK, OpenAI, langchain,

llama-index,kore.ai

DL Architectures: LLM, ANN, CNN, R-CNN, RNN, GRU, LSTM, Transformers, Attention Mechanism, Tokenisers,

BERT, T5, Sentence Transformers, Foundational models

Packages: Pandas, NumPy, Spark, Matplotlib, SciPy

Cloud Technologies: AWS (EC2, S3, RDS, ECS, Lambda), Azure(VM, Functions, ACR, AKS), Digital Ocean, GCP, Paperspace

Database: MySQL, PostgreSQL, MongoDB, Chroma DB, Pinecone, SQLite

Web Frameworks and Web Servers/ Deployment:

Fast API, Flask, Nginx, Gunicorn, Uvicorn, Docker, Kubernetes

Miscellaneous Tools and Technologies:

JIRA, Auto Gluon, GitHub Actions, GitHub Issues, Datadog, MS Power BI, Postman, Locust, Stream lit, CUDA, cuDNN, TensorRT

Version Control: Git, GitHub, DVC (Data Version Control)

Operating Systems: Windows, Linux, Mac

 







LAVANYA KUMARI KAKARLA

LEAD RECRUITER

Call: +1(816) 754 1498

Email: lkumari@blykengineering.com 

Show more "
Machine Learning Operations Engineer ( ML Ops),IT Associates,United States,2024-08-29,https://www.linkedin.com/jobs/view/machine-learning-operations-engineer-ml-ops-at-it-associates-4012856745?position=4&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=blkycvb64tXgWxhExNeJmw%3D%3D&trk=public_jobs_jserp-result_search-card,"MLOps Engineer




Local to MI or willing to relocate
12+ months contract
Hybrid - 1-2 days/week in the office and 3-4 days work from home.
Immediate hire
Azure experience is a must. Azure Container Apps
Strong DevOps Practices and Tools exp. Red Hat Linux, Jenkins ( Building Jenkins Instances) , Ansible Playbooks for automation
Problem Solving




**Responsibilities: **




Design, implement, and maintain end-to-end machine learning pipelines for model training, validation, and deployment.
Collaborate with data scientists, software engineers, and DevOps engineers to integrate machine learning models into production systems.
Optimize model performance and scalability by leveraging cloud computing resources and distributed computing techniques.
Implement monitoring and logging solutions to track model performance, data quality, and system health in production.
Manage model versioning, experimentation, and reproducibility using version control systems and experiment tracking tools.
Stay up-to-date with the latest trends and technologies in machine learning, cloud computing, and software engineering, and incorporate them into the MLOps workflow.
Provide technical guidance and mentorship to junior team members on best practices for MLOps.




**Qualifications: **




Bachelor's degree or higher in computer science, engineering, mathematics, or related field.
Strong programming skills in languages such as Python, Java, or Scala.
Proven experience as an MLOps Engineer, specifically with Azure ML and related Azure technologies specially Azure Container Apps experience.
Good experience with containerization technologies such as Docker and orchestration tools like Kubernetes.
Proficiency in automation tools like Ansible playbooks, Jenkins (Building and configuring Jenkins instances from scratch) , Docker compose, Artifactory, etc.
Strong Knowledge of DevOps practices and tools for continuous integration, continuous deployment (CI/CD), and infrastructure as code (IaC).
Red Hat Linux ( RPM based) experience highly preferred.
Experience working in Air-Gapped environment highly preferred.
Experience with version control systems such as Git and collaboration tools like GitLab or GitHub.
Excellent problem-solving skills and ability to work in a fast-paced, collaborative environment.
Strong communication skills and ability to effectively communicate technical concepts to non-technical stakeholders.
Certification in cloud computing (e.g., AWS Certified Machine Learning – Specialty, Google Professional Machine Learning Engineer) is a plus
Knowledge of software engineering best practices such as test-driven development (TDD) and code reviews.
Experience with Rstudio/POSIT connect, RapidMiner

Show more "
Data Scientist,HatchPros,United States,2024-08-23,https://www.linkedin.com/jobs/view/data-scientist-at-hatchpros-4008677090?position=5&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=NK4w2Nge9aq9MEc6nwBQ7A%3D%3D&trk=public_jobs_jserp-result_search-card,"Video

REmote

USC or GC

central or eastern time zone only

Pricing experience

Education


Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, Mathematics, or a related field.


Experience


Exploratory Data Analysis (EDA):
Proficiency in performing EDA to understand data characteristics and identify patterns, trends, and anomalies.
Experience in data cleaning, data preprocessing, and dealing with missing or inconsistent data.
Machine Learning Model Building:
Proven experience in developing, training, and validating machine learning models for various applications.
Strong understanding of supervised and unsupervised learning algorithms, including regression, classification, clustering, and dimensionality reduction.
Experience in time series forecasting, anomaly detection, and natural language processing is a plus.
Programming Skills:
Proficiency in Python programming, with a deep understanding of data structures, algorithms, and object-oriented programming.
Experience with Python-based data science and machine learning libraries such as NumPy, Pandas, Scikit-learn, TensorFlow, Keras, and PyTorch.
Experience with SQL for database querying and data manipulation.
Feature Engineering:
Expertise in creating new features from raw data to improve model performance.
Knowledge of feature selection techniques to reduce dimensionality and prevent overfitting.
Data Visualization:
Ability to create insightful and interactive visualizations to communicate data findings and model results.
Proficiency with data visualization tools such as Matplotlib, Seaborn, Plotly, or Tableau.


Preferred Experience


Experience with deep learning techniques and frameworks such as TensorFlow and PyTorch.
Familiarity with MLOps practices and tools for continuous integration, delivery, and monitoring of machine learning models.
Previous experience in industries such as safety, compliance, or engineering is a plus.
Show more "
Senior ML Ops Engineer,Fractal,United States,2024-08-30,https://www.linkedin.com/jobs/view/senior-ml-ops-engineer-at-fractal-4012349494?position=6&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=b91kw4%2FXh%2B61l%2BS4MBBimQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Senior ML Ops Engineer




Fractal Analytics is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better. We believe that a true Fractalite empowers imagination with intelligence. And that it will be such Fractalites that will continue to build the company for the next 100 years.




Please visit Fractal | Intelligence for Imagination for more information about Fractal.

Role Overview

We seek an innovative and forward-thinking ML Ops Engineer specializing in Model Development. This role is designed for someone who thrives on the intersection of technical excellence and strategic insight and is capable of navigating the complexities of machine learning models while coordinating the Model Deployment with data scientists. You will be part of a dynamic team tasked with designing and implementing scalable, efficient, and reliable model training and evaluation processes.




Responsibilities

Collaborate closely with clients to deeply understand their business challenges, translating these into actionable business problems that machine learning models can solve.
Focus on Model Development and Deployment coordination with data scientists for designing and implementing scalable, efficient, and reliable model training and evaluation processes.
Implement CI/CD pipelines for machine learning models using tools like AWS.
Code Pipeline /AWS Cloud formation / Terraform. Enabling seamless deployment and integration into production systems.
Automate the build, testing, and deployment processes to ensure smooth and efficient delivery of updated models.
Implement monitoring solutions to track the performance and behavior of deployed models in real-time.
Set up alerts and notifications to proactively identify issues, such as model degradation or data drift, and take appropriate actions.
Optimize the performance and cost efficiency of machine learning workflows on AWS Sagemaker.
Fine-tune the infrastructure settings, explore autoscaling capabilities, and utilize spot instances for cost-effective model training and inference.
Work alongside cross-functional teams to identify, assess, and mitigate risks associated with model performance and compliance, ensuring alignment with business objectives and regulatory requirements.
Develop processes for continuous monitoring and performance testing of models, identifying opportunities for improvement and innovation within the ML Ops ecosystem.




Qualifications

Bachelor’s / Master’s degree in Engineering, Economics/Statistics, or equivalent field.
Minimum of 8+ years of relevant ML Ops experience in building robust machine learning pipelines in production.
Industry domain experience within insurance, healthcare, financial services, or a related area is strongly preferred.
Hands-on experience in deploying and managing containerized applications using Kubernetes and Docker for scalable and resilient infrastructure in ML Ops environments.
Understanding of ML gateway and load balancing.
Understanding of machine learning lifecycle, model building process, ability to build model implementation pipelines, model evaluation , drift detection, etc.
Experience with Kafka for efficient data streaming and real-time data processing in distributed systems.
Data monitoring tools such as DataDog or similar technology
Knowledge of working with Vertex AI
Experience in setting up and managing Continuous Integration and Continuous Deployment (CI/CD) pipelines, automating testing, deployment, and monitoring processes in MLOps and DevOps workflows.
Git, Control M, ETL experience,
Proficiency in programming languages such as Python, R, or Scala, essential for scripting and automation in MLOps workflows.
Understanding of NLP Models.




Other Requirements

Ability to be present at the client office for at least 4 days a week.
Openness to travel up to 25% of the time to meet business needs.




Pay

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Fractal, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is: $110,000 - $160,000. In addition, for the current performance period, you may be eligible for a discretionary bonus.

Benefits

As a full-time employee of the company or as an hourly employee working more than 30 hours per week, you will be eligible to participate in the health, dental, vision, life insurance, and disability plans in accordance with the plan documents, which may be amended from time to time. You will be eligible for benefits on the first day of employment with the Company. In addition, you are eligible to participate in the Company 401(k) Plan after 30 days of employment, in accordance with the applicable plan terms. The Company provides for 11 paid holidays and 12 weeks of Parental Leave. We also follow a “free time” PTO policy, allowing you the flexibility to take time needed for either sick time or vacation.

Fractal provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

Show more "
MLOps Engineer – Model Risk Management,Fractal,United States,2024-08-07,https://www.linkedin.com/jobs/view/mlops-engineer-%E2%80%93-model-risk-management-at-fractal-3993651824?position=7&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=923yPRSXsKG4F4caP5%2FsOg%3D%3D&trk=public_jobs_jserp-result_search-card,"Fractal Analytics is a strategic AI partner to Fortune 500 companies with a vision to power every human decision in the enterprise. Fractal is building a world where individual choices, freedom, and diversity are the greatest assets. An ecosystem where human imagination is at the heart of every decision. Where no possibility is written off, only challenged to get better.




We believe that a true Fractalite is one who empowers imagination with intelligence. And that it will be such Fractalites that will continue to build the company for the next 100 years.




Role Overview

2 Openings available for senior and mid-level MLOps Engineers.

We seek an innovative and forward-thinking ML Ops Engineer specializing in Model Risk Management & Governance. This role is designed for someone who thrives on the intersection of technical excellence and strategic insight and is capable of navigating the complexities of machine learning models while ensuring robust governance and risk management protocols are in place. You will be part of a dynamic team tasked with developing, implementing, and maintaining a centralized model governance framework that ensures compliance, consistency, and efficiency across all model modules.




Responsibilities:

Collaborate closely with clients to deeply understand their business challenges, translating these into actionable business problems that machine learning models can solve.
Lead the creation and implementation of a comprehensive model governance framework that standardizes processes for model development, validation, monitoring, and documentation.
Establish standardized documentation templates and explore automation possibilities to streamline documentation processes at various levels, ensuring efficient capture of model metadata related to data quality, design, validation, performance testing, risk mitigation, and compliance.
Establish Model Governance, Model Data Management (Data Collection, Data Quality, Data Privacy), Monitoring, Documentation, Reporting, Risk Management, Continuous Improvement.
Work alongside cross-functional teams to identify, assess, and mitigate risks associated with model performance and compliance, ensuring alignment with business objectives and regulatory requirements.
Develop processes for continuous monitoring and performance testing of models, identifying opportunities for improvement and innovation within the MLOps ecosystem.




Skills Needed:

Bachelor’s / Master’s degree in Engineering, Business, Economics/Statistics, or equivalent field.
Minimum of 5+ years of relevant experience in financial services, insurance, or a related industry, with a strong foundation in analytics, model governance, risk management, and compliance.
Demonstrated ability to apply analytical/logical thinking skills to solve complex problems and drive innovative solutions.
Proficiency in programming languages such as Python, R, or Scala; familiarity with automation tools for documentation; and experience with model development, validation, monitoring, and documentation processes.
Understanding of NLP Models, NLP Model Governance.
Exceptional communication skills, capable of presenting complex concepts to senior leadership/executives and collaborating effectively with cross-functional teams.
A proven track record of innovative thinking, inspiring action within teams, and demonstrating leadership in driving governance and risk management initiatives.
Understanding of industry regulations and compliance requirements, with experience developing and implementing governance policies and procedures.




Other Requirements:

Ability to be present at the client office for at least 4 days a week.
Openness to travel up to 25% of the time to meet business needs.




Pay:

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Fractal, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is: $125,000 - $175,000. In addition, for the current performance period, you may be eligible for a discretionary bonus.




Benefits:

As a full-time employee of the company or as an hourly employee working more than 30 hours per week, you will be eligible to participate in the health, dental, vision, life insurance, and disability plans in accordance with the plan documents, which may be amended from time to time. You will be eligible for benefits on the first day of employment with the Company. In addition, you are eligible to participate in the Company 401(k) Plan after 30 days of employment, in accordance with the applicable plan terms. The Company provides for 11 paid holidays and 12 weeks of Parental Leave. We also follow a “free time” PTO policy, allowing you the flexibility to take time needed for either sick time or vacation.




Fractal provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

Show more "
Data Scientist,Iris Software Inc.,United States,2024-08-16,https://ca.linkedin.com/jobs/view/data-scientist-at-iris-software-inc-4000247367?position=8&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=930DINn9c8sRlIrEIxXNjg%3D%3D&trk=public_jobs_jserp-result_search-card,"Iris's client, the largest bank in the Canada is looking to hire Sr. Data Scientist (MLOps)




Please find below the job details and share your resume if interested at sandeep.goel@irissoftware.com




Job Description:

Title: Sr. Data Scientist (MLOps)

Location: Toronto, ON (HYBRID)

Duration: Long term assignment




Data Scientist with experience on MLOps platforms, focused on financial models (Credit, Retail, etc…)

About Iris Software Inc.

With 4,000+ associates and offices in India, U.S.A. and Canada, Iris Software delivers technology services and solutions that help clients complete fast, far-reaching digital transformations and achieve their business goals. A strategic partner to Fortune 500 and other top companies in financial services and many other industries, Iris provides a value-driven approach - a unique blend of highly-skilled specialists, software engineering expertise, cutting-edge technology, and flexible engagement models. High customer satisfaction has translated into long-standing relationships and preferred-partner status with many of our clients, who rely on our 30+ years of technical and domain expertise to future-proof their enterprises. Associates of Iris work on mission-critical applications supported by a workplace culture that has won numerous awards in the last few years, including Certified Great Place to Work in India; Top 25 GPW in IT & IT-BPM; Ambition Box Best Place to Work, #3 in IT/ITES; and Top Workplace NJ-USA.










Thanks and Regards

Sandeep Goyal

Iris Software




200 Metroplex Drive, Suite #300

Edison, NJ 08817

Mobile: 732-426-8546

www.irissoftware.com

Show more "
Senior MLOps Engineer,Motion Recruitment,United States,2024-08-30,https://ca.linkedin.com/jobs/view/senior-mlops-engineer-at-motion-recruitment-3991778258?position=9&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=ebDyyeQy%2Fiq0vx4f0%2Bk1LA%3D%3D&trk=public_jobs_jserp-result_search-card,"Must have consistent and dedicated experience working in MLOps solely**


We are Leading the charge in revolutionizing drug discovery with AI, our state of the art platform unravels biology's complexities to uncover unique drug targets, mechanisms, and therapies that traditional approaches cannot reach.

We are hiring for a Senior MLOps Engineer. We're on the hunt for experts with hands-on MLOps experience and a solid grasp of ML infrastructure management, capable of seamlessly integrating ML and production environments. In this pivotal role, you'll spearhead the creation of groundbreaking AI applications, particularly scalable ML pipelines transforming the medical discovery industry. You'll architect and manage high-performance systems, making crucial decisions that impact our entire business.

MLOps seniority is the key skillset we are looking for, not seniority in Data science. Key assets in this role are someone with distributed systems experience and has designed a system on the cloud.

This is a unique opportunity to be a senior member in our team and provide your expertise and see the results of your work on the business in real-time. If you have the MLOps skills and are ready to work somewhere that addresses real-world challenges, then don’t hesitate to apply!?? Desired Skills & Experience What You Will Be Doing Tech Breakdown Daily Responsibilities The Offer


Must have consistent and dedicated experience working in MLOps solely** Required Skills & Experience
5+ years of consistent experience working as an MLOps engineer or equivalent
Expert level experience in deploying and scaling ML models
Experience designing on a cloud system
Exceptional communication skills
Experience with distributed training across multiple GPU’s
100% MLOps
80% Hands On
20% Thought leadership and mentorship
Competitive salary


You Will Receive The Following Benefits


Stock Options
Medical, Dental, Vision, insurance benefits
Four weeks’ vacation


Applicants must be currently authorized to work in the Canada on a full-time basis now and in the future.

Posted By: Seif Tadros
Show more "
MLops Data Scientist,LTIMindtree,United States,2024-08-08,https://www.linkedin.com/jobs/view/mlops-data-scientist-at-ltimindtree-3995697977?position=10&pageNum=2&refId=2SNkORqu1zigG0lx%2FRk%2FkA%3D%3D&trackingId=qa4BT0uEQFWwS51Z2pFanw%3D%3D&trk=public_jobs_jserp-result_search-card,"About Us:

LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com.




Job Title:

MLops Data Science




Work Location

Denver, Colorado, United States




Job Description:

""MLOps with AWS SageMaker experience to work from Denver P3P4

Mandatory

Hands on experience with AWS Sagemaker for ML model training pipeline development and integration

Hands on experience on shifting traffics all at once canary bluegreen

Hands on experience in working with Snowflake its integration to AWS resources

Require good knowledge on model deployment MLOps

Proficient knowledge on IAC using Terraform yaml to create and manage AWS resources

Proficient knowledge on CICD pipelines creation and its optimization

Individuals who are adept at developing and testing AI models




Must be able to

Break a problem down to its implementable components

Perform data cleaning data transforms and feature engineering

Perform model fitting tuning and validationtesting

Identify what parts of the experiments worked and what did not

Use this new knowledge and loop from 1 until the project scope is complete




Good to have

Proficient in Python SQL

Good Data Science and ML work experience specifically on the regression and classification models

Good analytical skill to derive insights and correlation from the data points

Good understanding on NLP GenAI domain""




Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”):




Benefits and Perks:

Comprehensive Medical Plan Covering Medical, Dental, Vision

Short Term and Long-Term Disability Coverage

401(k) Plan with Company match

Life Insurance

Vacation Time, Sick Leave, Paid Holidays

Paid Paternity and Maternity Leave




The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation.




Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting.




LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law.

Safe return to office:

In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.

Show more "
Machine Learning Engineer,Ema Unlimited,United States,2024-08-30,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-ema-unlimited-4013294923?position=1&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=6NxA4DqctiCJkzOy2mS4QQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Who We Are

At Ema, we are pioneering the next generation of AI technology to empower enterprise employees to unleash their creativity and productivity. Our proprietary AI, Ema, handles repetitive tasks, allowing humans to focus on what truly matters. Founded by former executives from Google, Coinbase, and Okta, and backed by leading investors like Accel Partners and Silicon Valley luminaries such as Sheryl Sandberg and Jerry Yang, we are a well-funded, dynamic company based in Silicon Valley and Bangalore.Our team is a blend of exceptional talent from top tech companies and prestigious universities, creating a powerhouse of innovation and expertise. We thrive in a hybrid work environment, fostering collaboration and creativity.




Who You Are

We are seeking passionate Machine Learning Engineers who are eager to solve complex problems and transform theoretical concepts into practical, scalable solutions. Whether you hold a Ph.D. in Computer Science or have deep industry experience, if you have a background in large language models, information retrieval, or natural language processing, we want you to join our mission-driven startup.




Your Role

As a Machine Learning Engineer at Ema, you will:

Innovate and Implement: Develop and deploy cutting-edge machine learning models for NLP, retrieval, ranking, and more, using advanced algorithms like Transformer-based models and reinforcement learning.
Data-Driven Development: Lead the processing and analysis of large datasets, informing model development and ensuring robust performance.
Lifecycle Management: Engage in every stage of ML model development, from problem definition to deployment, ensuring quality and effectiveness through A/B testing and automated validation.
Collaborate and Communicate: Work closely with technical and non-technical stakeholders to ensure understanding and adoption of ML solutions.




What We Value

Education & Experience: A Master’s or Ph.D. in a relevant field, or significant industry experience in deploying machine learning models.
Technical Skills: Proficiency in Python, TensorFlow, or PyTorch, and experience with large-scale data systems and MLOps principles.
Industry Insight: Stay abreast of the latest trends in machine learning and AI, applying this knowledge to drive innovation.
Problem Solving & Collaboration: Exceptional problem-solving skills and the ability to work collaboratively in a fast-paced, startup environment.




Why Ema?

Impactful Work: At Ema, your work directly contributes to our mission of transforming enterprise productivity. We value shipped impact over theoretical perfection, encouraging innovation and efficiency.
Collaborative Culture: We believe in breaking down silos. Every engineer codes, contributes to product management, and participates in the full lifecycle of product development.
Continuous Growth: Embrace the 10x engineering mindset by continuously improving and scaling your efforts. We support learning and growth, enabling you to challenge the status quo and pursue ambitious goals.
Supportive Environment: Our team thrives on collaboration and knowledge sharing. We encourage feedback, mentorship, and the sharing of expertise to drive team success.




Join us at Ema and be part of a team that is not just building AI, but redefining what it means to work in the AI-first era. If you are ready to make a significant impact and grow with us, we want to hear from you.

Show more "
Senior MLOps Engineer,Intapp,United States,2024-08-21,https://www.linkedin.com/jobs/view/senior-mlops-engineer-at-intapp-4004711641?position=2&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=4uc%2FUVNsjItm49nYMUaMSg%3D%3D&trk=public_jobs_jserp-result_search-card,"As a Senior MLOps Engineer, you will play a crucial role in enabling applied AI. Your main focus will be on the design, build, and maintenance of secure, scalable and efficient ML Platform, with a platform as a product mindset, that automates the end-to-end life-cycle for traditional ML models and LLM models, as part of the Cloud platforms engineering (CPE) directorate. CPE’s mission is to enable our Engineering teams to ship value faster, securely, efficiently and reliably.

In this role, you will:




Design and implement robust MLOps and LLMOps pipelines to automate and optimize machine learning model training, testing, deployment, and scaling.


Collaborate with data scientists and software engineers to ensure operational criteria are met before deployment.


Maintain and enhance continuous integration (CI) and continuous deployment (CD) environments for machine learning systems.


Develop tools to improve visibility into the system's operation and to facilitate rapid troubleshooting and debugging.


Foster a culture of continuous improvement by incorporating feedback and lessons learned into future ML deployments.


Lead initiatives to increase the resilience and scalability of ML systems.



What you need:




Bachelor’s degree in computer science, Engineering, Statistics, or a related field.


Experience in software development or data engineering, with at least 3 years focused on MLOps or similar roles.


Proven track record in designing and deploying scalable machine learning systems in production.


Strong programming skills in Python and experience with ML frameworks and tools (e.g., TensorFlow, PyTorch, MLFlow, MetaFlow, vLLM, Kubeflow, Jupyter notebook, Azure ML Studio, Amazon Sagemaker, Apache Spark, Apache Flink).


Expertise in containerization technologies (e.g., Docker, Kubernetes) and automation tools (e.g., Jenkins, GitLab CI).


Excellent problem-solving skills and the ability to work independently or as part of a team.



Bonus if you have:




Experience with data governance and ensuring compliance with data security regulations.


Familiarity with performance tuning of big data technologies.


LLM Model development



What you will gain at Intapp:

Our culture at Intapp emphasizes accountability, responsibility, and growth. We support each other in a positive, open atmosphere that fosters creativity, approachability, and teamwork. We’re committed to creating a modern work environment that’s connected yet flexible, supporting both professional success and work-life balance. In return for your passion, commitment, and collaborative approach, we offer:




Competitive base salary plus variable compensation and equity


Generous paid parental leave, including adoptive leave


Traditional comprehensive benefits, plus:



Generous Paid Time Off


Tuition reimbursement plan


Family Formation benefit offered by Carrot


Wellness programs and benefits provided by Modern Health


Paid volunteer time off and donation matching for the causes you care about


Opportunities for personal growth and professional development supported by a community of talented professionals


An open, collaborative environment where your background and contributions are valued


Experience at a growing public company where you can make an impact and achieve your goals


Open offices and kitchens stocked with beverages and snacks


Intapp provides equal employment opportunities to all qualified applicants and will make hiring decisions without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristic protected by federal, state or local laws. All offers are contingent upon passing a criminal history and other background checks if applicable to the position.

Please note: Intapp will not hire through text message, social media, or email alone. We will never extend a job offer unless you have been contacted directly by an Intapp recruiter and have participated in the interview process which will generally consist of 3 or more virtual or in person meetings. Please note that Intapp only uses company email addresses, which contain “@intapp.com” or “@dealcloud.com” to communicate with candidates via email. Intapp will never ask for financial information of any kind or for any payment during the job application process. We post all legitimate job openings on the Intapp Career Site at https://www.intapp.com/working-at-intapp/. If you believe you were a victim of such a scam, you may contact your local authorities. Intapp is not responsible for any claims, losses, damages, or expenses resulting from scammers.
Show more "
Machine Learning Operations Engineer,Flagship Pioneering,United States,2024-08-30,https://www.linkedin.com/jobs/view/machine-learning-operations-engineer-at-flagship-pioneering-3996315706?position=3&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=DwG1cvcG6%2FQzbQ3MwySDbw%3D%3D&trk=public_jobs_jserp-result_search-card,"Company Summary

Flagship Labs 97 Inc. (FL97) is a privately held, early-stage technology company pioneering the application of artificial intelligence to transform every aspect of the scientific method. FL97 is backed by Flagship Pioneering, which brings the courage, long-term vision, and resources needed to realize unreasonable results. Join our mission-driven team and contribute to the future of science.

Our Life Sciences effort is leveraging AI and high-throughput automation for valuable therapeutic discovery and development across biological modalities.

At FL97, we are uniquely cross-functional and collaborative. We are actively reimagining the way teams work together and communicate. Therefore, we seek individuals with an inclusive mindset and a diversity of thought. Our teams thrive in unstructured and creative environments. All voices are heard because we know that experience comes in many forms, skills are transferable, and passion goes a long way.

If this sounds like an environment you’d love to work in, even if you only have some of the experience listed below, please apply.

The Role

FL97 is seeking a dedicated and skilled Machine Learning Operations Engineer (ML Ops) to join our team. This role will focus on building and maintaining private cloud infrastructure used to train large scale machine learning models. You will be part of a dynamic, cross-functional team responsible for developing new artificial intelligence models that push the frontier of science. Working closely with biologists, bioinformaticians, software developers, machine learning scientists and automation engineers, you will contribute to the development of ML models for a range of scientific applications. The ideal candidate has a strong background in machine learning, as well as either experience in biotech industry or a record of scientific achievement, with a focus on MLOps, model training, and deployment.

Responsibilities include:


Developing and managing a large cloud-based cluster with >100 GPUs in support of FL 97 machine learning scientists (help make the GPUs go brr).
Implementing MLOps practices to streamline the model development and deployment process.
Collaborating with cross-functional teams to integrate ML models into the data pipelines for our labs.
Implementing rigorous testing, documentation, and performance benchmarking.


Qualifications:


Master's degree (or equivalent experience) in computer science, computational biology, physics, or other quantitative disciplines
Experience managing Kubernetes clusters with kubectl on cloud-based GPU infrastructure such as Lamda Labs or AWS
Experience with MLOps practices and tools including version control, automated testing, and CI/CD
Experience with GPU accelerated ML computing in at least pytorch and robust experience in the Python data science ecosystem.
Knowledge of additional high-performance libraries like Accelerate, DeepSpeed, etc is a plus
Experience with managing large, containerized multi-GPU training runs for large language models on Ray, Dask, Kueue, or Slurm or similar libraries.


Working at FL97, you would have access to advanced technology in the areas of:


AI experimental design and simulation
Automated custom instrumentation
Generative molecular and material design


More About Flagship Pioneering

Flagship Pioneering is a biotechnology company that invents and builds platform companies, each with the potential for multiple products that transform human health or sustainability. Since its launch in 2000, Flagship has originated and fostered more than 100 scientific ventures, resulting in more than $90 billion in aggregate value. Many of the companies Flagship has founded have addressed humanity’s most urgent challenges: vaccinating billions of people against COVID-19, curing intractable diseases, improving human health, preempting illness, and feeding the world by improving the resiliency and sustainability of agriculture. Flagship has been recognized twice on FORTUNE’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies, and has been twice named to Fast Company’s annual list of the World’s Most Innovative Companies. Learn more about Flagship at www.flagshippioneering.com.

Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.

At Flagship, we recognize there is no perfect candidate. If you have some of the experience listed above but not all, please apply anyway. Experience comes in many forms, skills are transferable, and passion goes a long way. We are dedicated to building diverse and inclusive teams and look forward to learning more about your unique background.

Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.
Show more "
System Administrator/Machine Learning Operations (MLOps),ABSC (Absolute Business Solutions Corp.),United States,2024-08-30,https://www.linkedin.com/jobs/view/system-administrator-machine-learning-operations-mlops-at-absc-absolute-business-solutions-corp-3942394601?position=4&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=bXj1y74feXIcyalrN00eyA%3D%3D&trk=public_jobs_jserp-result_search-card,"ABSC is seeking a System Administrator/Machine Learning Operations (MLOps) supporting DIA-NMEC under the DOMEX Data Discovery Platform (D3P) Modernization program which falls under our 10 year DOMEX Technology Platform (DTP) contract. Have impact as part of a mission-focused, solutions oriented, and adaptive team that values innovation, collaboration, and professional development. Come support a major program advancing the state of the art in Machine Learning Operations (MLOps) supporting mission-focused big data analytics and predictive analytics. You will be delivering cutting edge machine learning capabilities to advance national security objectives, swiftly produce and analyze results, and disseminate findings with actionable intelligence insights. While most work is conducted on-site at our client location in Bethesda, MD, we offer a flexible schedule and, occasionally, some tasks may be performed remotely. Percentage of remote work will vary based on client requirements / deliverables. If you are ready to join ABSC in enabling the NMEC to provide critical and unique capabilities to the Intelligence Community, apply today!

Responsibilities include, but are not limited to:


Work closely with a cross-functional agile application development team of data scientists, data engineers, software developers, system engineers, researchers, and data analysts working on the design, building, and optimization of a complex, resource demanding application.
Support multiple simultaneous work packages and take open-ended or high-level guidance, independently and collaboratively provide first-class infrastructure and deployment solutions.
Bring your mix of intellectual curiosity, quantitative acumen, and customer-focus to identify novel approaches to improve the performance of system function through system administration optimizations in partnership with a highly qualified, highly motivated team.


Experience and education required for this role:


Bachelor's degree or equivalent with a minimum of eight years of experience in a related field. Two additional years of experience may be substituted for the bachelor's degree.
4+ years of experience in system administration preferably in a cloud native environment
Must have an active TS/SCI clearance and willing and able to obtain a CI Polygraph.
Strong experience with Amazon Web Services (AWS/C2S)
Strong experience with Linux OS system administration
Strong experience application and infrastructure deployment, configuration, and maintenance
Proper prerequisites and ability to gain and maintain Privileged User Access (PUA) on the customer’s network
Experience maintaining hardware in compliance with security policy
Proficiency in one or more system administration scripting languages
Track record of active learning and creative problem solving
Ability to analyze and assess infrastructure and application deployment requirements and determine optimum, cost-effective solutions
Ability and desire to work in a fast-paced environment learning new skills quickly as needed


Desired experience includes:


A significant share of your experience in direct support of military or intelligence community customers, demonstrating progressive technical development and mission-focused outcomes
Experience supporting data team operations
An interest in data science, data engineering, or machine learning
Experience system administration in an on-prem, air-gapped environment
Experience configuring and optimizing storage solutions
Experience configuring and optimizing networking solutions
Experience or a desire to learn
Deploying and maintaining Kubernetes applications
DevOps and MLOPs
IT automation (e.g., SaltStack, Ansible, Terraform, etc.)
Familiarity utilizing virtualization and distributed file systems, such as Hadoop (or similar distributed file systems) in development and production environments;
Familiarity using git, svn, JIRA, or other version control and program management technologies;
Amazon Web Services (AWS) professional certifications;
Familiarity with NVIDIA GPUs and NVIDIA GPU appliances


Who we are:

Since 2001, Absolute Business Solutions Corp (ABSC) has delivered professional services and technology-enabled solutions to federal, defense, and intelligence customers through a mission-first ethos resulting in agile, innovative, and technology-advancing capabilities.

ABSC’s employees – including software developers, multi-disciplined intelligence analysts, technology protection engineers, program support personnel, and specialists in cloud, data science, AI/ML, and cyber – diligently support their customers, address their challenges, and stay ahead of technological or operational impacts to the mission.

ABSC stands ready to deliver the next generation of programs, personnel, and solutions to help advance our federal government customers’ driving innovation, agility, and security across all mission areas.

Some of our benefits include:


4 weeks of PTO plus 11 Federal Holidays
Retirement Planning – 401k Fully Vested with Matching
Tuition Assistance Program – Have Student Loans? Let us help!
Annual Health and Wellness Allowance
Career Development –5,250 USD Annually Towards Education and Training
Volunteer Time Off – Spend time directly supporting a charity of your choice
Charitable Match – ABSC matches (set amount) an employee’s donation to a qualifying charity
Paid Parental Leave –Employees receive 3 weeks of paid parental leave at 100% pay
Referral Program – We pay for internal and external referrals!
Performance Bonus


Apply to join our team today! We are always looking to grow our team - if you know someone who is seeking a new career opportunity, please share this job opening with them! ABSC offers generous external referral bonuses. You don’t need to be an employee to benefit from our Referral Program!

*ABSC is a proud V3, Virginia Values Vets, member which recognizes our commitment to hiring Veterans. If you are a veteran, please be sure to include that in your application. Thank you! *

Absolute Business Solutions Corp. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Equal Employment Opportunity Posters https://www.dol.gov/agencies/ofccp/posters; If you’d like to view a copy of the company’s affirmative action plan or policy statement, please email HR@absc-us.com.

If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact ABSC Human Resources at 703-437-3000 or HR@absc-us.com. Please do not call about the status of your job application if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a response.
Show more "
Hybrid Work - Need Lead ML Ops Engineer in Irving TX or Richardson TX,Steneral Consulting,United States,2024-08-15,https://www.linkedin.com/jobs/view/hybrid-work-need-lead-ml-ops-engineer-in-irving-tx-or-richardson-tx-at-steneral-consulting-4000465814?position=5&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=cRNFxZcipAMzu013FlkgVw%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Title - Lead ML Ops Engineer

Type - Hybrid

Location - Irving, TX or Richardson, TX

Should be local

Description -

Required


Python & SQL for scripting & programming
Experience in ML & Ops Engineering
Open source (but they use Python on Azure Kubernetes)
ML Ops
Kubernetes
Public Cloud
Support the deployment of ML/AI pipelines on the platform.
Enable functionality to support analysis, model optimization, statistical testing, model versioning, deployment and monitoring of model and data.
Ability to translate functionality into scalable, tested, and configurable platform architecture and software.
Establish strong software engineering principles for development in Python on the Azure/Google Cloud Platform.
Deliver features aligned to enterprise AutoML, Feature Engineering, and MLOPS capability.
Innovative thinking and great communication skills.
Strong ownership of deliverables, with design decisions aligned to scale and industry best practices.
Provide technical leadership and mentorship to a team of machine learning engineers. Collaborate with cross-functional teams to align ML initiatives with overall business goals.
Design, implement, and optimize machine learning algorithms and models. Stay abreast of the latest advancements in ML research and apply them to solve complex business problems.
Architect and implement scalable and efficient machine learning systems. Collaborate with software engineers to integrate ML models into production systems.
Work closely with data engineers to ensure the availability and quality of data for training and evaluation of machine learning models.
Develop strategies for deploying machine learning models at scale. Ensure models are integrated into production systems with high reliability and performance.
Design and conduct experiments to evaluate the performance of machine learning models. Iterate on models based on feedback and evolving business requirements.


Required Qualifications


6+ years of experience in analytics domains, and deep understanding of ML operationalization and lifecycle management.
5+ years of deploying and monitoring analytical assets in batch/real-time business processes.
5+ years of SQL & Python programming experience leveraging strong software development principles.
Experience in designing and developing AI applications and systems.
Experience with real-time and streaming technology (i.e. Azure Event Hubs, Azure Functions, Pub/Sub, Kafka, Spark Streaming etc.)
Experience with REST API/Microservice development using Python/Java.
Experience with deployment/scaling of apps on containerized environment (AKS and/or GKE)
Experience with Snowflake/BigQuery, Google Dataproc/Databricks or any big data frameworks on Spark
Experience with RDBMS and NoSQL Databases and hands-on query tuning/optimization.


Preferred Qualifications


Hands on experience in building solutions using cloud native services (Azure, GCP preferred)
Understanding of DevOps, Infrastructure as Code, automation for self service


Education


Required: Bachelor’s degree in computer science, Engineering, Statistics, Physics, Math, or related field or equivalent experience
Preferred: Master’s Degree or PhD with coursework focused on advanced algorithms, mathematics in computing, data structures, etc.
Show more "
MLOps Engineer,Stanford Health Care,United States,2024-08-07,https://www.linkedin.com/jobs/view/mlops-engineer-at-stanford-health-care-3996232820?position=6&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=Iy4CM9r5p%2F%2FybqsoLxsYag%3D%3D&trk=public_jobs_jserp-result_search-card,"1.0 FTE Full time Day - 08 Hour R2441639 Remote USA 108480039 TDS Data Science Innovation Technology & Digital Solutions

If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)

We are seeking a versatile DevOps Engineer with a strong foundation in full stack development to join our dynamic team. In addition to your expert-level DevOps skills, we are excited to see candidates who have hands-on experience in full stack development. As a DevOps Engineer at Stanford Healthcare, you'll play a crucial role in bridging the gap between development and operations, ensuring seamless integration, deployment, and automation of our systems. Your proficiency in both areas will empower you to architect solutions that not only optimize our infrastructure but also enhance the end-to-end development lifecycle. If you possess a deep understanding of coding, architecture, and deployment processes, coupled with your proven DevOps expertise, we encourage you to bring your unique perspective and skill set to our team. Your ability to collaborate, adapt, and innovate will contribute to the growth and success of both our DevOps practices and our broader development initiatives.

This is a Stanford Health Care job.

A Brief Overview

The MLOPs Engineer will play an integral role incorporating Artificial Intelligence (AI) within Stanford Health Care. The solutions will impact patient care, medical research, and operational services. This group is tasked to innovate, build, deploy and monitor production grade AI, machine learning (ML) and predictive algorithms into healthcare. The role will partner closely with lead researchers within the AI field and leaders across various clinical specialties and operations.

This role will report to the Infrastructure group and have a dotted line relationship to the Data Science team. The role will be responsible for maintaining cloud-based infrastructure as code repositories, maintaining infrastructure, deployment pipelines and designing the security landscape for the team and objects. The role will set the standards for the full SDLC of projects for the Data Science team.

Locations

Stanford Health Care

What You Will Do


Design, build and maintain scalable and robust infrastructure for AI/ML systems, including cloud-based environments, containerization and orchestration platforms.
Develop and implement CI/CD pipelines to automate the deployment, testing and monitoring of AI/ML models and applications.
Collaborate with data scientists, data engineers and software engineers to optimize model training, deployment and inference pipelines.
Monitor and troubleshoot AI/ML systems to ensure high availability, performance and reliability.
Maintain and monitor model training and inference pipelines across multi-cloud tenants especially around Large Language Models (LLMs).
Maintain Kubernetes pods, container registry and virtual machine image library and model registry
Monitor infrastructure utilization and costs pertaining to model training, inference and GPU utilization
Implement best practices for security, data privacy and compliance in AI/ML workflows and infrastructure.
Evaluate and integrate new tools, technologies and frameworks to improve the efficiency and effectiveness of our MLOps processes.
Mentor and provide technical guidance to junior members of the organization.
Stay up-to-date with the latest advancements and trends in MLOps, DevOps and cloud technologies and share them with the team.


Education Qualifications


Bachelor’s or higher degree in Computer Science, Engineering or a related field


Experience Qualifications


Three (3) or more years of directly related experience


Required Knowledge, Skills And Abilities


Proven experience as an MLOps Engineer.
Strong knowledge of cloud platforms such as AWS, Azure or Google Cloud and experience with infrastructure-as-code tools like Terraform or CloudFormation.
Proficiency in containerization technologies such as Docker and container orchestration platforms like Kubernetes.
Experience with CI/CD tools such as GitLab CI/CD, Github Actions or CiricleCI.
Solid programming skills in languages such as Python, Rust or Go and experience in scripting and automation.
Familiarity with machine learning frameworks and libraries such as PyTorch, Tensorflow and scikit-learn.
Deep understanding of DevOps principles, agile methodologies and software development lifecycle.
Strong problem-solving and trouble shooting skills, with the ability to analyze and resolve complex technical issues.
Excellent communication and collaboration skills with the ability to work effectively in cross-functional teams.


Physical Demands and Work Conditions

Blood Borne Pathogens


Category III - Tasks that involve NO exposure to blood, body fluids or tissues, and Category I tasks that are not a condition of employment


These Principles Apply To ALL Employees

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:


Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination


Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.

Base Pay Scale: Generally starting at $74.66 - $98.94 per hour

The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.
Show more "
Sr MLOps Engineer,Globant,United States,2024-08-29,https://mx.linkedin.com/jobs/view/sr-mlops-engineer-at-globant-4010889386?position=7&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=hAGXqCqhVLO2R5pTKHMrfQ%3D%3D&trk=public_jobs_jserp-result_search-card,"We are a digitally native technology services company where innovation, design and engineering meet scale. We use some of the latest technologies in the digital and cognitive field to empower organizations in every aspect.

Right now, we are looking for a Sr MLOps Engineer to join our Cloud Studio at Globant! This Studio combines the best cloud technologies, continuous integration and continuous delivery practices along with unique Globant capabilities to facilitate new and more efficient way of doing business.

You will get the chance to:


Work with professionals who have created some of the most revolutionary solutions in their fields.
Develop your career in our Studios and within an industry or multiple industries.
Be empowered to choose your career path and be part of an agile pod.
Design and develop CI/CD pipelines
Deployment of data structures



What will help you succeed:


5 Years of experience in similar positions
Understanding of business requirements and data
Cloud & ML Platforms (preferably Google Cloud and Vertex AI)
ML Life Cycle Management (CRISP-DM / MLOps)
Programming: Python, Shell
Containers: Kubernetes, Docker or similar
Orchestration: Airflow, Luigi or similar
CI/CD: Jenkins, GitLab CI or similar (preferably Harness.io)
Automation: Terraform, Ansible or similar
Security: Sonarqube, Checkmarks or similar
Branching: Gitflow, Trunk based or similar.
Advanced English (B2+)



At Globant we believe that an inclusive culture and a diverse environment makes us stronger. We encourage people to have an inclusive spirit as our global footprint expands. We seek to generate a place of inspiration and growth for everyone. A safe space, based on equity as a value, where everyone's careers can be promoted and developed in the same way. There is no innovation without diversity and there is no improvement without plurality.

This job can be only filled in CDMX

Are you ready?

Job Segment: Engineer, Equity, Finance, Engineering


Show more "
AI/ML Engineer I,Kraken Digital Asset Exchange,United States,2024-08-13,https://www.linkedin.com/jobs/view/ai-ml-engineer-i-at-kraken-digital-asset-exchange-3997540063?position=8&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=lMulPjWhHXBA7ITrPMLeYA%3D%3D&trk=public_jobs_jserp-result_search-card,"Building the Future of Crypto

Our Krakenites are a world-class team with crypto conviction, united by our desire to discover and unlock the potential of crypto and blockchain technology.

What makes us different?

Kraken is a mission-focused company rooted in crypto values. As a Krakenite, you’ll join us on our mission to accelerate the global adoption of crypto, so that everyone can achieve financial freedom and inclusion. For over a decade, Kraken’s focus on our mission and crypto ethos has attracted many of the most talented crypto experts in the world.

Before you apply, please read the Kraken Culture page to learn more about our internal culture, values, and mission. We also expect candidates to familiarize themselves with the Kraken app. Learn how to create a Kraken account here.

As a fully remote company, we have Krakenites in 70+ countries who speak over 50 languages. Krakenites are industry pioneers who develop premium crypto products for experienced traders, institutions, and newcomers to the space. Kraken is committed to industry-leading security, crypto education, and world-class client support through our products like Kraken Pro, Kraken NFT, and Kraken Futures.

Become a Krakenite and build the future of crypto!

Proof of work

The team

Kraken is looking for an experienced Machine Learning engineer to join our AI/ML Team in the centralized Data organization. In this role you will be applying cutting edge AI/ML technology to solving the most complex and exciting problems in the quickly growing and evolving crypto industry. We are looking for an extremely strong communicator and team-player, who is able to break down large complex problems into smaller more manageable problems-to-solve. You will take initiative to identify business problems, explore different ways to resolve issues, and systematically find the most efficient and effective way to deliver business impact.

The opportunity


Assist in designing, implementing, and deploying Machine Learning solutions to solve complex problems and deliver real business value ie. revenue, engagement and customer satisfaction
Collaborate with data scientists, software engineers, and business partners to identify AI/ML opportunities for improving operation scalability and efficiency
Assist in developing production-grade ML models to power personalized customer experience, content recommendation, fraud detection/prevention and more
Support the monitoring and improvement of model performance via data enhancement, feature engineering, experimentation and online/offline evaluation
Stay up-to-date in machine learning, and artificial intelligence trends and technologies, all while contributing to the growth of AI/ML in the Crypto industry


Skills You Should HODL


Experience in building, deploying, measuring, and maintaining machine learning models
Experience with GenAI / LLM's running in production, both open source and proprietary
Familiarity with the software development lifecycle, DevOps (build, continuous integration, deployment tools) and best practices
Programming skills in Python, Scala, Go or other languages
Good written and verbal communication skills and interpersonal skills
Experience or familiarity with ML frameworks, such as scikit-learn, Tensorflow, PyTorch
Experience or familiarity with Big Data tools – Spark, S3, Hadoop
Experience or familiarity with MLOps platforms, such as Kubeflow or MLFlow, is a plus
Experience with GenAI tools, such as Langchain, LlamaIndex, and open source Vector DBs, is a plus
Bachelor's degree in Computer Science, Machine Learning or related field
A minimum of 2 years of experience in AI/ML engineering, with a focus on learning and skill development


#USCANEU

This job is accepting ongoing applications and there is no application deadline.

Please note, applicants are permitted to redact or remove information on their resume that identifies age, date of birth, or dates of attendance at or graduation from an educational institution.

We consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.

Kraken is powered by people from around the world and we celebrate all Krakenites for their diverse talents, backgrounds, contributions and unique perspectives. We hire strictly based on merit, meaning we seek out the candidates with the right abilities, knowledge, and skills considered the most suitable for the job. We encourage you to apply for roles where you don't fully meet the listed requirements, especially if you're passionate or knowledgable about crypto!

As an equal opportunity employer, we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.

Stay in the know

Follow us on Twitter

Learn on the Kraken Blog

Connect on LinkedIn


Show more "
Senior AI/ML Engineer,Artmac,United States,2024-08-19,https://www.linkedin.com/jobs/view/senior-ai-ml-engineer-at-artmac-4004531953?position=9&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=UdZNYLCsf3IdN152NcJf9A%3D%3D&trk=public_jobs_jserp-result_search-card,"Who We Are

Artmac Soft is a technology consulting and service-oriented IT company dedicated to providing innovative technology solutions and services to Customers.

Job Description

Job Title : Senior AI/ML Engineer

Job Type : W2 / C2C

Experience : 6-10 Years

Location : San Diego, California

Responsibilities


10+ years of industry experience, including 5+ years of experience with AIML modeling, MLOps, and model deployment.
Experience in AI System Development foundational model Lifecycle training, retrieval of Augmented Systems, and Model Evaluation.
Proficient in Large Language Models (LLMs) Architecture, creating targeted Instruction Datasets, and implementing Quantization and Inference Optimizations.
Capable of covering Problem Definition, Data Acquisition, and Full-cycle Deployment, utilizing tools like MLflow and cloud Platforms like AWS, Google Cloud, and Azure.
Proprietary Models like GPT-4 and Claude, Open-source Models like Llama and Mistral, are able to deliver high-performing, scalable, and cost-efficient AI solutions.
NLP libraries like NLTK, spaCy, GPT-3, BERT, and Hugging Face's Transformers create sophisticated natural language processing solutions.
Expert in AIML modeling, Python, AIML Infrastructure, model deployment, and MLOps
Experience working in Supply Chain, Operations, or a related field
End-to-end GenAI application experience
Knowledge in RAG, Prompt Engineering, LoRA, and other GenAI techniques
Ability to operate independently and lead without authority
Superb communication and interpersonal skills.


Technical Skills


Methodologies: Spiral, Agile, Waterfall, Lean.
Programming Language: C++, Python, Shell, SQL, R
IDE Tools: PyCharm, RStudio, Visual Studio Code, Jupyter Notebook, Google Collab, Navicat.
ML Frameworks: Transformers, Scikit-Learn, Keras, TensorFlow, PyTorch, ONNX, NLTK, OpenAI, long-chain, llama-index,kore.ai
DL Architectures: LLM, ANN, CNN, R-CNN, RNN, GRU, LSTM, Transformers, Attention Mechanism, Tokenisers, BERT, T5, Sentence Transformers, Foundational models
Packages: Pandas, NumPy, Spark, Matplotlib, SciPy
Cloud Technologies: AWS (EC2, S3, RDS, ECS, Lambda), Azure(VM, Functions, ACR, AKS), Digital Ocean, GCP, Paperspace
Database: MySQL, PostgreSQL, MongoDB, ChromaDB, Pinecone, SQLite
Web Frameworks and Web Servers/ Deployment: Fast API, Flask, Nginx, Gunicorn, Uvicorn, Docker, Kubernetes
Miscellaneous Tools and Technologies: JIRA, Auto Gluon, GitHub Actions, GitHub Issues, Datadog, MS Power BI, Postman, Locust, Stream lit, CUDA, cuDNN, TensorRT
Version Control: Git, GitHub, DVC (Data Version Control)
Operating Systems: Windows, Linux, Mac.


Qualifications


Industry experience 10+ years BSCS, 5+ years MS/PhD in Computer Science, Statistics, Applied Math, or a related field
Show more "
MLOps Engineer,Dice,United States,2024-08-29,https://www.linkedin.com/jobs/view/mlops-engineer-at-dice-4011018961?position=10&pageNum=5&refId=1WUdc0WAESqVBM6iLCH8AA%3D%3D&trackingId=hGBlragw%2FtX2kv4WnT1ADg%3D%3D&trk=public_jobs_jserp-result_search-card,"Dice is the leading career destination for tech experts at every stage of their careers. Our client, Apex Systems, is seeking the following. Apply via Dice today!

Job#: 2043671

Job Description:

Job Title: MLOps Engineer

Job Location: Columbus, OH or Minnetonka, MN

Pay Range: $51/hr-$59/hr

Contract Length: 3 Months (Contract-to-Hire)

About Us:

We are a forward-thinking team within a large enterprise bank, deeply invested in leveraging machine learning and artificial intelligence to drive impactful business outcomes. Our team is responsible for ensuring the smooth, scalable and secure deployment of machine learning models into production, handling both real-time and batch processing workloads. We offer a unique opportunity to work closely with data scientists and engineers, focusing on large language models and cutting-edge MLOps practices.

Job Summary:

As an MLOps Engineer, you will be responsible for the end-to-end productionization and deployment of machine learning models at scale. You will work closely with data scientists to refine models and ensure they are optimized for production. Additionally, you will be responsible for maintaining and improving our MLOps infrastructure, automating deployment pipelines, and ensuring compliance with IT and security standards. You will play a critical role in image management, vulnerability remediation, and the deployment of ML models using modern infrastructure-as-code practices.

Key Responsibilities:


Vulnerability Remediation & Image Management:
Manage and update Docker images, ensuring they are secure and optimized.
Collaborate with data scientists to validate that models run effectively on updated images.
Address security vulnerabilities by updating and patching Docker images.
AWS & Terraform Expertise:
Deploy, manage, and scale AWS services (SageMaker, S3, Lambda) using Terraform.
Automate the spin-up and spin-down of AWS infrastructure using Terraform scripts.
Monitor and optimize AWS resources to ensure cost-effectiveness and efficiency.
DevOps & CI/CD Pipeline Management:
Design, implement, and maintain CI/CD pipelines in Azure DevOps (ADO).
Integrate CI/CD practices with model deployment processes, ensuring smooth productionization of ML models.
Strong experience with Git for code versioning and collaboration.
Model Productionization:
Participate in the end-to-end process of productionizing machine learning models, from model deployment to monitoring and maintaining their performance.
Work with large language models, focusing on implementing near real-time and batch inferences.
Address data drift and model drift in production environments.
Collaboration & Continuous Learning:
Work closely with data scientists, DevOps engineers, and other MLOps professionals to ensure seamless integration and deployment of ML models.
Stay updated on the latest trends and technologies in MLOps, especially related to AWS and Docker.


Required Skills & Qualifications:


Python: Deep expertise in Python for scripting and automation.
AWS: Strong experience with AWS services, particularly SageMaker, S3, and Lambda.
Terraform: Proficiency in using Terraform for infrastructure-as-code on AWS.
Docker: Extensive experience with Docker, including building, managing, and securing Docker images.
Linux: Strong command-line skills in Linux, especially for Docker and system management.
DevOps Experience: Azure DevOps (ADO): Significant experience in setting up and managing CI/CD pipelines in ADO.
Git: Proficient in using Git for version control and collaboration.
Additional DevOps Tools: Experience with Jenkins or other CI/CD tools is a plus.
Experience & Education: 4 years of experience in combination of MLOps/DevOps/Data Engineering; Bachelors degree in Computer Science, Engineering, or a related discipline.


Preferred Qualifications:


Experience with large language models and productionizing ML models in a cloud environment.
Exposure to near real-time inference systems and batch processing in ML.
Familiarity with data drift and model drift management.


EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at or .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing in Talent Satisfaction in the United States and Great Place to Work in the United Kingdom and Mexico.
Show more "
ML Ops Engineer,Zendar,United States,2024-08-30,https://www.linkedin.com/jobs/view/ml-ops-engineer-at-zendar-4013747397?position=1&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=p609VXCBygEgpm8jZKUZdg%3D%3D&trk=public_jobs_jserp-result_search-card,"Who We Are:

Zendar is creating a high-resolution radar imaging system that has resolution similar to lidar, allowing cars to see the driving world in all conditions and at long distances to travel at high speeds. We want to change the role of radar in the Advanced driving assist (ADAS) sensor stack and demonstrate that radars can take on many of the functions of lidar at a much lower cost. Zendar has pioneered a software-defined radar technology which fuses data streams from multiple sensors to build a more accurate scene and utilizes machine learning to understand the environment. All of this works in an embedded AI processor with tight latency and performance guarantees to deliver reliable sensing and perception.

Zendar was founded in the San Francisco Bay area, at the very heart of one of the most advanced regions in the development of advanced vehicles technologies. We also have offices in Germany and France.

Zendar has a diverse and dynamic team of electrical, mechanical, RF, algorithms and software engineers with a deep background in sensing technology. Zendar is backed by Tier-1 VCs, has raised more than $50M in funding and has established strong partnerships with industry leaders. Our team has more than doubled in number over the last year as our technology has gained traction in the automotive and agriculture industries.

Who You Are:

Radar has long been a neglected sensor in the autonomy field. At Zendar, we have applied state-of-the-art ML techniques to show that radar can be just as capable as a camera in perceiving the environment. Our ML team’s mission is to unlock the capability of radar and show that camera + radar is the right combination of sensors for autonomy.

To help us achieve this mission, we are establishing an MLOps Team to support and power the productivity of our perception efforts. In this role, you will be second hire on the MLOps Team at Zendar, working alongside the team lead, a small team of machine learning researchers and engineers, and Zendar’s existing DevOps team.

As a core member of the MLOps team, you’ll be working on:

A robust and reliable data lake for our proprietary training and evaluation data
A high-capacity batch job system for ad-hoc compute workloads
A dynamically-scalable and GPU-accelerated compute cluster for model training
Whatever else we need to scale up to the next level!

As an MLOps Engineer at Zendar, you will:

Work with our rich store of proprietary radar, lidar, and camera data, and take ownership of our associated ETL / data transformation pipelines
Take meaningful ownership over the responsibilities mentioned above, continually working to improve and expand the systems we already have in place
Collaborate with the Machine Learning / Radar Perception team and the DevOps team to build out new capabilities and scale our existing capabilities to new heights

What We Look For:

3+ years of hands-on experience with cloud computing platforms (AWS, GCP, or Azure)
Broad knowledge of data engineering and ML ops tools (Airflow, kubernetes, docker)
Strong engineering skills in Python and SQL
Excellent communication and organizational skills
Eagerness to challenge yourself, learn new skills, and adapt as the company grows.

Bonus Points:

Experience with the modern Deep Learning stack (PyTorch, Tensorflow, CUDA)
Prior experience with automotive perception tasks (semantic segmentation, object detection, tracking, route planning)
Knowledge of the physics of radar devices and electromagnetic theory

What We Have To Offer:

Opportunity to make an impact at a young, venture-backed company in an emerging market
Competitive salary ranging from $125-165k annually depending on experience
Performance based Bonus
Benefits including medical, dental, and vision insurance, flexible PTO, and equity
Hybrid work model: in office 3 days per week, the rest… work from wherever!
Daily catered lunch and a stocked fridge (when working in the Berkeley, CA office)




Zendar participates in E-Verify.

Zendar is committed to creating a diverse environment where talented people come to do their best work. We are proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

Show more "
Machine Learning Engineer,Artisan,United States,2024-08-03,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-artisan-3992509622?position=2&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=nxKqRqPfClRFkcEv3WiF9Q%3D%3D&trk=public_jobs_jserp-result_search-card,"At Artisan, we're creating AI Employees, called Artisans, and software which is beautiful, easy to use, and replaces the endless stack of point solutions. We're starting with outbound sales and our AI BDR, Ava. Our platform contains every tool needed for outbound sales - B2B data, AI email sequences, deliverability optimization tools and so much more.

We're growing very rapidly and are building our sales org from the ground up. We recently raised a $11M seed round from top investors, and are looking for talented engineers to join us on our rocketship growth as we relentlessly work towards building a multi-billion dollar company 🦄

Key Responsibilities


Fine-tuning and prompt engineering LLMs for our Artisans, helping us to create the most advanced AI Employees (primarily Google's Gemini, OpenAI's GPT 3.5, GPT 4 & GPT-4o, and Anthropic's Claude).
Developing systems to allow users to interact with platform features through chat (e.g. our onboarding flow and platform setup is currently done by Ava, our AI BDR).
Architect LLM systems which integrate with third-party tools for a plethora of Artisan use cases (think email conversations, the user chat interface, etc.)
Minimize hallucinations and strange tone of voice.
Reduce latency of our LLM systems.
Stay up-to-date with the latest LLM technologies so we stay on the bleeding edge of what's possible.


Qualifications


Degree in Computer Science, Machine Learning, Data Science, or a related field.
Industry experience with LLM fine tuning and prompt engineering.
Excellent written and spoken English.
Extensive experience in Python and MLOps tools like MLFlow and cloud platforms such as Azure or AWS.
Expertise in Python back-end development.


Benefits


Generous equity.
Great health + vision + dental.
Show more "
Machine Learning Engineer,Insight Global,United States,2024-08-23,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-insight-global-4006460034?position=3&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=AE0mb%2F6YwflI7zCcVxEW4w%3D%3D&trk=public_jobs_jserp-result_search-card,"Tile: ML-Ops Engineer (Machine Learning Operations)

Contract Type: 3 month Contract to hire

Conversion Salary: 90-95K

Location: Hybrid/Columbus, OH or Minneapolis, MN




Must Haves:

4 years of experience in combination of MLOps/DevOps/Data Engineering
Bachelor's degree in Computer Science, Engineering, or a related discipline.
Python: Deep expertise in Python for scripting and automation.
AWS: Strong experience with AWS services, particularly SageMaker, S3, and Lambda.
Terraform: Proficiency in using Terraform for infrastructure-as-code on AWS.
Docker: Extensive experience with Docker, including building, managing, and securing Docker images.
DevOps Experience: Azure DevOps (ADO): Significant experience in setting up and managing CI/CD pipelines in ADO.
Proficient in using Git for version control and collaboration.




Plusses:

- Experience with large language models and productionizing ML models in a cloud environment.

- Exposure to near real-time inference systems and batch processing in ML.

- Familiarity with data drift and model drift management.







JOB DESCRIPTION

Location: Hybrid (Minneapolis, MN or Columbus, OH) - Remote for the duration of the contract, with an expectation of 3 days in the office per week once hired full-time. This is a hybrid role, with the expectation of being in the office three days a week once hired full-time. Candidates must be based in or willing to relocate to the Minneapolis, MN, or Columbus, OH areas. Remote work is possible for the duration of the 90-day contract, with the understanding that the role will transition to a hybrid model post-contract. Position not eligible for sponsorship now or in the future. Please make sure answers to screening questions are provided.




We are a forward-thinking team within a large enterprise bank, deeply invested in leveraging machine learning and artificial intelligence to drive impactful business outcomes. Our team is responsible for ensuring the smooth, scalable and secure deployment of machine learning models into production, handling both real-time and batch processing workloads. We offer a unique opportunity to work closely with data scientists and engineers, focusing on large language models and cutting-edge MLOps practices.




Job Summary:

As an MLOps Engineer, you will be responsible for the end-to-end productionization and deployment of machine learning models at scale. You will work closely with data scientists to refine models and ensure they are optimized for production. Additionally, you will be responsible for maintaining and improving our MLOps infrastructure, automating deployment pipelines, and ensuring compliance with IT and security standards. You will play a critical role in image management, vulnerability remediation, and the deployment of ML models using modern infrastructure-as-code practices.

Key Responsibilities:

1) Vulnerability Remediation & Image Management:

- Manage and update Docker images, ensuring they are secure and optimized.

- Collaborate with data scientists to validate that models run effectively on updated images.

- Address security vulnerabilities by updating and patching Docker images.

2) AWS & Terraform Expertise:

- Deploy, manage, and scale AWS services (SageMaker, S3, Lambda) using Terraform.

- Automate the spin-up and spin-down of AWS infrastructure using Terraform scripts.

- Monitor and optimize AWS resources to ensure cost-effectiveness and efficiency.

3) DevOps & CI/CD Pipeline Management:

- Design, implement, and maintain CI/CD pipelines in Azure DevOps (ADO).

- Integrate CI/CD practices with model deployment processes, ensuring smooth productionization of ML models.

- Strong experience with Git for code versioning and collaboration.

4) Model Productionization:

- Participate in the end-to-end process of productionizing machine learning models, from model deployment to monitoring and maintaining their performance.

- Work with large language models, focusing on implementing near real-time and batch inferences.

- Address data drift and model drift in production environments.

5) Collaboration & Continuous Learning:

- Work closely with data scientists, DevOps engineers, and other MLOps professionals to ensure seamless integration and deployment of ML models.

- Stay updated on the latest trends and technologies in MLOps, especially related to AWS and Docker.

Show more "
ML Generalist,Quantum World Technologies Inc.,United States,2024-08-23,https://ca.linkedin.com/jobs/view/ml-generalist-at-quantum-world-technologies-inc-4008888278?position=4&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=TcHINaX%2BaKjrdwngMwxsgA%3D%3D&trk=public_jobs_jserp-result_search-card,"Role: ML Generalist

Location: Remote in Canada




Technical Skills Primary

Role Overview

In this role you will help drive personalized experiences for customers as a ML Generalist Pricing Recommendations

Are you passionate about harnessing the power of data to drive impactful business decisions customer is seeking a ML Generalist to play a pivotal role in shaping the future of our consumer journey through cuttingedge Machine Learning ML solutions for pricing and recommendations Join us and make a tangible difference in the lives of our customers by developing innovative solutions that deliver personalized experiences and optimize value

About The Role

Ability to attend meetings and discussions during overlapping XXXX Standard Time XST hours musthave
Full Stack ML acumen to conceptualize design and implement stateoftheart ML models for dynamic pricing strategies and personalized product recommendations
Develop implement and deploy machine learning models that leverage our unique combination of user behavior and subscription data to improve consumer value
Engineer and maintain largescale consumer behavioral feature stores while ensuring scalability and performance
Develop and maintain data pipelines and infrastructure to support efficient and scalable ML model development and deployment
Collaborate with crossfunctional teams Marketing Product Sales to ensure your solutions align with strategic objectives and deliver realworld impact
Create algorithms for optimizing consumer journeys and increasing conversion and monetization
Design analyze and troubleshoot controlled experiments Causal AB tests Multivariate tests to validate your solutions and measure their effectiveness
Agile development mindset appreciating the benefit of constant iteration and improvement
Focus on business practicality and the 8020 rule very high bar for output quality but recognize the business benefit of having something now vs perfection sometime in the future

About You

Masters Degree PhD in Machine Learning Statistics Data Science or related quantitative fields preferred
5 to 7 years of experience in one or more of the following areas machine learning including deep learning recommendation systems pattern recognition data mining or artificial intelligence
Proficiency in using casual inference uplift modeling splines support vector machines lookalike modeling model stacking ensembles embeddingbased modeling etc
Proficient in Python SQL intermediate data engineering skill set with tools libraries or frameworks such as PySpark Hadoop Hive and Big Data technologies scikitlearn pandas numpy PyTorch etc
Experience with various ML techniques and frameworks eg data discretization normalization sampling linear regression decision trees deep neural networks etc
Experience in building industrystandard recommender systems and pricing models
Experience in MLOps ML Engineering and Solution Design
Its Great But Not Required If You Also Have
Experience working in a consumer or B2C space for a SaaS productsoftware provider
Experience in developing recommendation systems and deep learningbased models
Excel in solving ambiguous and complex problems being able to navigate through uncertain situations breaking down complex challenges into manageable components and developing innovative solutions

Skills

Machine Learning-Python

Show more "
Data Scientist,DataSkate,United States,2024-08-28,https://www.linkedin.com/jobs/view/data-scientist-at-dataskate-4009764819?position=5&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=0hzrRiQQjs0s3ay9QUc6pA%3D%3D&trk=public_jobs_jserp-result_search-card,"Hello Connections,

***Seeking an Data Scientist with AI/ML and Python comfortable to go Onsite at Charlotte, NC USA***

Role and Responsibility:

We need to add 2 resources to implement some of the advanced features (Predictive Analysis using iONA).

It is AIML resource with Python programming experience.




Python Strong in Data science and Machine Learning , must know time series algos, Anomalies detection and prediction algos like Radom forest isolation, LSTM etc. Strong understanding of frameworks like BERT, GPT or transformer models, Supervised and unsupervised ML techniques, frameworks like TensorFlow, PyTorch, etc,




Experience with cloud platforms, Experience with MLOPS , Basic knowledge of deep learning and neural networks. (1.) To be responsible for providing technical guidance to a team of developers, enhancing their technical capabilities and increasing productivity.

(2.) To conduct comprehensive code reviews, establish and oversee quality assurance processes, performance optimization , implementation of best practices and coding standards to ensure succeful delivery of complex projects. (3.) To ensure process compliance in the assigned module, and participate in technical discussionsorreview as a technical consultant for feasibility study (technical alternatives, best packages, supporting architecture best practices, technical risks, breakdown into components, estimations).

(4.) To collaborate with stakeholders to define project scope, objectives, deliverables and accordingly prepare and submit status reports for minimizing exposure and closure of escalations.




If you need assistance in the application process, please feel free to reach out,

And email khushi@cblsolutions.com with your resume and the best time/number to chat, so we can get you submitted and interviewed immediately!




Looking forward to your response,

Thanks




Khushi Pachauri

khushi@cblsolutions.com

Show more "
Data Engineer,McDonald's,United States,2024-08-27,https://www.linkedin.com/jobs/view/data-engineer-at-mcdonald-s-4011494690?position=6&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=pwdMEWbjT9yIakhBJgnShA%3D%3D&trk=public_jobs_jserp-result_search-card,"McDonald’s is proud to be one of the most recognized brands in the world, with restaurants in over 100 countries that serve 70 million customers daily. We continue to operate from a position of strength. Our updated growth strategy is focused on staying ahead of what our customers want and realizing further growth potential. Our relentless ambition is why McDonald’s remains one of the world’s leading corporations after almost 70 years. Joining McDonald's means thinking big and preparing for a career that can have influence around the world.

At McDonald’s, we see every day as a chance to create positive impact. We lead through our values centered on inclusivity, service, integrity, community and family. From support of Ronald McDonald House Charities to our Youth Opportunity project and sustainability initiatives, our values keep us dedicated to using our scale for good: good for our customers, people, industry and planet. We also offer a broad range of outstanding benefits including a sabbatical program, tuition assistance and flexible work arrangements.

We are enjoying the flexibility of a hybrid work model, in which employees spend part of their week connecting with co-workers in our state-of-the-art headquarters. Located in the booming West Loop of downtown Chicago, it's set up to be a global hub that cultivates collaboration:

Take a class at Hamburger University
Sample future items in our Test Kitchen
Utilize the latest technology to connect with your team around the globe

We are an equal opportunity employer committed to the diversity of our crew members, staff, operators, and suppliers. We promote an inclusive work environment that creates feel-good moments for everyone.



Job Description



We are looking for a Data Engineer to join our Data Science and Engineering team within Enterprise Data, Analytics and AI (EDAA). EDAA is responsible for turning the System’s data into a winning advantage, empowering a data-centric system, making faster and better decisions.

Responsibilities:

Build data pipelines to ingest and integrate data from various sources into the organization's data lake.
Design and maintain data quality checks, identify, and resolve data quality issues in coordination with other teams.
Develop CI/CD pipeline and automation to account for data, code and model changes.
Develop and optimize complex SQL queries to extract and transform data from large and complex datasets.
Collaborate globally with Data Scientists, MLOps, and Architects.
Partner with the Data Governance team to enhance data capabilities.





Qualifications


Bachelor’s degree in engineering, statistics, or other fields with a quantitative component is required
2+ years of experience in building and deploying data pipelines, preferably with ML platforms like Databricks or similar.
2+ years of Data Engineering within the context of Data Science, familiar with cloud platforms such as AWS.
2+ years coding advanced SQL and Python.
Experience using big data batch and streaming tools such as Spark.
Understanding of modern machine learning techniques.
Experience working with data scientists for feature engineering and exploratory data analysis.
Experience with continuous integration and deployment (CI/CD) frameworks.
Strong knowledge of relational and multi-dimensional database architecture.
Self-starter with a high level of intellectual curiosity and ability to set priorities.
Strong analytical and problem-solving mindset.
Ability to build trust and rapport, creating a comfortable and effective workplace.
Strong verbal and written communication skills, with the ability to convey technical information to a non-technical audience.
Comfortable with ambiguity and proactive in problem-solving.


Additional Information



McDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.

McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Nothing in this job posting or description should be construed as an offer or guarantee of employment.

Show more "
Machine Learning Engineer,Intelliswift Software,United States,2024-08-22,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-intelliswift-software-4005648828?position=7&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=LqGavP82KT3fTuu1GMjCEg%3D%3D&trk=public_jobs_jserp-result_search-card,"Pay rate range - $65/hr. to $68/hr. on W2

Onsite in Arlington or Boston, hybrid schedule with flexible days.




Must Have

5 years minimum machine learning experience.

Bachelors in programming or similar (statistics, mathematical degrees on top of a tech degree would be a plus)

AWS development experience, Built within AWS products.




Daily Schedule

MLE (Machine Learning Engineer) to complete productionalization of our ML models to support operations efficiency gains.

Team will not be able to scale nor productionalize our models and will remain within the research milestones.

Own the development and operationalization of solutions deployed in production.

Work across multiple teams to integrate our solutions with products owned by our partners.

Design model experimentation processes and frameworks in synergy with our scientists.

Help the team grow and cultivate best practices in software development, MLOps, and experimentation.

Model training, data pre-processing,

Ongoing support of model and lifestyle.




As a Machine Learning Engineer, you will work closely with science teams to bring research to production.

This is a role that combines engineering knowledge (around machine learning, natural language processing, and computer vision), technical strength, and product focus.

It will be your job to implement novel ML systems, product integrations, and performance optimization releases into production.

While ensuring CI/CD compliance and ensuring best practices in software development and cloud infrastructure are followed (in the realm of scalability, security, and availability).

Key job responsibilities

Own the development and operationalization of solutions deployed in production.

Work across multiple teams to integrate our solutions with products owned by our partners.

Design model experimentation processes and frameworks in synergy with our scientists.

Help the team grow and cultivate best practices in software development, MLOps, and experimentation.

Model training, data pre-processing,

Ongoing support of model and lifestyle.

AWS development experience, Built within AWS products.
Bachelor in programming or similar (statistics, mathematical degrees on top of that would be a plus)
Minimum 5 years of ML experience in the role previous.
High preference for anyone with a previous ML title.
Familiarity with Tensorflow and the statistics scripting language R.
Show more "
Machine Learning Engineer,Acceler8 Talent,United States,2024-08-28,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-acceler8-talent-4009753332?position=8&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=N6mZgL%2Fb0Qc%2FoYUEa9cG1g%3D%3D&trk=public_jobs_jserp-result_search-card,"Senior ML Engineer Position – San Francisco (Hybrid/Flexible)




Introduction:

We are seeking a talented Senior ML Engineer to join our team and lead pioneering projects in data-centric AI. This role offers the chance to develop cutting-edge tools that diagnose and correct dataset issues, enhancing the reliability and performance of AI models across various industries.




About the Company:

Our company, a MIT/ Berkeley spinout, has quickly emerged as a significant player in AI technology. We develop advanced data-centric AI solutions, including no-code SaaS enterprise solutions that help identify and rectify dataset issues. Our founders bring a wealth of experience from top organizations, and our mission is to streamline the way AI systems interact with real-world, messy data.




About the Role:

The Senior ML Engineer will play a crucial role in our dynamic startup environment. This position involves handling text, image, and structured data from diverse industry sectors and developing scalable modeling infrastructures. Candidates should be well-versed in software engineering, MLOps, and contemporary AI technologies, including Generative AI and Foundation models.




What We Can Offer You:

Competitive salary range of $180,000 to $220,000, plus equity options.
Premium health, dental, and vision insurance with top-tier options available.
Annual travel stipend to support work-from-anywhere flexibility and cultural enrichment.
Stipend for attending relevant conferences to stay abreast of industry advancements.
Opportunity to work with a team of AI pioneers and industry leaders in a well-funded startup environment.




Key Responsibilities:

Develop and manage cloud infrastructure for ML projects involving diverse datasets.
Lead and execute full-cycle Data/AI projects from inception through to production.
Act as a technical lead within the ML team, promoting innovation in algorithmic approaches to enhance dataset quality.
Maintain and enhance production code and models in cloud-based environments.




This position is designed for an individual ready to challenge their skills and lead innovative projects that refine the utility and accuracy of machine learning data. Join us in our quest to advance AI technology and achieve our mission of enhancing data quality at a fundamental level.




Relevant Keywords

Senior ML Engineer, data-centric AI, MLOps, cloud infrastructure, Generative AI, Foundation models, data quality, scalable modeling infrastructure, machine learning, SaaS, Python, AWS, GCP, Software Development.

Show more "
MLOps Automation Engineer Lead,Huntington National Bank,United States,2024-08-30,https://www.linkedin.com/jobs/view/mlops-automation-engineer-lead-at-huntington-national-bank-4013724164?position=9&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=msMnGAlwkM64aT790odYDA%3D%3D&trk=public_jobs_jserp-result_search-card,"Description

Summary:

Our Enterprise Data and Analytics department is growing, and we're looking for an outstanding MLOps Automation Engineer Lead to join our team. At Huntington, this is an opportunity to work cross-functionally with nearly every team in the company to elevate the organization by uncovering trends and opportunities, decreasing the time to insight, and making data accessible to all. Our goal is to be the Best performing Regional Bank in America, and we need data and analytics to meet that goal.

As we advance our data and analytics capabilities, we want individuals interested in leading and developing current team members, while also serving as a technical leader who will still be involved in deploying data and models to production. The primary focus is automating development and delivery processes and maintaining the continuous integration and continuous deployment (CI/CD) pipeline.

Duties And Responsibilities


Streamline the data, analytics, and model development lifecycle by identifying pain points and productivity barriers and determining ways to resolve them through automation.
Understand the current process and technical complexities of developing and deploying data pipelines and model builds and develop automation solutions to improve and extend the existing process to become an unattended delivery pipeline.
Collaborate closely with product development, architecture, data engineering and testing teams to understand their current build and release processes and make recommendations for improvement through the automation of various tasks.
Partner with cross-functional stakeholders, including development, operations, quality assurance and security, to streamline processes.
Develop and continuously improve automation solutions to enable teams to build and deploy quality data and code efficiently and consistently.
Build automated testing solutions in support of quality management objectives to reduce manual effort.
Build automated environment provisioning solutions in response to changes in processing demand.
Build automated feedback mechanisms to monitor the performance of models in production.
Work closely with cross-functional stakeholders to analyze and troubleshoot complex production issues.
Prepare and present design and implementation documentation to multiple stakeholders.
Promote automation across the data management and analytics delivery organization.
Provide leadership, coaching, and mentoring to team members and develop team to work with all areas of the organization.
Work with stakeholders to ensure that business needs are clearly understood and that services meet those needs.
Anticipate and analyze trends in technology while assessing the emerging technology’s impact(s).
Coach individuals and teams through change and serve as a role model.
Perform other duties as assigned.



Basic Qualifications


Bachelor’s Degree (Computer Science, Business Administration, Economics or related fields) or equivalent relevant work experience
7+ years’ experience in automation engineering, software engineering, or related field
7+ years’ experience with one or more coding languages (e.g., JavaScript, C++, Python, Java), CI/CD tools (e.g., Jenkins, Artifactory, CircleCI, Ansible), and development platforms (e.g., AWS, Azure, Docker, Kubernetes)



Preferred Qualifications


Experience developing CI/CD workflows and tools
Strong automation scripting skills
Experience in configuration management, test-driven development, and release management
Strong analytical and troubleshooting skills
Experience with agile development and strong understanding of DataOps and ModelOps principles
Ability to investigate and analyze information, and to draw conclusions
Flexibility, adaptability, and desire to learn new languages and technologies
Strong verbal and written communication skills
Demonstrated ability to work independently across multiple tasks while meeting aggressive timelines
Strategic, intellectually curious thinker with focus on outcomes
Financial Services background
Professional image with the ability to form relationships across functions
Ability to train more junior analysts regarding day-to-day activities, as necessary
Proven ability to lead cross-functional efforts
Willingness and ability to learn new technologies on the job



Exempt Status: (Yes = not eligible for overtime pay) (No = eligible for overtime pay)

Yes

Workplace Type

Hybrid

Huntington is an equal opportunity and affirmative action employer and is committed to providing equal employment opportunities for all regardless of race, color, religion, sex, national origin, age, disability, sexual orientation, veteran status, gender identity and expression, genetic information, or any other basis protected by local, state, or federal law.

Tobacco-Free Hiring Practice: Visit Huntington's Career Web Site for more details.

Agency Statement: Huntington does not accept solicitation from Third Party Recruiters for any position
Show more "
MLOps Engineer,Apex Systems,United States,2024-08-23,https://www.linkedin.com/jobs/view/mlops-engineer-at-apex-systems-4008885230?position=10&pageNum=7&refId=W2XzjnKjbjuKFKWRryCPmQ%3D%3D&trackingId=lbVMNZy2jGyBAq8cnTe5Bw%3D%3D&trk=public_jobs_jserp-result_search-card,"Job#: 2043671

Job Description:

Job Title: MLOps Engineer

Job Location: Columbus, OH or Minnetonka, MN

Pay Range: $51/hr-$59/hr

Contract Length: 3 Months (Contract-to-Hire)

About Us:

We are a forward-thinking team within a large enterprise bank, deeply invested in leveraging machine learning and artificial intelligence to drive impactful business outcomes. Our team is responsible for ensuring the smooth, scalable and secure deployment of machine learning models into production, handling both real-time and batch processing workloads. We offer a unique opportunity to work closely with data scientists and engineers, focusing on large language models and cutting-edge MLOps practices.

Job Summary:

As an MLOps Engineer, you will be responsible for the end-to-end productionization and deployment of machine learning models at scale. You will work closely with data scientists to refine models and ensure they are optimized for production. Additionally, you will be responsible for maintaining and improving our MLOps infrastructure, automating deployment pipelines, and ensuring compliance with IT and security standards. You will play a critical role in image management, vulnerability remediation, and the deployment of ML models using modern infrastructure-as-code practices.

Key Responsibilities:


Vulnerability Remediation & Image Management:
Manage and update Docker images, ensuring they are secure and optimized.
Collaborate with data scientists to validate that models run effectively on updated images.
Address security vulnerabilities by updating and patching Docker images.
AWS & Terraform Expertise:
Deploy, manage, and scale AWS services (SageMaker, S3, Lambda) using Terraform.
Automate the spin-up and spin-down of AWS infrastructure using Terraform scripts.
Monitor and optimize AWS resources to ensure cost-effectiveness and efficiency.
DevOps & CI/CD Pipeline Management:
Design, implement, and maintain CI/CD pipelines in Azure DevOps (ADO).
Integrate CI/CD practices with model deployment processes, ensuring smooth productionization of ML models.
Strong experience with Git for code versioning and collaboration.
Model Productionization:
Participate in the end-to-end process of productionizing machine learning models, from model deployment to monitoring and maintaining their performance.
Work with large language models, focusing on implementing near real-time and batch inferences.
Address data drift and model drift in production environments.
Collaboration & Continuous Learning:
Work closely with data scientists, DevOps engineers, and other MLOps professionals to ensure seamless integration and deployment of ML models.
Stay updated on the latest trends and technologies in MLOps, especially related to AWS and Docker.


Required Skills & Qualifications:


Python: Deep expertise in Python for scripting and automation.
AWS: Strong experience with AWS services, particularly SageMaker, S3, and Lambda.
Terraform: Proficiency in using Terraform for infrastructure-as-code on AWS.
Docker: Extensive experience with Docker, including building, managing, and securing Docker images.
Linux: Strong command-line skills in Linux, especially for Docker and system management.
DevOps Experience: Azure DevOps (ADO): Significant experience in setting up and managing CI/CD pipelines in ADO.
Git: Proficient in using Git for version control and collaboration.
Additional DevOps Tools: Experience with Jenkins or other CI/CD tools is a plus.
Experience & Education: 4 years of experience in combination of MLOps/DevOps/Data Engineering; Bachelors degree in Computer Science, Engineering, or a related discipline.


Preferred Qualifications:


Experience with large language models and productionizing ML models in a cloud environment.
Exposure to near real-time inference systems and batch processing in ML.
Familiarity with data drift and model drift management.


EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at [email protected] or 844-463-6178 .

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing® in Talent Satisfaction in the United States and Great Place to Work® in the United Kingdom and Mexico.

Apex Systems is a world-class IT services company that serves thousands of clients across the globe. When you join Apex, you become part of a team that values innovation, collaboration, and continuous learning. We offer quality career resources, training, certifications, development opportunities, and a comprehensive benefits package. Our commitment to excellence is reflected in many awards, including ClearlyRated's Best of Staffing® in Talent Satisfaction in the United States and Great Place to Work® in the United Kingdom and Mexico.

4400 Cox Road

Suite 200

Glen Allen, Virginia 23060

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at [email protected] (Do not submit resumes or solicit consultants to this email address). UnitedHealthcare creates and publishes the Transparency in Coverage Machine-Readable Files on behalf of Apex Systems.
Show more "
"AI/ML, NLP Engineer",Action Tech,United States,2024-08-23,https://www.linkedin.com/jobs/view/ai-ml-nlp-engineer-at-action-tech-3994797845?position=1&pageNum=10&refId=x1ovfniROMtHNHlZBFkRPg%3D%3D&trackingId=6UWJOFsoq2f%2BvzdPQwMfkQ%3D%3D&trk=public_jobs_jserp-result_search-card,"This opportunity is a hybrid position that requires 4 days onsite in either NYC or Greenwich, CT.

All candidates must be US Citizens or Green card holders and already be local to the tri-state area!

AVP or VP level role available!




Job Description

The AI/ML team is developing cutting edge solutions to establish a unique competitive edge for the firm. As a senior AI/ML - NLP Engineer on our team, you will be responsible for designing, developing, and implementing AI/ML models for natural language processing (NLP) applications. This would involve working with large datasets, selecting appropriate algorithms and techniques, training or fine-tuning models to achieve optimal performance, and deploying and monitoring model performance in production. You will be working in a collaborative team environment across product management, data engineering, and software engineering teams. If you are passionate about leveraging machine learning techniques to drive innovation and have a strong background in developing scalable solutions, we would love to hear from you.

Responsibilities

Design, develop, train, and deploy AI/ML models to solve business problems through a full development and production cycle in the FinTech domain.
Evaluate and compare the performance of different AI/ML algorithms and models.
Utilize and improve Machine Learning Operations (MLOps) pipelines and procedures to ensure efficiency, scalability, and maintainability.
Ensure the reliability, robustness, and scalability of machine learning models in production environments.
Collaborate with cross-functional teams, including product managers and full stack engineers, to deliver scalable machine learning solutions.
Understand business requirements, communicate with stakeholders, and mentor junior team members.

Qualifications

4-6+ (mid-career) years of experience as a hands-on data scientist or AI/ML engineer in AI/ML/DS fields.
Advanced degree (Masters, PhD) in a relevant field (AI/ML/DS, mathematics, computer science, etc.).
Solid understanding of Natural Language Processing techniques, including text classification, named entity recognition, and information extraction.
Experience working with Large Language Models, such as GPT-4, Liama 2, and other commercial or open-source models in production environment.
Proficiency in programming languages commonly used in NLP, such as Python, and libraries/frameworks like TensorFlow, PyTorch, or spaCy and strong understanding of software engineering principles and best practices.
Strong knowledge of NLP techniques, including text data preprocessing (tokenization, stemming, and text normalization, etc.) and information extraction (summarization, and question answering, etc.)
Knowledge of machine learning algorithms and statistical techniques, their limitations and implementation challenges
Experience with cloud platforms and distributed computing environments for NLP tasks, such as AWS, Google Cloud, or Azure
Experience with software development best practices, including source control (Git), CI/CD pipelines, testing, and documentation.
Excellent problem-solving skills and the ability to work independently and collaboratively in a fast-paced, agile environment.
Strong communication skills and the ability to effectively articulate technical concepts to both technical and non-technical audiences.

Nice to Haves:

Publications, conference talks, and/or patents in AI/ML/DS or related fields
Experience with data visualization tools and techniques to effectively communicate and present findings.
Experience with data transformation tool (such as dbt) and orchestration tool (such as Airflow).
Portfolio of personal projects on Github, BitBucket, Google Colab, Kaggle, etc.
Experience working in Finance or Financial Technology (FinTech). Understanding of regulatory and compliance requirements in the financial industry and their implications for machine learning applications.
Show more "
Senior Engineer (AI/ML),TD,United States,2024-08-31,https://ca.linkedin.com/jobs/view/senior-engineer-ai-ml-at-td-3988474919?position=2&pageNum=10&refId=x1ovfniROMtHNHlZBFkRPg%3D%3D&trackingId=%2F36zKPAyp2%2BDqQ9lKgdGsw%3D%3D&trk=public_jobs_jserp-result_search-card,"Work Location:

Canada

Hours:

37.5

Line Of Business:

Technology Solutions

Pay Details:

We’re committed to providing fair and equitable compensation to all our colleagues. As a candidate, we encourage you to have an open dialogue with a member of our HR Team and ask compensation related questions, including pay details for this role.

Job Description:

Our passion is to advance the organization by enabling Azure AI and ML capability for the enterprise

to solve business problems and deliver TD products faster.

We are looking for a senior AI / ML Platform Engineer to deliver enterprise data services/capabilities

and solutions on Azure and GCP. The perfect candidate will have previous AI / ML cloud experience

delivering enterprise data solutions within financial services including knowledge of the security and

regulatory requirements. The role is focused on AI and ML service enablement along with applying

AIOPs best practices to and engineering principals to the platform.

You will work in collaboration with cloud engineering, network, security, AI governance groups, and

Model risk management to deliver secured Azure AI and ML solutions that meet security policies and

standards within TD. You will collaborate with developers in our platform engineering team and

lines of business to implement and continuously improve the framework and tools to support self-

service automation of the AI and ML services.

Job Description


Contribute toward the vision and strategy for Generative AI and Machine Learning
Passionate about deep learning and natural language models
AIOps/MLOps mindset enabling services and developing pipelines for managing training models and production models.
Collaborate with internal application development teams to leverage AI/ML services to solve business objectives.
Deliver AI / ML POCs to demonstrate examples of how business can solve issues, help train on specific use cases and generate business value
Understand security, risks and mitigations to load data and training models securely into Cloud Partnering with various control partners to help establish AI Security & Governance standards and processes to support GenAI application and model usage
Partner with Enterprise architecture to establish GenAI Reference architecture/framework and patterns Help formulate platform strategy & approach for expanding AI/ML across the hybrid cloud landscape


Job Requirements


3+ years AI and ML engineering experience – Azure AI stack or equivalent
Working knowledge of Google GCP AI stack (Vertex.AI, BigQuery...) a plus
5+ years of experience developing platform orchestration code in Azure Python SDK, Terraform and GitHub Runners
Strong Prompt Engineering, Python Development and REST API skills
Strong expertise with delivering Cloud Infrastructure as Code (IAC) leveraging CI/CD pipelines, Terraform and Github Actions.
Demonstrated knowledge of cloud provisioning and administration, cloud bursting, cloud interoperability, cloud disaster recovery and business continuity strategies, as well as performance measurement and monitoring in the cloud
Must be a self-starter, demonstrated ability to take independent action to achieve results.
Highly developed critical thinking, analytical and problem-solving skills
Understanding of different GenAI models, development frameworks (Langchain, Semantic Kernel) and AI ecosystem tooling (evaluation, monitoring, governance, security, vector databases)
Ability to understand and identify security risks related to GenAI and techniques.
Understanding of major components of RAG applications, usage patterns, and optimization


Who We Are:

TD is one of the world's leading global financial institutions and is the fifth largest bank in North America by branches/stores. Every day, we deliver legendary customer experiences to over 27 million households and businesses in Canada, the United States and around the world. More than 95,000 TD colleagues bring their skills, talent, and creativity to the Bank, those we serve, and the economies we support. We are guided by our vision to Be the Better Bank and our purpose to enrich the lives of our customers, communities and colleagues.

TD is deeply committed to being a leader in customer experience, that is why we believe that all colleagues, no matter where they work, are customer facing. As we build our business and deliver on our strategy, we are innovating to enhance the customer experience and build capabilities to shape the future of banking. Whether you’ve got years of banking experience or are just starting your career in financial services, we can help you realize your potential. Through regular leadership and development conversations to mentorship and training programs, we’re here to support you towards your goals. As an organization, we keep growing – and so will you.

Our Total Rewards Package

Our Total Rewards package reflects the investments we make in our colleagues to help them and their families achieve their financial, physical, and mental well-being goals. Total Rewards at TD includes a base salary, variable compensation, and several other key plans such as health and well-being benefits, savings and retirement programs, paid time off, banking benefits and discounts, career development, and reward and recognition programs. Learn more

Additional Information:

We’re delighted that you’re considering building a career with TD. Through regular development conversations, training programs, and a competitive benefits plan, we’re committed to providing the support our colleagues need to thrive both at work and at home.

Colleague Development

If you’re interested in a specific career path or are looking to build certain skills, we want to help you succeed. You’ll have regular career, development, and performance conversations with your manager, as well as access to an online learning platform and a variety of mentoring programs to help you unlock future opportunities. Whether you have a passion for helping customers and want to expand your experience, or you want to coach and inspire your colleagues, there are many different career paths within our organization at TD – and we’re committed to helping you identify opportunities that support your goals.

Training & Onboarding

We will provide training and onboarding sessions to ensure that you’ve got everything you need to succeed in your new role.

Interview Process

We’ll reach out to candidates of interest to schedule an interview. We do our best to communicate outcomes to all applicants by email or phone call.

Accommodation

Your accessibility is important to us. Please let us know if you’d like accommodations (including accessible meeting rooms, captioning for virtual interviews, etc.) to help us remove barriers so that you can participate throughout the interview process.

We look forward to hearing from you!

Language Requirement:

N/A.
Show more "
Principal AI/ML Engineer (MLOps focus),Optum,United States,2024-08-27,https://www.linkedin.com/jobs/view/principal-ai-ml-engineer-mlops-focus-at-optum-4009450092?position=4&pageNum=10&refId=x1ovfniROMtHNHlZBFkRPg%3D%3D&trackingId=yccSeAuZperu51A%2BwUXNlw%3D%3D&trk=public_jobs_jserp-result_search-card,"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data, and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits, and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together.

Optum AI is chartered to drive value on high impact enterprise AI problems, democratize AI through the enterprise ML platform, accelerate the adoption of Generative Artificial Intelligence (Gen AI) and drive Responsible AI. Projecting to deliver $8.4B of benefit value over the next 5 years through these efforts as well as reduce risk through safe, accurate, and unbiased AI, this is a key focus of the enterprise.

As the Principal AI/ML Engineer, you will be responsible for the development and execution of the vision for enabling the design and deployment of high impact enterprise AI problems, including problems related to disease prediction and identification, patient engagement, and optimization of clinical trials using both structured and unstructured (text) data. As a thought leader, you will establish guidance on how to develop, execute, and deploy AI models in compliance with enterprise standards. As a subject matter expert, you will work closely with other engineering teams and leaders to drive the adoption of quality and efficiency standards.

You’ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges.

Primary Responsibilities:

Develop and execute the vision for engineering platforms, and reusable code that will be used by thousands of other engineers for automation and improved efficiency of AI/ML development
Stay up to date with latest technologies and literature recommending solutions to improve business goals
Evangelize the benefits of the AI models and platforms built in our team to drive adoption for employees and functional roles across the UHG enterprise including technology, operations, marketing, legal, compliance, people team, internal infrastructure, and more
Mentor data scientists, AI/ML scientists, and other engineers to ensure the delivery of the AI/ML projects, and provide guidance on how to best use specific tools or technologies to achieve the desired results
Collaborate with cross-functional teams to determine applicability of AI to business problems
Closely collaborate with the Responsible Use of AI (RUAI) team to ensure that the delivered solutions are compliant with the company policies and standards
Create and manage best practices for ML models integration, orchestration, and deployment, that will ensure secure, consistent, and efficient use of resources across the UHG enterprise, including data versioning, ingress and model output egress, CI/CD pipelines for MLOps and DevOps functions
Automate the provisioning and configuration of infrastructure resources
Create documentation for infrastructure design and deployment procedures

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Qualifications - External

Required Qualifications:

Bachelor’s degree in computer science, Math, Statistics, or a related STEM field with equivalent experience (Either 10+ years of experience in a technical engineering role, or a PhD in Computer Science or a related field and 5+ years engineering role)
3+ years of experience focused on AI/ML solutions delivery
Demonstrated experience leading and implementing AI/ML projects from ideation to delivery, evaluation, and maintenance in production
Proven experience in Python and one of PySpark or Scala, including demonstrable proficiency of AI/ML frameworks and tools (e.g., MLFlow, TensorFLow, PyTorch)
Experience developing and deploying data pipelines, machine learning models, or applications on cloud platforms (e.g., Azure, AWS, Databricks, AzureML)
Demonstrated experience in Gen AI solution pipeline engineering, (e.g., RAG) and Large Language Modeling and Transformer Architectures (e.g., BERT, GPT, etc.)
Proven presentation experience with the ability to explain complex AI/ML concept and results to technical and non-technical audiences

Preferred Qualifications:

A graduate degree (Master’s or PhD) in computer science, Mathematics, Statistics, or a related STEM discipline
Experience in healthcare (AI)
Experience working with cross-functional and distributed teams in a global and diverse environment
Experience in mentoring and coaching AI/ML talent
Experience in establishing AI/ML best practices, standards, and ethics
A portfolio of AI/ML publications, patents, or awards
Working knowledge of Software Development tools and practices including DevOps and CI/CD tools (e.g., Git, Jenkins, Docker, Kubernetes, etc.)
Security and vulnerability management (package scans, remediation)
Familiarity with data versioning tools (Delta Lake, DVC, LakeFS, etc.)
Experience with model observability tools for insights into the behavior, performance, and health of your deployed ML models (tracking, alerting, compliance monitoring, etc.)

*All employees working remotely will be required to adhere to UnitedHealth Group’s Telecommuter Policy.

California, Colorado, Connecticut, Hawaii, Nevada, New Jersey, New York, Rhode Island, Washington, Washington, D.C. Residents Only: The salary range for this role is $122,100 to $234,700 annually. Pay is based on several factors including but not limited to local labor markets, education, work experience, certifications, etc. UnitedHealth Group complies with all minimum wage laws as applicable. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives.

Application Deadline: This will be posted for a minimum of 2 business days or until a sufficient candidate pool has been collected. Job posting may come down early due to volume of applicants.

At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone–of every race, gender, sexuality, age, location and income–deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes — an enterprise priority reflected in our mission.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.

Show more "
"ML Ops Engineer, Central Tech",Chan Zuckerberg Initiative,United States,2024-08-28,https://www.linkedin.com/jobs/view/ml-ops-engineer-central-tech-at-chan-zuckerberg-initiative-3995190629?position=6&pageNum=10&refId=x1ovfniROMtHNHlZBFkRPg%3D%3D&trackingId=2Yy%2BrpmIRXQbrTMxPeOG9g%3D%3D&trk=public_jobs_jserp-result_search-card,"The Chan Zuckerberg Initiative was founded by Priscilla Chan and Mark Zuckerberg in 2015 to help solve some of society’s toughest challenges — from eradicating disease and improving education to addressing the needs of our local communities. Our mission is to build a more inclusive, just, and healthy future for everyone.

The Team

Across our work in Science, Education, and within our communities, we pair technology with grantmaking, impact investing, and collaboration to help accelerate the pace of progress toward our mission. Our Central team provides the support needed to push this work forward.

The Central team at CZI consists of our Finance, People & DEI, Real Estate, Events, Workplace, Facilities, Security, Brand & Communications, Business Systems, Central Operations, Strategic Initiatives, and Ventures teams. These teams provide strategic support and operational excellence across the board at CZI.

The AI/ML Infrastructure team works on building shared tools and platforms to be used across the Chan Zuckerberg Initiative, partnering and supporting the work of an extensive group of Research Scientists, Data Scientists, AI Research Scientists, as well as a broad range of Engineers focusing on Education and Science domain problems. Members of the shared infrastructure engineering team have an impact on all of CZI's initiatives by enabling the technology solutions used by other engineering teams at CZI to scale.

The Opportunity

By pairing engineers with leaders in our science and education teams, we can bring AI/ML technology to the table in new ways to help drive AI powered solutions that accelerate Biomedical research. We are uniquely positioned to design, build, and scale software systems to help educators, scientists, and policy experts better address the myriad challenges they face. We are supporting researchers and scientists around the world by developing the capacity to apply state-of-the-art methods in artificial intelligence and machine learning to solve important problems in the biomedical sciences.

As a member of the AI Infrastructure and MLOps Engineering team, you will be responsible for a variety of MLOps and AI development projects that empower users across the AI lifecycle. You will take an active role in building and operating our AI Systems Infrastructure and MLOps efforts focused on our GPU Cloud Cluster operations, ensuring our systems are highly utilized and stable across the AI lifecycle of usage.

We are building a world-class shared services model, and being based in New York helps us achieve our service goals. We require all interested candidates to be based out of New York City and available to work onsite 2-3 days a week.

What You'll Do


As a member of the MLOps team responsible for the operations of our large scale GPU Research cluster, you will be intimately involved in the end to end AI lifecycle working directly with our AI Research and AI Engineers, pre-training through training through fine tuning and through inference for the models we deploy and host.
Take an active role in building out our model deployment automation, alerting, and monitoring systems, allowing us to automate and operate our GPU Cluster in a proactive way that reduces reactive on-call efforts to a minimum.
Work on the integration and usability of our MLFlow based model versioning and experiment tracking as part of the platform and integral across the AI lifecycle.
As part of the on-call responsibilities, you will be working with our vendor partners in troubleshooting and resolving issues in as short of a time frame as is possible on our Kubernetes based GPU Cluster.
Actively collaborate in the technical design and build of our AI/ML and Data infrastructure engineering solutions, such as deep MLFlow integration.
Be an active part of optimizing our GPU platform and model training processes, from the hardware level on up through our Deep Learning code and libraries.
Collaborate with team members in the design and build of our Cloud based AI/ML data platform solutions, which includes Databricks Spark, Weaviate Vector Databases, and supporting our hosted Cloud GPU Compute services running containerized PyTorch on large scale Kubernetes.
Collaborate with our AI Researchers on data management solutions for our heterogeneous collection of complex very large scale training datasets.
As a team take part in defining and implementing our SRE style service level indicator instrumentation and metrics gathering, alongside defining SLOs and SLAs for our model platform end to end.


What You'll Bring


BS, MS, or PhD degree in Computer Science or a related technical discipline or equivalent experience.
MLOps experience working with medium to large scale GPU clusters, in Kubernetes (preferred) or HPC environments, or large scale Cloud based ML deployments.
Experience using DevOps tooling with data and machine learning use cases. Experience with scaling containerized applications on Kubernetes or Mesos, including expertise with creating custom containers using secure AMIs and continuous deployment systems that integrate with Kubernetes (preferred) or Mesos.
5+ years of relevant coding experience with a scripting language such as Python, PHP, or Ruby.
Experience coding with a systems language such as Rust,C/ C++, C#, Go, Java, or Scala.
Data platform operations experience in an environment with challenging data and systems platform challenges - such as Kafka, Spark, and Airflow.
Experience with Amazon Web Services (AWS), Google Cloud Platform (GCP), or Microsoft Azure - experience with On-Prem and Colocation Service hosting environments a plus.
Knowledge of Linux systems optimization and administration.
Understanding of Data Engineering, Data Governance, Data Infrastructure, and AI/ML execution platforms.


Compensation

The Redwood City, CA base pay range for this role is $190,000 - $238,000. New hires are typically hired into the lower portion of the range, enabling employee growth in the range over time. Actual placement in range is based on job-related skills and experience, as evaluated throughout the interview process. Pay ranges outside Redwood City are adjusted based on cost of labor in each respective geographical market. Your recruiter can share more about the specific pay range for your location during the hiring process.

Benefits For The Whole You

We’re thankful to have an incredible team behind our work. To honor their commitment, we offer a wide range of benefits to support the people who make all we do possible.


CZI provides a generous employer match on employee 401(k) contributions to support planning for the future.
Annual benefit for employees that can be used most meaningfully for them and their families, such as housing, student loan repayment, childcare, commuter costs, or other life needs.
CZI Life of Service Gifts are awarded to employees to “live the mission” and support the causes closest to them.
Paid time off to volunteer at an organization of your choice.
Funding for select family-forming benefits.
Relocation support for employees who need assistance moving to the Bay Area
And more!


Commitment to Diversity

We believe that the strongest teams and best thinking are defined by the diversity of voices at the table. We are committed to fair treatment and equal access to opportunity for all CZI team members and to maintaining a workplace where everyone feels welcomed, respected, supported, and valued. Learn about our diversity, equity, and inclusion efforts.

If you’re interested in a role but your previous experience doesn’t perfectly align with each qualification in the job description, we still encourage you to apply as you may be the perfect fit for this or another role.

Explore our work modes, benefits, and interview process at www.chanzuckerberg.com/careers.


Show more "
Machine Learning Engineer,eTeam,United States,2024-08-09,https://ca.linkedin.com/jobs/view/machine-learning-engineer-at-eteam-3996687313?position=7&pageNum=10&refId=x1ovfniROMtHNHlZBFkRPg%3D%3D&trackingId=Mrl1K33RVbD9AYL2tI2xrA%3D%3D&trk=public_jobs_jserp-result_search-card,"Title: Machine Learning Enfgineer

Location: Montreal, QC

Duration: 09 Months

Pay rate: $90/hr to $100/hr without any benefits




Responsibilities: The Machine Learning (ML) Expert will:

• Understand the business needs and requirements and translate them into ML solutions.

• Communicate technical concepts and results to non-technical stakeholders in a clear and concise manner.

• Collaborate with internal clients to identify new opportunities for ML applications and models.

• Ensure that ML Models are aligned with the bank’s overall strategy and goals. • Work with Application Development teams to deploy and support ML models in production environments.

• Stay up to date with latest development in ML and AI and apply this knowledge to first improve the performances of applications (current & past), and second to the benefits of the team.




Minimum Required Qualifications

• Master’s degree in computer science, mathematics, statistics, or a related field.

• Strong programming skills in languages such as Python, database manipulation (SQL), statistical modeling, and data analysis techniques.

• Experience with machine learning frameworks such as Tensorflow, PyTorch, or scikit-learn.

• Experience in developing and working on real-world machine learning projects.

• Strong problem-solving and analytical skills.

• Excellent communication (both French and English) and collaboration skills.

• Very strong work ethic and ability to deal with confidential information.




Nice-to-have Qualifications

• Experience in deploying models to production.

• Experience with CI/CD pipelines (GIT, Jenkins, …) and MLOps (MLFlow).

• Experience with containerization techniques (Docker & Kubernetes).

• Experience with mentoring junior team members.

Show more "
Machine Learning Engineer,Caylent,United States,2024-08-21,https://mx.linkedin.com/jobs/view/machine-learning-engineer-at-caylent-4004392502?position=8&pageNum=10&refId=x1ovfniROMtHNHlZBFkRPg%3D%3D&trackingId=oWsUcdYMkXzMAlJUpXRsGw%3D%3D&trk=public_jobs_jserp-result_search-card,"Caylent is a cloud native services company that helps organizations bring the best out of their people and technology using Amazon Web Services (AWS). We provide a full-range of AWS services including: workload migrations & modernization, cloud native application development, DevOps, data engineering, security & compliance and everything in between. At Caylent, our people always come first.

We are a fully remote global company with employees in Canada, the United States and Latin America. We celebrate the culture of each of our team members and foster a community of technological curiosity. Come talk to us to learn more about what it means to be a Caylien!

The Mission

At Caylent, a Machine Learning Engineer works as an integral part of a cross-functional delivery team to design and document machine learning solutions on the AWS cloud for our customers. We are looking for someone that has a strong understanding of the various model types and tools, and can help our customers connect their business goals with the details of feature design, model training and inference. You will also have a weekly 1:1 with your manager to help guide you in your career and make the most of your time at Caylent.

Your Assignments


Work with a team to deliver machine learning solutions on AWS for customers
Participate in and contribute to daily standup meetings
Develop and implement ML models, MLOps, and analytics
Big data processing and preparation of training data for models


Your Qualifications


At least 3 years of hands on experience in at least a few of these ML tools/techniques:
Build ML models in SageMaker
Build ML models in frameworks like Tensorflow & PyTorch and deploy in SageMaker
Train and deploy AWS pre-trained AI Services and Foundational Models
Build and optimize models using feature definition, activation functions, hyperparameter tuning and other techniques
Integrate ML models into real-time applications and batch workflows, recommend better infrastructure design and optimization
Monitor, evaluate and continuously improve model performance, as well as automate these tasks using one or more tools for MLOps
Hands on experience in these data engineering tools/techniques:
Data integration, cleansing, transformation, and visualization using Python packages, SQL etc.
AWS services such as Glue, EMR, Athena, DynamoDB, StepFunctions, EKS etc.
Experience with an IaC tool such as CloudFormation, CDK or Terraform
Excellent written and verbal communication skills


Benefits


100% remote work
Medical Insurance for you and eligible dependents
Generous holidays and flexible PTO
Competitive phantom equity
Paid for exams and certifications
Peer bonus awards
State of the art laptop and tools
Equipment & Office Stipend
Individual professional development plan
Annual stipend for Learning and Development
Work with an amazing worldwide team and in an incredible corporate culture


Caylent is a place where everyone belongs. We celebrate diversity and are committed to creating an inclusive environment for all employees. Our approach helps us to build a winning team that represents a variety of backgrounds, perspectives, and abilities. So, regardless of how your diversity expresses itself, you can find a home here at Caylent.

We are proud to be an equal opportunity employer. We prohibit discrimination and harassment of any kind based on race, color, religion, national origin, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, veteran status, genetic information, disability, or other applicable legally protected characteristics. If you would like to request an accommodation due to a disability, please contact us at hr@caylent.com.
Show more "
Machine Learning (ML) Expert,Hudson Data LLC,United States,2024-08-16,https://www.linkedin.com/jobs/view/machine-learning-ml-expert-at-hudson-data-llc-4002456702?position=9&pageNum=10&refId=x1ovfniROMtHNHlZBFkRPg%3D%3D&trackingId=ditXgiNYZW52OdYGIZM2EQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Job Title: Machine Learning (Client) Expert (Banking Domain)

Location: Jersey City, NJ (Web Cam Interview)

Duration: Long Term (W2)

H1 Transfer/ GC/ Citizen

Responsibilities:

Job Description:

The Machine Learning (Client) Expert Will:

""Understand the business needs and requirements and translate them into Client solutions.

""Communicate technical concepts and results to non-technical stakeholders in a clear and concise manner.

""Collaborate with internal clients to identify new opportunities for Client applications and models.

""Ensure that Client Models are aligned with the bank's overall strategy and goals.

""Work with Application Development teams to deploy and support Client models in production environments.

""Stay up to date with latest development in Client and AI and apply this knowledge to first improve the performances of applications (current & past), and second to the benefits of the team.

Minimum Required Qualifications

""Master's degree in computer science, mathematics, statistics, or a related field.

""Strong programming skills in languages such as Python, database manipulation (SQL), statistical modeling, and data analysis techniques.

""Experience with machine learning frameworks such as Tensorflow, PyTorch, or scikit-learn.

""Experience in developing and working on real-world machine learning projects.

""Strong problem-solving and analytical skills.

""Excellent communication (both French and English) and collaboration skills.

""Very strong work ethic and ability to deal with confidential information.

Nice-to-have Qualifications

""Experience in deploying models to production.

""Experience with CI/CD pipelines (GIT, Jenkins, ...) and MLOps (MLFlow).

""Experience with containerization techniques (Docker & Kubernetes).

""Experience with mentoring junior team members. Job Title: Machine Learning (Client) Expert (Banking Domain)

Location: Jersey City, NJ (Web Cam Interview)

Duration: Long Term (W2)

H1 Transfer/ GC/ Citizen

Nice-to-have Qualifications

""Experience in deploying models to production.

""Experience with CI/CD pipelines (GIT, Jenkins, ...) and MLOps (MLFlow).

""Experience with containerization techniques (Docker & Kubernetes).

""Experience with mentoring junior team members.
Show more "
Machine Learning Engineer,Harnham,United States,2024-08-19,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-harnham-4004818313?position=10&pageNum=10&refId=x1ovfniROMtHNHlZBFkRPg%3D%3D&trackingId=z29Tid9BOF7w5p1s6BpGAA%3D%3D&trk=public_jobs_jserp-result_search-card,"Machine Learning Engineer

Flatiron, New York City – IN-PERSON ROLE 5 DAYS PER WEEK

$170,000 - $$200,000




Harnham is currently partnered with an innovative hypergrowth tech start up that is based out of NYC. This company is focused on creating an AI service for financial and accounting firms to automate workflows with the end goal of saving time and money.




THE ROLE

IN PERSON 5 DAYS PER WEEK; FLATIRON NYC
Deploy, manage, and scale machine learning models in production environments
Maintain the system and make sure it is responsible over time
Move research into the production world; strong backend capabilities to contribute to the production code base
Data cannot be wrong- needs to be able to scale models efficiently and accurately
Organize, scale, and maintain many models that operate in tandem
Evaluate and monitor machine learning pipelines
Heavily work on data pipelines and the engineering side of business; be ready to own and scale




YOUR SKILLS AND EXPERIENCE

Proficient in Python
Proven track record of putting models into production
Have completed a project from scratch (0-1 architecting, planning, and scaling)
Experience working in an accounting environment would be ideal (Other types of financial data are also great i.e. Quickbooks, Plaid, and downstream financial data)
Has been in a hyper-growth start-up environment that has previously gone through rounds of funding
Strong across LLMs, backend, and product side of business




THE BENEFITS

A competitive base salary of $170,000 - $200,000 will be offered + Equity.




HOW TO APPLY

Please register your interest by sending your resume to Grace McCarthy via the Apply link on this page.




KEYWORDS

Machine Learning | Accounting | FinTech | Start Up | Funding | Python | MLOPs | Research | 0-1 | Infrastructure | Deployment | Scale | Deep Learning

Show more "
Machine Learning Engineer(Strictly W2),"TekVivid, Inc",United States,2024-08-06,https://www.linkedin.com/jobs/view/machine-learning-engineer-strictly-w2-at-tekvivid-inc-3994723756?position=1&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=8znDe7G4ZLV04MirPrYMyQ%3D%3D&trk=public_jobs_jserp-result_search-card,"Hello

Hope you are doing well,

This is Bheem from Tekvivid INC, I just wanted to check if you or someone you know may be interested in the following position.

Please go through the below requirement and please share me an updated resume at your earliest convenience, so that we may support your candidacy for the role. I sincerely appreciate you referring this requirement to anyone that you know who might be interested in case of your unavailability.

Job Title: Machine Learning Engineer(Strictly W2)

Location: Arlington, VA & Boston MA - Onsite

Duration: 12 Months+

Job Description Overview:

• Client is building next generation software, hardware, and processes that will run our global network of fulfilment centers that move millions of units of inventory, and ensure customers get what they want when promised.

• The Business Analytics and Decision Support (BADS) team automates the ingestion and curation of data for analyses, business reviews and operational reporting demands.

• Our north star is to enable and leverage the power of data to drive informed decision-making and value through analytical and scientifically derived insights and innovative solutions and processes. 

• As a Machine Learning Engineer within our BADS team, you will work closely with science teams to bring research to production.

• This is a role that combines engineering knowledge (around machine learning, natural language processing, computer vision), technical strength, and product focus. 

• It will be your job to implement novel ML systems, product integrations, and performance optimizations releases into production.

• While ensuring CI/CD compliance and ensuring best practices in software development and cloud infrastructure are followed (in the realm of scalability, security and availability).

Key job responsibilities 

• Own the development and operationalization of solutions deployed in production. 

• Work across multiple teams to integrate our solutions with products owned by our partners. 

• Design model experimentation processes and frameworks in synergy with our scientists. 

• Help the team grow and cultivate best practices in software development, MLOps, and experimentation. 

• Model training, data pre-processing 

Story Behind the Need – Business Group & Key Projects 

• BADS Team requires a MLE (Machine Learning Engineer) to complete productionalization of our ML models support operations efficiency gains. 

Work that will not get completed without this resource(s):

• BADS Team will not be able to scale nor productionalize our models and will remain within the research milestones. 

Typical Day in the Role 

• Own the development and operationalization of solutions deployed in production. 

• Work across multiple teams to integrate our solutions with products owned by our partners. 

• Design model experimentation processes and frameworks in synergy with our scientists. 

• Help the team grow and cultivate best practices in software development, MLOps, and experimentation. 

• Model training, data pre-processing, 

• Ongoing support of model and lifestyle. 

Compelling Story & Candidate Value Proposition 

• Industrial automation revolution and help with prediction and optimization for the warehouse distribution network and robotics. 

Candidate Requirements 

• Leadership principles: Insist on the highest standards, bias for action, deliver results. 

Top 3 must-have hard skills 

• 5 years minimum machine learning experience. 

• Bachelors in programming or similar (statistics, mathematical degrees on top of a tech degree would be a plus) 

• AWS development experience, Build within AWS products. 



Enchure Bheem

Sr US IT Recruiter

Phone: 972-597-0151 Ext: 477

Email ID: bheem@tekvividinc.com Website: www.tekvividinc.com

This email is not intended as unsolicited communication. If you wish to stop receiving emails from me and TekVivid Inc, kindly reply with ""Unsubscribe."" Please feel free to reach out with any inquiries or concerns.

Show more "
Principal Machine Learning Ops Engineer,QuantumScape,United States,2024-08-29,https://www.linkedin.com/jobs/view/principal-machine-learning-ops-engineer-at-quantumscape-4011036974?position=2&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=I4iuh7RPHwmy84fmUrZsnw%3D%3D&trk=public_jobs_jserp-result_search-card,"QuantumScape developed the industry’s first anode-less cell design, which delivers high energy density while lowering material costs and simplifying manufacturing. Our innovative battery cell technology can store energy more efficiently and reliably than today’s lithium-ion batteries.

Description:

QuantumScape developed the industry’s first anode-less solid-state battery targeted for automotive use, designed to deliver high energy density and power while lowering material costs and simplifying manufacturing. Our innovative battery cell technology can deliver longer range and faster charging than today’s lithium-ion batteries. Come join us to help build out our MLOps platforms and enable data scientists and engineers to streamline the development, deployment, and monitoring of machine learning models!

Job Summary:

As a MLOps Engineer, you will play an integral role as we build out our MLOps platform and facilitate adoption across QuantumScape. You will work on a team of other domain specific experts in the areas of MLOps, Software Engineering, Data Engineering, and DevOps. You will collaborate closely with data scientists and engineers to design, implement, and maintain scalable ML pipelines within the platform, ensuring efficient and reproducible model training, reliable and scalable deployments, and insightful monitoring.

As a member of the broader Software Team, you will adopt software engineering best practices in every aspect of your work and champion these principles as you work closely with other teams. You will contribute to a platform that empowers data scientists to own their models in production by equipping them with the tools and training necessary to deploy, monitor, and maintain models throughout their lifecycle. You will help cultivate a production focused machine learning culture that bridges the gap between model development and operational success.

Key Responsibilities:

Help design, build, and facilitate adoption of a modern MLOps platform
Modularize complex ML code into standardized and repeatable components
Establish and facilitate adoption of repeatable patterns for model development, deployment, and monitoring
Champion the next level of maturity in all aspects of the ML lifecycle
Directly contribute to solutions that monitor models in production and make results easily available to developers and stakeholders
Leverage workflow orchestration tools to deploy efficient and scalable execution of complex data and ML pipelines
Own and maintain internal Python packages
Review code changes from data scientists and champion software development best practices
Architect and implement sophisticated systems that solve data and machine learning problems end-to-end
Leverage cloud services like Kubernetes, blob storage, and queues in our cloud first environment
Design and contribute to the next level of enterprise data management intended to be the foundation for ML solutions for years to come

Minium Requirements:

B.S. in Computer Science, Data Science, Statistics, Applied Mathematics, or a related field and 10+ years related experience; or M.S. with 8+ years of experience; or Ph.D with 6+ years of experience.
6+ years experience developing and deploying machine learning solutions to production
3+ years experience with MLOps tools like MLFlow, Weights & Biases, Vertex AI etc.
Proficiency distributed computing and orchestration technologies (Kubernetes, Airflow, Prefect, etc.)
Knowledge of infrastructure-as-code tools such as Terraform
Expert level experience with Python
Expert level experience with CI/CD frameworks such as GitHub Actions
Expert level experience with containerization frameworks
Strong analytical and problem solving skills, capable of working in a dynamic environment
Exceptional interpersonal and communication skills

Compensation & Benefits:

Mid-point salary range for this role is $225,800.00. Final base compensation will be based on a candidate’s qualifications. QuantumScape also offers an annual bonus and a generous RSU/Equity package as part of its compensation plan. In addition, we do offer a tremendous benefits plan including employer sponsored health insurance, Employee Stock Purchase Plan (ESPP), and other exciting perks.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive benefits and privileges of employment. Please contact us to request an accommodation.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive benefits and privileges of employment. Please contact us to request an accommodation.

Show more "
AIML Engineer,ApTask,United States,2024-08-05,https://www.linkedin.com/jobs/view/aiml-engineer-at-aptask-3992962730?position=3&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=yjgqyP1oW8%2Fu%2F9nl1BNo6g%3D%3D&trk=public_jobs_jserp-result_search-card,"About Client:

The client provides information technology (IT) services, including business outsourcing, infrastructure technology, and application services. The application service offered by the company includes application development, maintenance, and support. The markets served by the company are financial services and insurance, healthcare, manufacturing, government, transportation, communications, and consumer and retail industries.

Rate Range: $60-$70/Hr

Job Description:

Key Responsibilities:


Participate in developing Generative AI & Traditional AI Platform Capabilities on enterprise on-prem and cloud platforms.
Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI, Azure Client)
Collaborating with Data scientist to optimize the scoring pipeline.
Building automation capabilities to deploy Client Models and LLM Models on the enterprise on-prem platform and cloud platform.
Build and Deploy capabilities for automating model scoring/Inferencing of Client models and LLMs.
Build and Deploy capabilities for data pipeline deployment standardization and model consumption by multiple LOBs.
Collaborate with product owners, devOps team, data scientists, support teams to define and drive end to end model scoring pipelines.
Participate in day-to-day standups for platform capability build.
Provide SME guidance for data science teams on software engineering principles, model deployments, platform capabilities.
Drive AI use case delivery end to end collaborating with Data scientists, Data Engineers, LOB Technology using standardized platform processes and capabilities.
Support Production Issues partnering with production support.


Key Requirements:


5+ years of Python experience
5+ years of big data experience needed (Big Query, Hadoop)
3 years of experience in AIML area (MLOps)
2+ years of experience in developing APIs using Python/FastAPI.
1+ year of Document AI, Agent Builder/GCP search/conversation / Dialogflow - Nice to have
Good to have 1+year of experience in LLM, Generative AI (developing capabilities or dev/ops)
Good to have Experience in developing of API on GCP/Azure/API Gateways
Good to have 1+year of experience in Vector Database, Model Development would be added benefit.


About ApTask:

ApTask is a leading global provider of workforce solutions and talent acquisition services, dedicated to shaping the future of work. As an African American-owned and Veteran-certified company, ApTask offers a comprehensive suite of services, including staffing and recruitment solutions, managed services, IT consulting, and project management. With a focus on excellence, collaboration, and innovation, ApTask provides unparalleled opportunities for professional growth and development. As a member of the ApTask team, you will have the chance to connect businesses with top-tier professionals, optimize workforce performance, and drive success across diverse industries. Join us at ApTask and be part of our mission to empower organizations to thrive while fostering a diverse and inclusive work environment.

Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

Candidate Data Collection Disclaimer:

At ApTask, we prioritize safeguarding your privacy. As part of our recruitment process, certain Personally Identifiable Information (PII) may be requested by our clients for verification and application purposes. Rest assured, we strictly adhere to confidentiality standards and comply with all relevant data protection laws. Please note that we only collect the necessary information as specified by each client and do not request sensitive details during the initial stages of recruitment.

If you have any concerns or queries about your personal information, please feel free to contact our compliance team at businessexcellence@aptask.com .
Show more "
Senior Machine Learning Engineer (MLOps),Altea Healthcare,United States,2024-08-15,https://www.linkedin.com/jobs/view/senior-machine-learning-engineer-mlops-at-altea-healthcare-3999355474?position=4&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=GtHC3aFWoqA1SSV0WGsMfw%3D%3D&trk=public_jobs_jserp-result_search-card,"Senior Machine Learning Engineer, MLOps




ALTEA Healthcare is a leading healthcare organization committed to revolutionizing the delivery of outpatient/post-acute care. We are seeking an experienced Machine Learning Engineer to join our team. The ideal candidate will have a strong background in deploying scalable ML models, including predictive/classification and NLP/NLU models. As an important member of the AI team, this person will contribute significantly to designing, implementing, and deploying various AI/ML product features to improve care delivery and quality for post-acute patients.




Responsibilities:

Develop and deploy production-ready ML models, with a focus on scalability and monitoring across a broad range of applications within healthcare
Write efficient, maintainable, and scalable Python code
Collaborate with machine learning scientists and data engineers to translate prototype code to production-ready code
Set up and maintain end-to-end pipelines including data ingress, egress, model inference, and model retraining
Build high-performance deployment architectures and model monitoring systems
Incorporate feedback from cross-functional teams and refine the ML-driven applications through quick iteration cycles
Maintain best practices of MLOps practices within the healthcare industry
Document the system architecture, design decisions, and codebase to facilitate future maintenance and enhancements.




Requirements:

Bachelor’s or Master’s degree in Engineering, Computer Science, or equivalent experience
At least 6+ years of relevant experience as an MLOps Engineer
6+ years of experience doing MLOps, model monitoring, drift detection, and model retraining
Azure Machine Learning Studio
Experience with transformer-based models and NLP, preferably in a healthcare context
Extensive experience with TensorFlow or PyTorch, and familiarity with HuggingFace
Track record of fine-tuning, running large-scale training jobs, and managing model servers like vLLM, TGI, or TorchServe
Strong proficiency in LangChain, vectorDB and cloud platforms (Azure), model experimentation tools like MLflow, and monitoring tools like Grafana/Splunk, and CI/CD like airflow, gitlab, and Big Data management like Spark, Kafka
Ability to work independently and collaboratively, manage priorities, and deliver high-quality results within project timelines




Job Type: Full-time

Pay: Competitive pay and benefits and extremely valuable startup stock options

Schedule: Full Time

Work Location: Hybrid position in Houston preferred, with remote options available for exceptionally qualified candidates.

Benefits:




401(k)
Dental insurance
Health insurance
Vision insurance

Show more "
AI/ML Engineer,Photon,United States,2024-08-08,https://www.linkedin.com/jobs/view/ai-ml-engineer-at-photon-3994300967?position=5&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=IrVLXQOk2PXSDxQcxRt7jA%3D%3D&trk=public_jobs_jserp-result_search-card,"About the job




Who are we?

For the past 20 years, we have powered many Digital Experiences for the Fortune 500. Since 1999, we have grown from a few people to more than 4000 team members across the globe that are engaged in various Digital Modernization. For a brief 1 minute video about us, you can check https://youtu.be/uJWBWQZEA6o.




Key Responsibilities:

Participate in developing Generative AI & Traditional AI Platform Capabilities on enterprise on-prem and cloud platforms.
Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI, Azure ML)
Collaborating with Data scientist to optimize the scoring pipeline.
Building automation capabilities to deploy ML Models and LLM Models on the enterprise on-prem platform and cloud platform.
Build and Deploy capabilities for automating model scoring/Inferencing of ML models and LLMs.
Build and Deploy capabilities for data pipeline deployment standardization and model consumption by multiple LOBs.
Collaborate with product owners, devOps team, data scientists, support teams to define and drive end to end model scoring pipelines.
Participate in day-to-day standups for platform capability build.
Provide SME guidance for data science teams on software engineering principles, model deployments, platform capabilities.
Drive AI use case delivery end to end collaborating with Data scientists, Data Engineers, LOB Technology using standardized platform processes and capabilities.
Support Production Issues partnering with production support.

Key Requirements:

5+ years of Python experience
5+ years of big data experience needed (Big Query, Hadoop)
3 years of experience in AIML area (MLOps)
2+ years of experience in developing APIs using Python/FastAPI.
1+ year of Document AI, Agent Builder/GCP search/conversation / Dialogflow – Nice to have
Good to have 1+year of experience in LLM, Generative AI (developing capabilities or dev/ops)
Good to have Experience in developing of API on GCP/Azure/API Gateways
Good to have 1+year of experience in Vector Database, Model Development would be added benefit.




What will make people successful in the team:

Hands on coding with minimal supervision
On the feet thinking
Great communication skills
30 day full ramp up time

Show more "
AI Engineer,Zortech Solutions,United States,2024-08-07,https://www.linkedin.com/jobs/view/ai-engineer-at-zortech-solutions-3993622480?position=6&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=2o9rw9kw6anPjnNyrMG%2B8A%3D%3D&trk=public_jobs_jserp-result_search-card,"Role: AI Engineer

Location: Charlotte NC (Day 1 Onsite)

Duration: 6+ Months

Job Description

Key Requirements:


5+ years of Python experience
5+ years of big data experience needed (Big Query, Hadoop)
3 years of experience in AIML area (MLOps)
2+ years of experience in developing APIs using Python/FastAPI.
Good to have 1+year of experience in LLM, Generative AI (developing capabilities or dev/ops)
Good to have Experience in developing of API on GCP/Azure/API Gateways
Good to have 1+year of experience in Vector Database, Model Development would be added benefit.


Key Responsibilities


Participate in developing Generative AI & Traditional AI Platform Capabilities on enterprise on-prem and cloud platforms.
Responsible for AI model delivery to on-prem infrastructure and cloud platforms (GCP-Vertex AI, Azure ML)
Collaborating with Data scientist to optimize the scoring pipeline.
Building automation capabilities to deploy ML Models and LLM Models on the enterprise on-prem platform and cloud platform.
Build and Deploy capabilities for automating model scoring/Inferencing of ML models and LLMs.
Build and Deploy capabilities for data pipeline deployment standardization and model consumption by multiple LOBs.
Collaborate with product owners, devOps team, data scientists, support teams to define and drive end to end model scoring pipelines.
Participate in day-to-day standups for platform capability build.
Provide SME guidance for data science teams on software engineering principles, model deployments, platform capabilities.
Drive AI use case delivery end to end collaborating with Data scientists, Data Engineers, LOB Technology using standardized platform processes and capabilities.
Support Production Issues partnering with production support.
Show more "
Sr MLOps Engineer with Azure Exp Dallas TX (onsite Role),InfoVision Inc.,United States,2024-08-24,https://www.linkedin.com/jobs/view/sr-mlops-engineer-with-azure-exp-dallas-tx-onsite-role-at-infovision-inc-3755176910?position=7&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=rZXhl2SW%2B0t2O%2BtHceTSDw%3D%3D&trk=public_jobs_jserp-result_search-card,"We have an immediate Openings with Our Direct Client for a Long term contract position.

Job Title: Sr MLOps Engineer With Azure Exp

Location: Dallas TX (onsite Role)

Duration: 12+ Months

Qualification


10+ years of experience in implementing MLOps processes and solutions within the Azure ecosystem.
Proficiency in Azure cloud services, including AzureML, Azure DevOps, Azure Kubernetes Service (AKS), Azure Databricks, and other relevant Azure services.
Strong knowledge of machine learning frameworks and tools compatible with Azure and scikit-learn.
Familiarity with Azure Resource Manager templates and Infrastructure as Code (IaC).
Experience with version control systems, particularly Git, and CI/CD pipelines using Azure DevOps.
Should have implemented test automation scripts to validate the deployment process.
Scripting and coding skills, with proficiency in languages such as Python, PySpark, PowerShell, or Azure CLI.
Understanding of security and compliance standards within the Azure ecosystem.
Should have executed atleast 2 Azure MLOps project
Should have worked atleast 2 projects using Agile/SAFe methodology
Problem-solving and troubleshooting abilities.
Should have cross global location experience and been part of a team with atleast 15+ members in a global delivery model
Azure-specific certifications can be a plus, such as Microsoft Certified: Azure AI Engineer Associate or Microsoft Certified: Azure DevOps Engineer Expert.


Responsibilities


Collaborate with data scientists and engineers to design, build, and maintain Azure-based MLOps pipelines for automating machine learning model deployment, monitoring, and maintenance.
Configure and manage Azure cloud resources to support machine learning workloads efficiently.
Collaborate with Azure administrators to ensure scalable and reliable infrastructure for MLOps.
Implement Azure-based deployment pipelines for deploying machine learning models into production environments.
Implement test automation script to monitor & validate the deployment process.
Work alongside data engineers to develop and maintain data pipelines on Azure, ensuring proper data governance and integration with MLOps pipelines.
Implement data versioning, data lineage tracking, and other data management best practices.
Implement test automation script to monitor & validate the deployment process.
Ensure that MLOps processes on Azure adhere to security and regulatory standards.
Monitor and troubleshoot application and infrastructure issues and implement solutions in a timely manner
Collaborate with development and BI teams to ensure code quality and application performance
Stay updated on the latest Azure MLOps tools and services and integrate improvements into existing processes.
Show more "
Machine Learning Engineer,US Tech Solutions,United States,2024-08-09,https://www.linkedin.com/jobs/view/machine-learning-engineer-at-us-tech-solutions-3996803892?position=8&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=LQV%2BOR0R5%2BBNJtgCIgViOg%3D%3D&trk=public_jobs_jserp-result_search-card,"Duration: 09 months contract




Job Description:

The Machine Learning Engineer will be responsible for designing, implementing, and deploying machine learning models and algorithms to solve complex business problems. You will work closely with data scientists, software engineers, and product managers to develop scalable solutions that leverage advanced analytics and machine learning techniques.




Responsibilities:

The Machine Learning (ML) Expert will:

Understand the business needs and requirements and translate them into ML solutions.

Communicate technical concepts and results to non-technical stakeholders in a clear and concise manner.

Collaborate with internal clients to identify new opportunities for ML applications and models.

Ensure that ML Models are aligned with the bank’s overall strategy and goals.

Work with Application Development teams to deploy and support ML models in production environments.

Stay up to date with the latest development in ML and AI and apply this knowledge to first improve the performances of applications (current & past), and second to the benefits of the team.




Experience:

8+ of hands-on experience in designing, developing, and deploying machine learning models for real-world applications. Proven ability to work with various types of models such as classification, regression, clustering, and deep learning.




Skills:

Experience with machine learning frameworks such as Tensorflow, PyTorch, or scikit-learn.

Strong programming skills in languages such as Python, database manipulation (SQL), statistical modeling, data analysis techniques.

Experience with CI/CD pipelines (GIT, Jenkins, …) and MLOps (MLFlow).




Education:

Master’s degree in computer science, mathematics, statistics, or a related field.




About US Tech Solutions:

US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com.




US Tech Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.




Recruiter Details:

Name: Jatin

Email: jatin.g@ustechsolutionsinc.com

Internal Id: 24-18625

Show more "
AI/ML Operations Manager,Insight Global,United States,2024-08-27,https://www.linkedin.com/jobs/view/ai-ml-operations-manager-at-insight-global-4009477093?position=9&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=yiUN0ZrgbKfuaDdfwVyYqw%3D%3D&trk=public_jobs_jserp-result_search-card,"Must Haves:

Bachelor’s degree in IT related field
12+ years of IT experience, 6+ years managing direct reports
Heavy experience with CI/CD concepts/tools such as Jenkins, Git, Terraform, Ansible, or Puppet.
Understanding of cloud-native development and cloud integration patterns.
Must have the ability to lead and manage an enterprise scale cloud-based ML operations function
Understanding of cyber security and information risk concepts







Preferred Qualifications:

Experience with enterprise data tools and platforms such as Snowflake, MicroStrategy, Informatica, Fivetran, Business Objects, Tableau, Dataiku.
Background in Data Science.
ITIL, Cloud, or PMP Certification.







Day-To-Day:

Insight Global is seeking an AI/ML Ops Engineering Manager for one of our largest clients in Cleveland, Ohio. This role collaborates with Enterprise Architecture, Infrastructure & Operations, and Enterprise Data & Insights to define, prioritize, and execute technical roadmaps for AI / MLOps platforms. This individual will be a key player in assisting with the company’s AI strategy, setting development goals for individuals to ensure that all members are contributing to the broader goals of the organization. They will be directly managing three engineers, and should portray servant leadership, strong decision-making and team management skills, and should be willing to help remote organizational blockers on behalf of the team.




Additional Responsibilities Include:




Collaborate with IT Leadership, engineers, and architects to create, promote, and execute a shared vision and roadmap for Data Technology platforms.
Collaborate with Data Technology partners on aligning priorities to remove blockers to team velocity.
Meet with clients, peers, and decision makers to understand goals and resolve conflicts.
Ensure tracking and management of strategies and plans is in alignment with organizational objectives; provide visibility to these plans.
Facilitate and oversee team goals.
Ensure a plan is in place for key individuals and specific skillsets to ensure that sufficient staff depth is in place to meet the needs of the business.
Determine staffing needs and skill requirements within teams.
Create and maintain development plans for each direct report, including training, skills assessment, career planning, and goal planning.
Conduct activities such as staffing, performance and resource management, and strategic direction of the team.
Set employee objectives, monitor and evaluate performance, and provide feedback and mentoring

Show more "
QA Engineer (Remote Eastern Hours),Arch Capital Group Ltd.,United States,2024-08-22,https://www.linkedin.com/jobs/view/qa-engineer-remote-eastern-hours-at-arch-capital-group-ltd-4007852593?position=10&pageNum=12&refId=YNIoc9WMoHZOoBK8%2BIcRvQ%3D%3D&trackingId=Zhty7RuN0QloLVVp3S0Sug%3D%3D&trk=public_jobs_jserp-result_search-card,"With a company culture rooted in collaboration, expertise and innovation, we aim to promote progress and inspire our clients, employees, investors and communities to achieve their greatest potential. Our work is the catalyst that helps others achieve their goals. In short, We Enable Possibility℠.

The Position

Strategic Analytics is a growing team at Arch that has established itself as a driving force in how the business is run. This is achieved through the implementation of real-time predictive analytic solutions that move the company forward. Our track record is 100% adoption of our tools and services. Data plays a critical role in our mission. We create best-in-class data solutions from internal and external sources by leveraging a diverse set of cloud technologies like Snowflake, the Azure tech stack, Databricks and Python.

As a QA engineer on the implementation engineering team, you will develop cutting edge solutions that put analytics at the heart of decision-making. You will work closely with other members of the Strategic Analytics team on high-profile analytics projects that drive business strategies. As a key member of the implementation engineering team, you will extend our capacity to deliver and push the team forward.

Job Responsibilities

Test Framework and Communication


Develop enhancements to the MLOps testing framework
Suggest improvements of the processes to increase quality of the product and performance of the team
Keep stakeholders updated with testing status and reports
Implement product requirements, technical execution plan, and testing objectives


Test Planning and Execution


Execute test plan and process as scheduled by QA Leadership
Create and modify test cases, test data, and develop automated test scripts for projects and ad-hoc releases
Analyze new feature performance against established baselines
Document efforts of defects and resolution
Collaborate with QA engineers, project leads and developers


Required Skills/Experience


1-3 years of software testing experience with Python and SQL
1-3 years of API testing experience
Foundational understanding of quality assurance with APIs
Experience testing APIs and using test automation resources
Experience developing automation scripts using automation framework
Experience using project management tools like JIRA, TFS and Asana


Desired Skills/Experience


Experience with BDD and Hybrid BDD frameworks
Experience with Allure reports
Experience with MLOps frameworks and concepts
Experience with Azure Portal, Function Apps, and Databricks
Strong understanding of SQL and Python, and the ability to use SQL resources to query a database to retrieve data.


Education


Bachelor’s degree in computer science or equivalent work experience.


For individuals assigned or hired to work in California, Colorado, Hawaii, Jersey City, NJ; New York State; and/or Washington State, the base salary range is listed below. This range is as of the time of posting. Position is incentive eligible.

$65,000 – $95,500/year


Total individual compensation (base salary, short & long-term incentives) offered will take into account a number of factors including but not limited to geographic location, scope & responsibilities of the role, qualifications, talent availability & specialization as well as business needs. The above range may be modified in the future
Click here to learn more on available benefits


Do you like solving complex business problems, working with talented colleagues and have an innovative mindset? Arch may be a great fit for you. If this job isn’t the right fit but you’re interested in working for Arch, create a job alert! Simply create an account and opt in to receive emails when we have job openings that meet your criteria. Join our talent community to share your preferences directly with Arch’s Talent Acquisition team.


Show more "
